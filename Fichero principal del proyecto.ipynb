{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0210de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "#Leemos el csv\n",
    "evaluation = pandas.read_csv('turkiye-student-evaluation_R_Specific.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "40fd7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  ...  \\\n",
       "1       1      2          1           0           4   3   3   3   3   3  ...   \n",
       "2       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "3       1      2          1           2           4   5   5   5   5   5  ...   \n",
       "4       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "5       1      2          1           0           1   1   1   1   1   1  ...   \n",
       "6       1      2          1           3           3   4   4   4   4   4  ...   \n",
       "7       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "8       1      2          1           1           3   5   5   5   5   5  ...   \n",
       "9       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "10      1      2          1           4           4   4   4   4   4   4  ...   \n",
       "\n",
       "    Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  \n",
       "1     3    3    3    3    3    3    3    3    3    3  \n",
       "2     3    3    3    3    3    3    3    3    3    3  \n",
       "3     5    5    5    5    5    5    5    5    5    5  \n",
       "4     3    3    3    3    3    3    3    3    3    3  \n",
       "5     1    1    1    1    1    1    1    1    1    1  \n",
       "6     4    4    4    4    4    4    4    4    4    4  \n",
       "7     4    4    4    4    4    4    4    4    4    4  \n",
       "8     5    5    5    5    5    5    5    5    5    5  \n",
       "9     4    4    4    4    4    4    4    4    4    4  \n",
       "10    4    4    4    4    4    4    4    4    4    4  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bién\n",
    "evaluation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9259e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08333333 0.         0.         ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.25       ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.5        ... 1.         1.         1.        ]\n",
      " ...\n",
      " [1.         0.         0.         ... 1.         1.         1.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos \n",
    "atributos = evaluation.loc[:, 'class':'Q27']\n",
    "atributos = atributos.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "atributos = scaler.fit_transform(atributos)\n",
    "print(atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b22a5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5]\n",
      " [0.5]\n",
      " [1. ]\n",
      " ...\n",
      " [1. ]\n",
      " [0. ]\n",
      " [0. ]]\n"
     ]
    }
   ],
   "source": [
    "objetivo = evaluation['Q28']\n",
    "objetivo = evaluation['Q28'].to_numpy(dtype=np.float32)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "objetivo = scaler.fit_transform(objetivo.reshape(-1, 1))\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "141c7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a6ff2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()\n",
    "normalizador.adapt(atributos_entrenamiento)\n",
    "red_evaluation = keras.Sequential()\n",
    "red_evaluation.add(keras.layers.Input(shape=(31,)))\n",
    "red_evaluation.add(normalizador)\n",
    "red_evaluation.add(keras.layers.Dense(75, activation='relu'))\n",
    "red_evaluation.add(keras.layers.Dense(75, activation='sigmoid'))\n",
    "red_evaluation.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "red_evaluation.add(keras.layers.Lambda(lambda x: x * 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6b8a17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_34 (Normaliza  (None, 31)               63        \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 75)                2400      \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 75)                5700      \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 1)                 76        \n",
      "                                                                 \n",
      " lambda_13 (Lambda)          (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,239\n",
      "Trainable params: 8,176\n",
      "Non-trainable params: 63\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_evaluation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3114e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.2068 - mae: 0.3653\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 997us/step - loss: 0.0638 - accuracy: 0.3151 - mae: 0.2067\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.3186 - mae: 0.1842\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.3208 - mae: 0.1663\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.3208 - mae: 0.1517\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 977us/step - loss: 0.0364 - accuracy: 0.3224 - mae: 0.1405\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.3228 - mae: 0.1320\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.3226 - mae: 0.1256\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.3228 - mae: 0.1204\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.3228 - mae: 0.1166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a51390a730>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "red_evaluation.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "29d4f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 713us/step - loss: 0.0305 - accuracy: 0.3333 - mae: 0.1201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.030451636761426926, 0.3333333432674408, 0.12010810524225235]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_evaluation.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "250f3119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08333333 0.         0.         ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.25       ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.5        ... 1.         1.         1.        ]\n",
      " ...\n",
      " [1.         0.         0.         ... 1.         1.         1.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]]\n",
      "[[0.5]\n",
      " [0.5]\n",
      " [1. ]\n",
      " ...\n",
      " [1. ]\n",
      " [0. ]\n",
      " [0. ]]\n",
      "[[0.5]\n",
      " [0.5]\n",
      " [1. ]\n",
      " ...\n",
      " [1. ]\n",
      " [0. ]\n",
      " [0. ]]\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_35 (Normaliza  (None, 31)               63        \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 75)                2400      \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 75)                5700      \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 1)                 76        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,239\n",
      "Trainable params: 8,176\n",
      "Non-trainable params: 63\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 0s 992us/step - loss: 0.1590 - accuracy: 0.2911 - mae: 0.2643\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 991us/step - loss: 0.0387 - accuracy: 0.3177 - mae: 0.1456\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 0.3196 - mae: 0.1315\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.3207 - mae: 0.1211\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.3223 - mae: 0.1137\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.3238 - mae: 0.1080\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 991us/step - loss: 0.0246 - accuracy: 0.3244 - mae: 0.1035\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.3242 - mae: 0.0999\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.3240 - mae: 0.0970\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.3246 - mae: 0.0947\n",
      "19/19 [==============================] - 0s 744us/step - loss: 0.0164 - accuracy: 0.3299 - mae: 0.0841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01639534905552864, 0.3298968970775604, 0.08413909375667572]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "steel = pandas.read_csv('turkiye-student-evaluation_generic.csv', header=0)\n",
    "steel.head(10)\n",
    "atributos = evaluation.loc[:, 'class':'Q27']\n",
    "atributos = atributos.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "atributos = scaler.fit_transform(atributos)\n",
    "print(atributos)\n",
    "objetivo = evaluation['Q28']\n",
    "objetivo = evaluation['Q28'].to_numpy(dtype=np.float32)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "objetivo = scaler.fit_transform(objetivo.reshape(-1, 1))\n",
    "print(objetivo)\n",
    "print(objetivo)\n",
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.10)\n",
    "normalizador = keras.layers.Normalization()\n",
    "normalizador.adapt(atributos_entrenamiento)\n",
    "red_evaluation = keras.Sequential()\n",
    "red_evaluation.add(keras.layers.Input(shape=(31,)))\n",
    "red_evaluation.add(normalizador)\n",
    "red_evaluation.add(keras.layers.Dense(75, activation='relu'))\n",
    "red_evaluation.add(keras.layers.Dense(75, activation='sigmoid'))\n",
    "red_evaluation.add(keras.layers.Dense(1))\n",
    "#red_evaluation.add(keras.layers.Lambda(lambda x: x * 5))\n",
    "red_evaluation.summary()\n",
    "red_evaluation.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "red_evaluation.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6c7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo LIME\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "N es el n´umero de permutaciones a realizar\n",
    "f es el modelo a explicar\n",
    "X′ ← {} muestras perturbadas\n",
    "R ← {} representaciones\n",
    "W ← {} las distancias entre la muestra x y sus perturbaciones\n",
    "for 1\n",
    "to\n",
    "N do\n",
    "Selecciona k atributos aleatoriamente\n",
    "x′ ← una perturbaci´on de x donde se perturban los k atributos anteriores.\n",
    "w ← la distancia entre x y x′\n",
    "r ← la representaci´on de x′ respecto a x\n",
    "X′ ← X′ ∪ x′\n",
    "R ← R ∪ r\n",
    "W ← R ∪ w\n",
    "end for\n",
    "Y ′ ← f(X′) las predicciones de las perturbaciones\n",
    "G ← modelo ridge entrenado con R para predecir Y ′ y ponderando cada\n",
    "muestra con W\n",
    "return los par´ametros de G\n",
    "\"\"\"\n",
    "\n",
    "def explain_model(f, x, N,M):\n",
    "    #f es el modelo a explicar\n",
    "    #N es el número de permutaciones a realizar\n",
    "    Xi = [] #muestras perturbadas\n",
    "    R = [] #representaciones\n",
    "    W = [] #Las distancias entre la muestra x y sus pertubaciones\n",
    "    for i in range(N):\n",
    "        k = random.randint(1, len(x)) #Escojo un número aletario que representa el número de los atributos a seleccionar\n",
    "        perturbed_x = x.copy() #copio la muestra original\n",
    "        for i in range(k): \n",
    "            perturbed_attr = random.choice(list(x.keys())) #Voy escojiento los atributos que perturbare de forma aleatoria\n",
    "            mx = abs(max([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor máximo\n",
    "            mn = abs(min([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor mínimo\n",
    "            perturbed_x[perturbed_attr] = random.uniform(mn, mx) # pertubo el atributo con un valor aleatorio ente mn y mx\n",
    "        w = abs(sum([x[attr] - perturbed_x[attr] for attr in x.keys()])) #Calculo la distancia entre el original y el perturbado\n",
    "        r = {attr: 0  if x_perturbed[attr] = x[attr] else 1 for attr in x.keys()} #miramos la representacion del pertubado respecto al original utilizando un operador ternario como solemos hacer en java\n",
    "        Xi.append(x_perturbed) #Acumulo en la lista los perturbados\n",
    "        R.append(r)#Acumulamos en la lista de representaciones\n",
    "        W.append(w)#Añadimos las distancias a la lista\n",
    "    Y_perturbed = f(Xi)#aplicamos el modelo f\n",
    "    G = Ridge().fit(R, Y_perturbed, sample_weight=W) #Utilizamos Ridge \n",
    "    return G.get_params() #Devolvemos los parametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03e8a21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La métrica Identidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\n"
     ]
    }
   ],
   "source": [
    "#METODO IDENTIDAD\n",
    "import pandas\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import lambertw\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Creamos dos instancias de datos y sus respectivas explicaciones LIME\n",
    "xa = np.array([0.5, 0.7, 0.1, 0.3])\n",
    "xb = np.array([0.3, 0.9, 0.2, 0.1])\n",
    "ea = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "eb = np.array([0.3, 0.4, 0.5, 0.1])\n",
    "\n",
    "# Calculamos la distancia entre las instancias de datos\n",
    "data_distance = cdist(xa.reshape(1,-1), xb.reshape(1,-1))\n",
    "\n",
    "# Calculamos la distancia entre las explicaciones LIME\n",
    "exp_distance = cdist(ea.reshape(1,-1), eb.reshape(1,-1))\n",
    "\n",
    "# Verificamos si la métrica Identidad se cumple\n",
    "if data_distance == 0 and exp_distance != 0:\n",
    "    print(\"La métrica Identidad no se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Identidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SEPARABILIDAD\n",
    "# Creamos dos instancias de datos y sus respectivas explicaciones LIME\n",
    "xa = np.array([0.5, 0.7, 0.1, 0.3])\n",
    "xb = np.array([0.3, 0.9, 0.2, 0.1])\n",
    "ea = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "eb = np.array([0.3, 0.4, 0.5, 0.1])\n",
    "\n",
    "# Calculamos la distancia entre las instancias de datos\n",
    "data_distance = cdist(xa.reshape(1,-1), xb.reshape(1,-1))\n",
    "\n",
    "# Calculamos la distancia entre las explicaciones LIME\n",
    "exp_distance = cdist(ea.reshape(1,-1), eb.reshape(1,-1))\n",
    "\n",
    "# Verificamos si la métrica Separabilidad se cumple\n",
    "if data_distance != 0 and exp_distance <= 0:\n",
    "    print(\"La métrica Separabilidad no se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Separabilidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO ESTABILIDAD\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Creamos las distancias entre las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_distances = cdist(x, x[0].reshape(1,-1))\n",
    "exp_distances = cdist(ex, ex[0].reshape(1,-1))\n",
    "\n",
    "# Calculamos el coeficiente de correlación de Pearson entre las distancias\n",
    "correlation, _ = pearsonr(data_distances.flatten(), exp_distances.flatten())\n",
    "\n",
    "# Verificamos si la métrica Estabilidad se cumple\n",
    "if correlation > 0:\n",
    "    print(\"La métrica Estabilidad se cumple para este conjunto de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Estabilidad no se cumple para este conjunto de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0722bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO COHERENCIA\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=1))\n",
    "exp_weights = np.exp(-np.linalg.norm(ex - ex.mean(axis=0), axis=1))\n",
    "\n",
    "# Calculamos los logaritmos naturales de los pesos y los sumamos\n",
    "log_sum_data = np.sum(np.log(data_weights))\n",
    "log_sum_exp = np.sum(np.log(exp_weights))\n",
    "\n",
    "# Calculamos la métrica Coherencia\n",
    "alpha = np.exp(log_sum_data - log_sum_exp + lambertw(0.0, -np.exp(log_sum_data - log_sum_exp)).real)\n",
    "alpha /= len(x)\n",
    "\n",
    "# Imprimimos el valor de la métrica Coherencia\n",
    "print(\"El valor de la métrica Coherencia es:\", alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97773e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO COMPLETITUD\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=1))\n",
    "exp_weights = np.exp(-np.linalg.norm(ex - ex.mean(axis=0), axis=1))\n",
    "\n",
    "# Calculamos los valores de ei y pi\n",
    "ei = np.sum(exp_weights)\n",
    "pi = np.sum(data_weights)\n",
    "\n",
    "# Calculamos la métrica Completitud\n",
    "gamma = ei / pi\n",
    "\n",
    "# Imprimimos el valor de la métrica Completitud\n",
    "print(\"El valor de la métrica Completitud es:\", gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO CONGRUENCIA\n",
    "# Creamos una lista de valores de coherencia para un conjunto de N muestras\n",
    "alpha_values = [0.8, 0.6, 0.7, 0.9, 0.5]\n",
    "\n",
    "# Calculamos el valor promedio de la coherencia\n",
    "alpha = np.mean(alpha_values)\n",
    "\n",
    "# Creamos una lista de valores de alpha_i para cada instancia de datos\n",
    "alpha_i_values = [0.9, 0.7, 0.6, 0.8, 0.4]\n",
    "\n",
    "# Calculamos el número de instancias de datos\n",
    "N = len(alpha_i_values)\n",
    "\n",
    "# Calculamos la suma de las diferencias cuadráticas entre alpha_i y alpha\n",
    "diff_squares_sum = np.sum((np.array(alpha_i_values) - alpha) ** 2)\n",
    "\n",
    "# Calculamos la métrica Congruencia\n",
    "delta = np.sqrt((diff_squares_sum / N) / alpha)\n",
    "\n",
    "# Imprimimos el valor de la métrica Congruencia\n",
    "print(\"El valor de la métrica Congruencia es:\", delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5de2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SELECTIVIDAD\n",
    "# Cargamos el dataset de cáncer de mama de scikit-learn\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Definimos las características y la variable objetivo\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "# Creamos un modelo de regresión logística\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(X, y)\n",
    "\n",
    "# Obtenemos las predicciones del modelo en el conjunto de datos completo\n",
    "y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculamos el AUC para el modelo entrenado en el conjunto de datos completo\n",
    "auc_full = roc_auc_score(y, y_pred)\n",
    "\n",
    "# Ordenamos las características de más a menos relevantes según el modelo\n",
    "idx_sorted = np.argsort(np.abs(model.coef_))[0][::-1]\n",
    "\n",
    "# Creamos una lista para almacenar los AUC para cada característica eliminada\n",
    "auc_scores = []\n",
    "\n",
    "# Iteramos sobre las características de más a menos relevantes según el modelo\n",
    "for i in range(X.shape[1]):\n",
    "    # Establecemos la característica i en cero\n",
    "    X_test = X.copy()\n",
    "    X_test[:, idx_sorted[i]] = 0\n",
    "    \n",
    "    # Obtenemos las predicciones del modelo en el conjunto de datos con la característica i eliminada\n",
    "    y_pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculamos el AUC para el modelo entrenado en el conjunto de datos con la característica i eliminada\n",
    "    auc_test = roc_auc_score(y, y_pred_test)\n",
    "    \n",
    "    # Almacenamos el AUC para la característica i eliminada en la lista de AUC\n",
    "    auc_scores.append(auc_test)\n",
    "\n",
    "# Calculamos la métrica Selectividad como el área bajo la curva ROC para el gráfico de AUC vs características eliminadas\n",
    "selectivity = np.trapz(auc_scores, dx=1)\n",
    "\n",
    "# Imprimimos el valor de la métrica Selectividad\n",
    "print(\"El valor de la métrica Selectividad es:\", selectivity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
