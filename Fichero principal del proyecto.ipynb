{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0210de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "#Leemos el csv\n",
    "evaluation = pandas.read_csv('turkiye-student-evaluation_R_Specific.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fd7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  ...  \\\n",
       "1       1      2          1           0           4   3   3   3   3   3  ...   \n",
       "2       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "3       1      2          1           2           4   5   5   5   5   5  ...   \n",
       "4       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "5       1      2          1           0           1   1   1   1   1   1  ...   \n",
       "6       1      2          1           3           3   4   4   4   4   4  ...   \n",
       "7       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "8       1      2          1           1           3   5   5   5   5   5  ...   \n",
       "9       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "10      1      2          1           4           4   4   4   4   4   4  ...   \n",
       "\n",
       "    Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  \n",
       "1     3    3    3    3    3    3    3    3    3    3  \n",
       "2     3    3    3    3    3    3    3    3    3    3  \n",
       "3     5    5    5    5    5    5    5    5    5    5  \n",
       "4     3    3    3    3    3    3    3    3    3    3  \n",
       "5     1    1    1    1    1    1    1    1    1    1  \n",
       "6     4    4    4    4    4    4    4    4    4    4  \n",
       "7     4    4    4    4    4    4    4    4    4    4  \n",
       "8     5    5    5    5    5    5    5    5    5    5  \n",
       "9     4    4    4    4    4    4    4    4    4    4  \n",
       "10    4    4    4    4    4    4    4    4    4    4  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bien\n",
    "evaluation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9259e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.   0.25 0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos \n",
    "atributos = evaluation.loc[:, 'class':'Q27']\n",
    "atributos = atributos.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "atributos = scaler.fit_transform(atributos)\n",
    "print(atributos[5818,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22a5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 5. ... 5. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos el objetivo\n",
    "objetivo = evaluation['Q28']\n",
    "objetivo = evaluation['Q28'].to_numpy(dtype=np.float32)\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141c7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos los datos que se usaran para entrenar y los que se usarán para evaluar los modelos\n",
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ff2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()#Definimos un normalizador\n",
    "normalizador.adapt(atributos_entrenamiento)\n",
    "red_evaluation = keras.Sequential()#Creamos la red neuronal\n",
    "red_evaluation.add(keras.layers.Input(shape=(31,)))#Definimos la capa de entrada con una neurona por cada atributo\n",
    "red_evaluation.add(normalizador)#Aplicamos el normalizador\n",
    "red_evaluation.add(keras.layers.Dense(70, activation='relu'))#Definimos una capa con 70 neuronas y función de activación relu\n",
    "red_evaluation.add(keras.layers.Dense(70, activation='sigmoid'))#Definimos una capa de 70 neuronas y función de activación sigmoide\n",
    "red_evaluation.add(keras.layers.Dense(1, activation='linear')) #Defnimios una capa de salida con función de activación lienal ya que los valores esperados son números lineales entre 0 y 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8a17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 31)               63        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 70)                2240      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,344\n",
      "Trainable params: 7,281\n",
      "Non-trainable params: 63\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_evaluation.summary()#Mostramos un resumen de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3114e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s 5ms/step - loss: 2.0086 - accuracy: 0.1391 - mae: 1.0738\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5204 - accuracy: 0.1417 - mae: 0.5208\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3553 - accuracy: 0.1417 - mae: 0.3859\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.1417 - mae: 0.3473\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3002 - accuracy: 0.1417 - mae: 0.3273\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2895 - accuracy: 0.1417 - mae: 0.3191\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2812 - accuracy: 0.1417 - mae: 0.3097\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2743 - accuracy: 0.1417 - mae: 0.3028\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2688 - accuracy: 0.1417 - mae: 0.2997\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2643 - accuracy: 0.1417 - mae: 0.2930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18fcf5c1e50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "red_evaluation.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])#Compilamos la red neuronal definiendo el optimizaodr, la función de perdida y dos metricas\n",
    "red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)#Entrenamos la red neuronal con 10 epocas y lotes de 256 elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d4f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.1271 - mae: 0.3210\n",
      "0.3242553472518921\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "#Para este conjunto de datos esto practicamente no es necesario pero así nos aseguramos de cometer un error muy pequeño\n",
    "perdObj = 1.0\n",
    "x=red_evaluation.evaluate(atributos_prueba, objetivo_prueba)\n",
    "while x[0]>perdObj:\n",
    "    red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_evaluation.evaluate(atributos_prueba, objetivo_prueba)\n",
    "    \n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad4c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.1271 - mae: 0.3210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3242553472518921, 0.12714776396751404, 0.32097163796424866]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_evaluation.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84bc4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 31) for input KerasTensor(type_spec=TensorSpec(shape=(None, 31), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "Esperado 4: [[4.1635756]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Esperado 3: [[2.9934316]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Esperado 3: [[3.0887675]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Esperado 1: [[1.0869037]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Esperado 3: [[3.0701988]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Esperado 1: [[1.2919029]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Esperado 1: [[1.0869037]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Esperado 5: [[4.651767]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Esperado 5: [[4.945514]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Esperado 1: [[1.1100278]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Esperado 1: [[1.1100278]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "X=atributos[5809]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 4:',predicciones)\n",
    "X=atributos[5810]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5811]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5812]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5813]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5814]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5815]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5816]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos[5817]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos[5818]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5819]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55821bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 0.29200438584356353\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_evaluation = RandomForestRegressor() #Creamos el modelo\n",
    "forest_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento)#Lo entrenamos\n",
    "evaluaciones = forest_evaluation.predict(atributos_prueba)#Evaluamos\n",
    "mse = mean_squared_error(objetivo_prueba, evaluaciones)#Calculamos la perdida\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)\n",
    "#Como este modelo suele tener una perdida muy pequeña tras entrenarlo una vez, no hacemos nada más para mejorarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a83c67dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 4: [4.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 1: [1.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 1: [1.02]\n",
      "Esperado 1: [1.]\n",
      "Esperado 5: [4.95]\n",
      "Esperado 5: [5.]\n",
      "Esperado 1: [1.]\n",
      "Esperado 1: [1.]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "atributos2 = atributos[:, np.newaxis]\n",
    "X=atributos2[5809]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 4:',predicciones)\n",
    "X=atributos2[5810]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5811]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5812]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5813]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5814]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5815]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5816]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos2[5817]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos2[5818]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5819]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "250f3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear otra red neuronal\n",
    "#Volemos a importar por si se quiere ejecutar este fragmento sin ejecutar el anterior\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#Leemos el csv\n",
    "#bikes = pandas.read_csv('hour.csv', header=0)\n",
    "bikes = pandas.read_csv('hour2.csv',header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0073ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0       1   0     1   0        0        6           0           1  0.24   \n",
       "1       1   0     1   1        0        6           0           1  0.22   \n",
       "2       1   0     1   2        0        6           0           1  0.22   \n",
       "3       1   0     1   3        0        6           0           1  0.24   \n",
       "4       1   0     1   4        0        6           0           1  0.24   \n",
       "5       1   0     1   5        0        6           0           2  0.24   \n",
       "6       1   0     1   6        0        6           0           1  0.22   \n",
       "7       1   0     1   7        0        6           0           1  0.20   \n",
       "8       1   0     1   8        0        6           0           1  0.24   \n",
       "9       1   0     1   9        0        6           0           1  0.32   \n",
       "\n",
       "    atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.2879  0.81     0.0000       3          13   16  \n",
       "1  0.2727  0.80     0.0000       8          32   40  \n",
       "2  0.2727  0.80     0.0000       5          27   32  \n",
       "3  0.2879  0.75     0.0000       3          10   13  \n",
       "4  0.2879  0.75     0.0000       0           1    1  \n",
       "5  0.2576  0.75     0.0896       0           1    1  \n",
       "6  0.2727  0.80     0.0000       2           0    2  \n",
       "7  0.2576  0.86     0.0000       1           2    3  \n",
       "8  0.2879  0.75     0.0000       1           7    8  \n",
       "9  0.3485  0.76     0.0000       8           6   14  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bién\n",
    "bikes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "890b5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.00817439 0.01467269]\n",
      " [0.         0.         0.         ... 0.         0.02179837 0.03611738]\n",
      " [0.         0.         0.         ... 0.         0.01362398 0.03047404]\n",
      " ...\n",
      " [0.         1.         1.         ... 0.19301751 0.01907357 0.09367946]\n",
      " [0.         1.         1.         ... 0.15786999 0.03542234 0.05417607]\n",
      " [0.         1.         1.         ... 0.15786999 0.03269755 0.04176072]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos y los nomalizamos\n",
    "attr = bikes.loc[:, 'season':'registered']\n",
    "attr = attr.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "attr = scaler.fit_transform(attr)\n",
    "\n",
    "print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e783ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16. 40. 32. ... 90. 61. 49.]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los objetivos\n",
    "obj = bikes['cnt']\n",
    "obj = bikes['cnt'].to_numpy(dtype=np.float32)\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bec2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cogemos un 85% de los datos para entrenar y un 15% de los datos para evaluar el modelo\n",
    "(attr_entrenamiento, attr_prueba,\n",
    " obj_entrenamiento, obj_prueba) = model_selection.train_test_split(\n",
    "    attr, obj, test_size=.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01172681",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()#Definimos un normalizador\n",
    "normalizador.adapt(attr_entrenamiento)\n",
    "red_bikes = keras.Sequential()#Creamos la red neuronal\n",
    "red_bikes.add(keras.layers.Input(shape=(14,))) #Añadimos la capa de entrada con 14 neuronas, una por cada atributo\n",
    "red_bikes.add(normalizador)#Aplicamos un normalizador\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(1, activation='linear'))#Necesitamos una capa de salida linear ya que los valores objetivos son lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b9f0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 14)               29        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               1500      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,730\n",
      "Trainable params: 11,701\n",
      "Non-trainable params: 29\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Vemos un resumen de la red\n",
    "red_bikes.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e5d4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 5ms/step - loss: 10915.7881 - accuracy: 0.0091 - mae: 67.1878\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1514.4172 - accuracy: 0.0091 - mae: 27.5313\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 610.2152 - accuracy: 0.0091 - mae: 16.7194\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 505.1913 - accuracy: 0.0091 - mae: 15.4094\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 219.1440 - accuracy: 0.0091 - mae: 9.5991\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 178.1140 - accuracy: 0.0091 - mae: 9.8253\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 214.9675 - accuracy: 0.0091 - mae: 9.5953\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 87.6014 - accuracy: 0.0091 - mae: 6.7033\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 135.3069 - accuracy: 0.0091 - mae: 7.2977\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 42.7013 - accuracy: 0.0091 - mae: 4.1675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18fd1de1670>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compilamos y entrenamos la red neuronal, buscamos minimizar la función de perdida\n",
    "red_bikes.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aa4bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 3ms/step - loss: 121.9681 - accuracy: 0.0086 - mae: 8.3876\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 96.8324 - accuracy: 0.0091 - mae: 7.3383\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 79.7620 - accuracy: 0.0091 - mae: 5.4665\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 58.2903 - accuracy: 0.0091 - mae: 5.5287\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 62.6145 - accuracy: 0.0091 - mae: 5.2642\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 24.9311 - accuracy: 0.0091 - mae: 3.3661\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 69.6575 - accuracy: 0.0091 - mae: 6.1104\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 33.2056 - accuracy: 0.0091 - mae: 4.0961\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 23.3364 - accuracy: 0.0091 - mae: 3.1660\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 106.6636 - accuracy: 0.0091 - mae: 5.2286\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 30.3541 - accuracy: 0.0091 - mae: 3.6637\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 67.5211 - accuracy: 0.0086 - mae: 4.0400\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 38.6803 - accuracy: 0.0091 - mae: 4.1722\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 18.0533 - accuracy: 0.0091 - mae: 3.1585\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 9.4230 - accuracy: 0.0091 - mae: 1.7910\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 26.9270 - accuracy: 0.0091 - mae: 3.8700\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 9.6635 - accuracy: 0.0091 - mae: 2.0743\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 31.1964 - accuracy: 0.0091 - mae: 3.8366\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 49.5052 - accuracy: 0.0091 - mae: 4.4786\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 23.9572 - accuracy: 0.0091 - mae: 3.1222\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 24.8559 - accuracy: 0.0091 - mae: 3.4614\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 32.1789 - accuracy: 0.0091 - mae: 3.8327\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 7.3055 - accuracy: 0.0086 - mae: 1.8693\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 5.1295 - accuracy: 0.0091 - mae: 1.3704\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 51.7945 - accuracy: 0.0091 - mae: 5.0777\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 62.2808 - accuracy: 0.0091 - mae: 4.5661\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 10.0727 - accuracy: 0.0091 - mae: 1.7796\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 10.3260 - accuracy: 0.0091 - mae: 2.2086\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 17.4441 - accuracy: 0.0091 - mae: 2.9881\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 28.5978 - accuracy: 0.0091 - mae: 3.6278\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 7.2018 - accuracy: 0.0091 - mae: 1.9201\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 4.0989 - accuracy: 0.0091 - mae: 1.2982\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 9.1838 - accuracy: 0.0091 - mae: 2.1971\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 21.3964 - accuracy: 0.0086 - mae: 3.5799\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 11.3421 - accuracy: 0.0091 - mae: 2.6480\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 6.7266 - accuracy: 0.0091 - mae: 1.9269\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 23.6478 - accuracy: 0.0091 - mae: 3.3472\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 26.6195 - accuracy: 0.0091 - mae: 3.5276\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.8413 - accuracy: 0.0091 - mae: 1.0667\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 6.4302 - accuracy: 0.0091 - mae: 1.8934\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.8448 - accuracy: 0.0091 - mae: 1.3506\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 10.4265 - accuracy: 0.0091 - mae: 2.4392\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.4055 - accuracy: 0.0091 - mae: 1.5792\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 6.4659 - accuracy: 0.0091 - mae: 1.7541\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 4.1873 - accuracy: 0.0086 - mae: 1.4481\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 6.2160 - accuracy: 0.0091 - mae: 1.9464\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.9618 - accuracy: 0.0091 - mae: 1.3513\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.2001 - accuracy: 0.0091 - mae: 1.2958\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.2642 - accuracy: 0.0091 - mae: 1.0646\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 7.7326 - accuracy: 0.0091 - mae: 2.0128\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 5.4327 - accuracy: 0.0091 - mae: 1.7239\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 4.4666 - accuracy: 0.0091 - mae: 1.5766\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 10.0409 - accuracy: 0.0091 - mae: 2.0621\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 8.6853 - accuracy: 0.0091 - mae: 2.1463\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 12.4015 - accuracy: 0.0091 - mae: 2.7560\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 34.5224 - accuracy: 0.0086 - mae: 4.0055\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 4.7054 - accuracy: 0.0091 - mae: 1.4792\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 19.4711 - accuracy: 0.0091 - mae: 3.1859\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.7453 - accuracy: 0.0091 - mae: 0.9796\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.4255 - accuracy: 0.0091 - mae: 1.3920\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.6767 - accuracy: 0.0091 - mae: 0.9253\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.7553 - accuracy: 0.0091 - mae: 1.5491\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.4930 - accuracy: 0.0091 - mae: 1.1611\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 9.7482 - accuracy: 0.0091 - mae: 2.2759\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.8037 - accuracy: 0.0091 - mae: 1.2329\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 7.4196 - accuracy: 0.0091 - mae: 1.8696\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 16.2959 - accuracy: 0.0086 - mae: 3.2616\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 41.9856 - accuracy: 0.0091 - mae: 4.2976\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.5886 - accuracy: 0.0091 - mae: 0.7888\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.3850 - accuracy: 0.0091 - mae: 0.7998\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.7544 - accuracy: 0.0091 - mae: 0.9177\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 6.6269 - accuracy: 0.0091 - mae: 1.9704\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.1149 - accuracy: 0.0091 - mae: 0.7020\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 5ms/step - loss: 1.1860 - accuracy: 0.0091 - mae: 0.7412\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 20.0747 - accuracy: 0.0091 - mae: 3.3826\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.4509 - accuracy: 0.0091 - mae: 1.6421\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 3.3066 - accuracy: 0.0091 - mae: 1.2451\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 3.2417 - accuracy: 0.0086 - mae: 0.9472\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.0263 - accuracy: 0.0091 - mae: 0.6932\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.8097 - accuracy: 0.0091 - mae: 1.1231\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.2287 - accuracy: 0.0091 - mae: 0.7909\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.6728 - accuracy: 0.0091 - mae: 1.1515\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.5533 - accuracy: 0.0091 - mae: 0.8326\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.2585 - accuracy: 0.0091 - mae: 1.0267\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.9554 - accuracy: 0.0091 - mae: 0.9519\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.2567 - accuracy: 0.0091 - mae: 1.3140\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 5.2901 - accuracy: 0.0091 - mae: 1.8140\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 4.0457 - accuracy: 0.0091 - mae: 1.5681\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 4.7778 - accuracy: 0.0086 - mae: 1.2964\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.3926 - accuracy: 0.0091 - mae: 1.3629\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.7837 - accuracy: 0.0091 - mae: 0.6132\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.8095 - accuracy: 0.0091 - mae: 0.5906\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.0367 - accuracy: 0.0091 - mae: 0.9915\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 4.1587 - accuracy: 0.0091 - mae: 1.5285\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 8.7784 - accuracy: 0.0091 - mae: 2.2224\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 5.8011 - accuracy: 0.0091 - mae: 1.6267\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 6.5338 - accuracy: 0.0091 - mae: 1.5306\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.0091 - mae: 0.5250\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.2977 - accuracy: 0.0091 - mae: 0.8384\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 2.4659 - accuracy: 0.0086 - mae: 1.3335\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 5.4256 - accuracy: 0.0091 - mae: 1.7765\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.3398 - accuracy: 0.0091 - mae: 0.8803\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.7297 - accuracy: 0.0091 - mae: 1.0144\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 4.8647 - accuracy: 0.0091 - mae: 1.6217\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.5397 - accuracy: 0.0091 - mae: 0.8682\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.5269 - accuracy: 0.0091 - mae: 0.8619\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.3912 - accuracy: 0.0091 - mae: 1.0340\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 5.9218 - accuracy: 0.0091 - mae: 1.9707\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.7579 - accuracy: 0.0091 - mae: 1.2807\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 3.8228 - accuracy: 0.0091 - mae: 1.4075\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 1.6323 - accuracy: 0.0086 - mae: 0.9581\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.2521 - accuracy: 0.0091 - mae: 1.1460\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 4.6455 - accuracy: 0.0091 - mae: 1.6370\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.6832 - accuracy: 0.0091 - mae: 0.9508\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 3.1301 - accuracy: 0.0091 - mae: 1.2616\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.8402 - accuracy: 0.0091 - mae: 1.3372\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.0037 - accuracy: 0.0091 - mae: 0.7335\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.0091 - mae: 0.5110\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.0091 - mae: 0.5375\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.0530 - accuracy: 0.0091 - mae: 0.7662\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.1728 - accuracy: 0.0091 - mae: 1.0960\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 8.6336 - accuracy: 0.0086 - mae: 2.1078\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 11.0646 - accuracy: 0.0091 - mae: 2.6436\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.0091 - mae: 0.4921\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.4409 - accuracy: 0.0091 - mae: 1.2173\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 5.2939 - accuracy: 0.0091 - mae: 1.7833\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 5.6177 - accuracy: 0.0091 - mae: 1.8277\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.5349 - accuracy: 0.0091 - mae: 1.1757\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.3069 - accuracy: 0.0091 - mae: 0.8661\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.5355 - accuracy: 0.0091 - mae: 1.2296\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.0091 - mae: 0.5405\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.8749 - accuracy: 0.0091 - mae: 1.2797\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 2.8267 - accuracy: 0.0086 - mae: 1.3361\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.3920 - accuracy: 0.0091 - mae: 0.9189\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.0310 - accuracy: 0.0091 - mae: 0.7375\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 1.2753 - accuracy: 0.0091 - mae: 0.8393\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.0197 - accuracy: 0.0091 - mae: 0.7836\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.3180 - accuracy: 0.0091 - mae: 1.1411\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 1.3257 - accuracy: 0.0091 - mae: 0.6996\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.8537 - accuracy: 0.0091 - mae: 1.2117\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 8.7864 - accuracy: 0.0091 - mae: 2.2208\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.8725 - accuracy: 0.0091 - mae: 0.6658\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.0091 - mae: 0.5129\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.0086 - mae: 0.5460\n",
      "0.5763916373252869\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "perdidaObj = 1.0\n",
    "x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "while x[0]>perdidaObj:\n",
    "    red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "    \n",
    "#La forma más efectiva que hemos encontrado para mejorar nuestra red ha sido la de hacer este bulce ya que es la unica forma de asegurarnos que la red obtendrá la precisión que busquemos\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c731f011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.0086 - mae: 0.5460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5763916373252869, 0.008630610071122646, 0.5459567904472351]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_bikes.evaluate(attr_prueba, obj_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e05ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 14) for input KerasTensor(type_spec=TensorSpec(shape=(None, 14), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None,).\n",
      "Esperado 203: [[202.2305]]\n",
      "Esperado 247: [[247.01466]]\n",
      "Esperado 315: [[315.46652]]\n",
      "Esperado 214: [[213.33109]]\n",
      "Esperado 164: [[164.65822]]\n",
      "Esperado 122: [[123.29248]]\n",
      "Esperado 119: [[120.30547]]\n",
      "Esperado 89: [[89.25454]]\n",
      "Esperado 90: [[89.97709]]\n",
      "Esperado 61: [[60.226505]]\n",
      "Esperado 49: [[49.236687]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "\n",
    "X=attr[17368]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr[17369]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr[17370]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr[17371]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr[17372]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr[17373]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr[17374]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr[17375]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr[17376]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr[17377]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr[17378]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9aa5e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 3.149963866513232\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_bikes = RandomForestRegressor()#Creamos el randomForest\n",
    "forest_bikes.fit(attr_entrenamiento, obj_entrenamiento)#Lo entrenamos\n",
    "evaluaciones = forest_bikes.predict(attr_prueba)#Evaluamos el modelo\n",
    "mse = mean_squared_error(obj_prueba, evaluaciones)#Calculamos la perdida\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d16b5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 203: [202.75]\n",
      "Esperado 247: [246.89]\n",
      "Esperado 315: [314.87]\n",
      "Esperado 214: [214.25]\n",
      "Esperado 164: [163.86]\n",
      "Esperado 122: [122.22]\n",
      "Esperado 119: [118.93]\n",
      "Esperado 89: [89.06]\n",
      "Esperado 90: [90.07]\n",
      "Esperado 61: [61.08]\n",
      "Esperado 49: [49.03]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "attr2 = attr[:, np.newaxis]\n",
    "X=attr2[17368]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr2[17369]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr2[17370]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr2[17371]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr2[17372]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr2[17373]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr2[17374]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr2[17375]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr2[17376]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr2[17377]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr2[17378]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc6c7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo LIME\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Partiremos de este seudocódigo para implementar el metodo\n",
    "N es el n´umero de permutaciones a realizar\n",
    "f es el modelo a explicar\n",
    "X′ ← {} muestras perturbadas\n",
    "R ← {} representaciones\n",
    "W ← {} las distancias entre la muestra x y sus perturbaciones\n",
    "for 1\n",
    "to\n",
    "N do\n",
    "Selecciona k atributos aleatoriamente\n",
    "x′ ← una perturbaci´on de x donde se perturban los k atributos anteriores.\n",
    "w ← la distancia entre x y x′\n",
    "r ← la representaci´on de x′ respecto a x\n",
    "X′ ← X′ ∪ x′\n",
    "R ← R ∪ r\n",
    "W ← R ∪ w\n",
    "end for\n",
    "Y ′ ← f(X′) las predicciones de las perturbaciones\n",
    "G ← modelo ridge entrenado con R para predecir Y ′ y ponderando cada\n",
    "muestra con W\n",
    "return los par´ametros de G\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def explain_model(f, x, N,M):\n",
    "    #f es el modelo a explicar\n",
    "    #X es una lista de ejemplos a los que se aplicará LIME\n",
    "    #N es el número de permutaciones a realizar\n",
    "    #M contiene todos los ejemplos\n",
    "    #Si queremos que el algoritmo cumpla la metrica identidad necesitamos fijar semillas para la aleatoriedad\n",
    "    random.seed(11)\n",
    "    Xi = [] #Aqui guardaremos las muestras perturbadas\n",
    "    R = []  #Aqui guardaremos las representaciones\n",
    "    W = []  #Aqui guradaremos las distancias\n",
    "    for i in range(N):\n",
    "        k = random.randint(1, len(x)) #Escojo un número aletario que representa el número de los atributos a seleccionar\n",
    "        perturbed_x = x.copy() #copio la muestra original\n",
    "        for j in range(k): \n",
    "            perturbed_attr = random.randint(0,len(x)-1)#Voy escojiento los atributos que perturbare de forma aleatoria\n",
    "            mx = abs(max([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor máximo\n",
    "            mn = abs(min([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor mínimo\n",
    "            perturbed_x[perturbed_attr] = random.uniform(mn, mx) # pertubo el atributo con un valor aleatorio ente mn y mx para que el valor esté acotado\n",
    "        w = abs(sum([x[attr] - perturbed_x[attr] for attr in range(0,len(x)-1)])) #Calculo la distancia entre el original y el perturbado\n",
    "        r = [0  if perturbed_x[attr] == x[attr] else 1 for attr in range(0,len(x)-1)] #Calculo la representación del perturbado respecto al original utilizando un operador ternario\n",
    "        Xi.append(perturbed_x) #Acumulo en la lista los perturbados\n",
    "        R.append(r)#Acumulamos en la lista de representaciones\n",
    "        W.append(w)#Añadimos las distancias a la lista\n",
    "    Y_perturbed = []#Aqui guardaremos las predicciones de las perturbaciones\n",
    "    for i in range(len(Xi)):\n",
    "        y = 1\n",
    "            #En los siguiente if y else comprobamos el tipo de modelo que tenemos ya que dependiendo del tipo necesita recibir los atributos de una forma u otra\n",
    "        if isinstance(f, keras.Sequential):#Comprueba si el modelo es una red neuronal\n",
    "            xi = Xi[i]\n",
    "            y = f.predict(xi,verbose=0)#Hacemos la prediccion con verbose=0 para no cargar la salida de lineas generadas por keras\n",
    "        else: #Si no, es un randomForest\n",
    "            xi = Xi[i]\n",
    "            array = np.array(xi)\n",
    "            xi = array.reshape(1, -1)\n",
    "            y = f.predict(xi)#RandomForest no tiene verbose porque no genera nada\n",
    "                \n",
    "            \n",
    "        Y_perturbed.append(y) #Aplico el modelo f a los ejemplos perturbados\n",
    "            \n",
    "    Y_perturbed = np.squeeze(Y_perturbed) #Por alguna razón aparece el error Found array with dim 3. Estimator expected <= 2\" y lo arreglamos con esta linea que quita una dimensión al array\n",
    "    G = Ridge()\n",
    "    G.fit(R, Y_perturbed, sample_weight=W)\n",
    "    return G.coef_#Devolvemos los parametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd8cf2d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02432406,  0.01243588,  0.01662844, -0.05516985,  0.00396146,\n",
       "       -0.02734023, -0.04393756, -0.05084051, -0.04591982,  0.01510503,\n",
       "        0.01737612, -0.01700965, -0.05885665,  0.00405327, -0.03006711,\n",
       "       -0.07217951, -0.00999771, -0.02601384, -0.05599222,  0.03124656,\n",
       "       -0.01269099, -0.01405098, -0.0430235 ,  0.04410394, -0.04393756,\n",
       "       -0.01205467, -0.02797656, -0.04434989, -0.04121068, -0.01719019])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos varias pruebas para comprobar que funciona el metodo LIME\n",
    "atributivos = atributos[5809]\n",
    "\n",
    "explain_model(red_evaluation,atributivos,10,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5173d8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02432406,  0.01243588,  0.01662844, -0.05516985,  0.00396146,\n",
       "       -0.02734023, -0.04393756, -0.05084051, -0.04591982,  0.01510503,\n",
       "        0.01737612, -0.01700965, -0.05885665,  0.00405327, -0.03006711,\n",
       "       -0.07217951, -0.00999771, -0.02601384, -0.05599222,  0.03124656,\n",
       "       -0.01269099, -0.01405098, -0.0430235 ,  0.04410394, -0.04393756,\n",
       "       -0.01205467, -0.02797656, -0.04434989, -0.04121068, -0.01719019])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos varias pruebas para comprobar que funciona el metodo LIME\n",
    "atributivos = atributos[5809]\n",
    "\n",
    "explain_model(red_evaluation,atributivos,10,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8f33d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05329193,  0.05785083, -0.02938303, -0.00121754,  0.03118763,\n",
       "        0.02368814, -0.0924245 , -0.04637594, -0.07885433, -0.12118314,\n",
       "        0.06010089, -0.0124536 , -0.00507487,  0.05150461, -0.11055356,\n",
       "       -0.01367114, -0.01184712, -0.05904895, -0.10843869,  0.04197182,\n",
       "       -0.05045268, -0.06335174, -0.07150255,  0.02386253, -0.0924245 ,\n",
       "       -0.0160142 , -0.01075033,  0.01123454,  0.04181721, -0.0939344 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atributivos = atributos[5809]\n",
    "\n",
    "explain_model(forest_evaluation,atributivos,10,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "634110b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -14.41166898, -108.19534129,  183.00625567,   76.05185988,\n",
       "         34.30216426, -164.87356029,  133.62825227,  -97.76374446,\n",
       "         37.47019646,   -3.57918921,  -51.81973685,  -48.83394444,\n",
       "        150.88655541])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attri = attr[17378]\n",
    "\n",
    "explain_model(red_bikes,attri,10,attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c2effc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -26.3872849 ,  -95.85683724,  190.29437754,   63.31487811,\n",
       "         50.39551782, -160.89999858,  147.04929586, -111.50024267,\n",
       "         20.8976087 ,  -18.79098559,  -52.05029761,  -64.21018778,\n",
       "        127.66247407])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attri = attr[17378]\n",
    "\n",
    "explain_model(forest_bikes,attri,10,attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a56246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#En la definición de cada metrica se importarán las cosas necesarias por si solo se quiere probar una metrica\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def identidad(x1,x2,exp1,exp2):\n",
    "    #Definición: El principio de identidad establece que objetos idénticos deben recibir explicaciones idénticas.\n",
    "\n",
    "    res = True #Si los objetos no son identicos no hay que valuar\n",
    "    distance = np.linalg.norm(x1 - x2)#Calcula las distancias entre los dos ejemplos\n",
    "    if(distance ==0):   #Solo comprobamos si las explicaciones sean identicas si los objetos son identicos\n",
    "        res = np.linalg.norm(exp1 - exp2) ==0#Comprobamos si ambas explicaciones son iguales\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b089f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ejemplo2=attr[17375]\n",
    "ejemplo1 = attr[17375]\n",
    "print(ejemplo2)\n",
    "print(ejemplo1)\n",
    "exp1 = explain_model(forest_bikes,ejemplo1,2,attr)\n",
    "exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "print(identidad(ejemplo1,ejemplo2,exp1,exp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a59b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def separabilidad(x1,x2,exp1,exp2):\n",
    "#Definición:#Separabilidad: Objetos no idénticos no pueden tener explicaciones idénticas. Para simplificar, cada característica \n",
    "#tiene un nivel mínimo de importancia, positivo o negativo, en las predicciones.\n",
    "\n",
    "    res = True\n",
    "    distance = np.linalg.norm(x1 - x2)#Calcula las distancias entre los dos ejemplos\n",
    "    if(distance >0):   #Si la distancia es distinta de cero\n",
    "        res = not(np.linalg.norm(exp1 - exp2) ==0)#Si las explicaciones son distintas se cumple la separabilidad\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "018fbb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         1.         0.91304348 0.         0.16666667\n",
      " 1.         0.         0.24489796 0.2576     0.6        0.19301751\n",
      " 0.01907357 0.09367946]\n",
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ejemplo2=attr[17376]\n",
    "ejemplo1 = attr[17375]\n",
    "print(ejemplo2)\n",
    "print(ejemplo1)\n",
    "exp1 = explain_model(forest_bikes,ejemplo1,2,attr)\n",
    "exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "print(separabilidad(ejemplo1,ejemplo2,exp1,exp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ce5cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def estabilidad(x1,x2,exp1,exp2,umbEj,umbExp):\n",
    "    #Objetos similares deben tener explicaciones similares\n",
    "    #Para esto calcularemos la correlacion de Spearman para los ejemplos, si superan el limite que se pasará a la función\n",
    "    #Calcularemos la correlación de Spearman para las explicaciones y comprobaremos si supera el umbral, en ese caso, cumpliran la estabilidad\n",
    "    res = True\n",
    "    correlacionEj, _ = spearmanr(x1, x2)\n",
    "    if(abs(correlacionEj) >= umbEj):\n",
    "        correlacionExp, _ = spearmanr(exp1,exp2)\n",
    "        res = abs(correlacionExp)>=umbExp \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1abc14ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         1.         0.91304348 0.         0.16666667\n",
      " 1.         0.         0.24489796 0.2576     0.6        0.19301751\n",
      " 0.01907357 0.09367946]\n",
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "SpearmanrResult(correlation=0.8770812523243259, pvalue=3.801615077865054e-05)\n",
      "SpearmanrResult(correlation=1.0, pvalue=0.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ejemplo2=attr[17376]\n",
    "ejemplo1 = attr[17375]\n",
    "print(ejemplo2)\n",
    "print(ejemplo1)\n",
    "print(spearmanr(ejemplo1, ejemplo2))\n",
    "exp1 = explain_model(forest_bikes,ejemplo1,2,attr)\n",
    "exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "print(spearmanr(exp1, exp2))\n",
    "print(estabilidad(ejemplo1,ejemplo2,exp1,exp2,0.75,0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0dc5db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherencia(mae1, mae2):\n",
    "    #Se calcula la diferencia entre el error de predicción (mae1) sobre la señal original y el error de predicción mae2\n",
    "    #de una nueva señaal donde se eliminan las características no importantes.\n",
    "    alpha_i = np.abs(mae1 - mae2)\n",
    "    return alpha_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e279b412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.298621440894193\n",
      "20.271639057122528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "evaluaciones1 = red_bikes.predict(attr[17375],verbose=0)\n",
    "evaluaciones2 = red_bikes.predict(attr[17376],verbose=0)\n",
    "mae1 = mean_absolute_error(evaluaciones1,evaluaciones2)\n",
    "\n",
    "\n",
    "evaluaciones3 = explain_model(red_bikes,attr[17375],10,attr)\n",
    "evaluaciones4 = explain_model(red_bikes,attr[17376],10,attr)\n",
    "mae2 = mean_absolute_error(evaluaciones3,evaluaciones4)\n",
    "\n",
    "coherencia1 = coherencia(mae1,mae2)\n",
    "print(coherencia1)\n",
    "\n",
    "evaluaciones5 = red_bikes.predict(attr[17373],verbose=0)\n",
    "evaluaciones6 = red_bikes.predict(attr[17374],verbose=0)\n",
    "mae3 = mean_absolute_error(evaluaciones5,evaluaciones6)\n",
    "\n",
    "\n",
    "evaluaciones7 = explain_model(red_bikes,attr[17373],10,attr)\n",
    "evaluaciones8 = explain_model(red_bikes,attr[17374],10,attr)\n",
    "mae4 = mean_absolute_error(evaluaciones7,evaluaciones8)\n",
    "\n",
    "coherencia2 = coherencia(mae3,mae4)\n",
    "print(coherencia2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96098651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def completitud(x, exp):\n",
    "    \n",
    "    # Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "    data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=0))\n",
    "    exp_weights = np.exp(-np.linalg.norm(exp - exp.mean(axis=0), axis=0))\n",
    "\n",
    "    # Calculamos los valores de ei y pi\n",
    "    ei = np.sum(exp_weights)\n",
    "    pi = np.sum(data_weights)\n",
    "\n",
    "    # Calculamos la métrica Completitud\n",
    "    gamma = ei / pi\n",
    "\n",
    "    # Imprimimos el valor de la métrica Completitud\n",
    "    return print(\"El valor de la métrica Completitud es:\", gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a9b351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de la métrica Completitud es: 4.7577439823703274e-57\n"
     ]
    }
   ],
   "source": [
    "ejemplo1 = attr[17375]\n",
    "exp1 = explain_model(forest_bikes,ejemplo1,2,attr)\n",
    "completitud(ejemplo1,exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f997bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def congruencia(alpha_values):\n",
    "    \"\"\"\n",
    "    Calcula la métrica de Congruencia para el método LIME.\n",
    "\n",
    "    Args:\n",
    "        alpha_values (ndarray): Arreglo de valores de alpha calculados para cada característica.\n",
    "\n",
    "    Returns:\n",
    "        float: Valor de la métrica de Congruencia.\n",
    "        \n",
    "    La desviación estándar de la coherencia proporciona el\n",
    "    proxy de congruencia. Esta métrica ayuda a capturar la variabilidad de\n",
    "    la coherencia.\n",
    "    \"\"\"\n",
    "\n",
    "    alpha_avg = np.mean(alpha_values)  # Coherencia promedio\n",
    "    n = alpha_values.shape[0]  # Número de características\n",
    "\n",
    "    # Calcula la métrica de Congruencia\n",
    "    delta = np.sum(np.square(alpha_values - alpha_avg)) / n\n",
    "\n",
    "    return delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c00a83e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.07479651774267"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores_coherencia = np.array((coherencia1,coherencia2))\n",
    "congruencia(valores_coherencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO CONGRUENCIA\n",
    "# Creamos una lista de valores de coherencia para un conjunto de N muestras\n",
    "alpha_values = [0.8, 0.6, 0.7, 0.9, 0.5]\n",
    "\n",
    "# Calculamos el valor promedio de la coherencia\n",
    "alpha = np.mean(alpha_values)\n",
    "\n",
    "# Creamos una lista de valores de alpha_i para cada instancia de datos\n",
    "alpha_i_values = [0.9, 0.7, 0.6, 0.8, 0.4]\n",
    "\n",
    "# Calculamos el número de instancias de datos\n",
    "N = len(alpha_i_values)\n",
    "\n",
    "# Calculamos la suma de las diferencias cuadráticas entre alpha_i y alpha\n",
    "diff_squares_sum = np.sum((np.array(alpha_i_values) - alpha) ** 2)\n",
    "\n",
    "# Calculamos la métrica Congruencia\n",
    "delta = np.sqrt((diff_squares_sum / N) / alpha)\n",
    "\n",
    "# Imprimimos el valor de la métrica Congruencia\n",
    "print(\"El valor de la métrica Congruencia es:\", delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def selectividad(X, y, model):\n",
    "    \"\"\"\n",
    "    Calcula la métrica de Selectividad para el método LIME.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Matriz de instancias de datos de forma (n, m), donde n es el número de instancias y m es el número de características.\n",
    "        y (ndarray): Vector de etiquetas de forma (n,), donde n es el número de instancias.\n",
    "        model: Modelo de aprendizaje automático ajustado sobre los datos completos.\n",
    "\n",
    "    Returns:\n",
    "        float: Área bajo la curva (AUC) que mide la selectividad al eliminar características una por una.\n",
    "    \"\"\"\n",
    "\n",
    "    n = X.shape[0]  # número de instancias\n",
    "    m = X.shape[1]  # número de características\n",
    "\n",
    "    auc_scores = []  # lista para almacenar los resultados del AUC\n",
    "\n",
    "    # Realiza las predicciones sobre los datos completos\n",
    "    y_pred_base = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Calcula el AUC para el modelo sobre los datos completos\n",
    "    auc_base = roc_auc_score(y, y_pred_base)\n",
    "\n",
    "    # Itera sobre cada característica y calcula el AUC al eliminarla\n",
    "    for i in range(m):\n",
    "        X_copy = X.copy()\n",
    "        X_copy[:, i] = 0  # Establece en cero la i-ésima característica\n",
    "\n",
    "        # Realiza las predicciones con la característica eliminada\n",
    "        y_pred = model.predict_proba(X_copy)[:, 1]\n",
    "\n",
    "        # Calcula el AUC y lo agrega a la lista de resultados\n",
    "        auc_score = roc_auc_score(y, y_pred)\n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "    # Calcula el AUC promedio para la selectividad\n",
    "    auc_selectivity = np.mean(auc_scores)\n",
    "\n",
    "    return auc_selectivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5de2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SELECTIVIDAD\n",
    "# Cargamos el dataset de cáncer de mama de scikit-learn\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Definimos las características y la variable objetivo\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "# Creamos un modelo de regresión logística\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(X, y)\n",
    "\n",
    "# Obtenemos las predicciones del modelo en el conjunto de datos completo\n",
    "y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculamos el AUC para el modelo entrenado en el conjunto de datos completo\n",
    "auc_full = roc_auc_score(y, y_pred)\n",
    "\n",
    "# Ordenamos las características de más a menos relevantes según el modelo\n",
    "idx_sorted = np.argsort(np.abs(model.coef_))[0][::-1]\n",
    "\n",
    "# Creamos una lista para almacenar los AUC para cada característica eliminada\n",
    "auc_scores = []\n",
    "\n",
    "# Iteramos sobre las características de más a menos relevantes según el modelo\n",
    "for i in range(X.shape[1]):\n",
    "    # Establecemos la característica i en cero\n",
    "    X_test = X.copy()\n",
    "    X_test[:, idx_sorted[i]] = 0\n",
    "    \n",
    "    # Obtenemos las predicciones del modelo en el conjunto de datos con la característica i eliminada\n",
    "    y_pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculamos el AUC para el modelo entrenado en el conjunto de datos con la característica i eliminada\n",
    "    auc_test = roc_auc_score(y, y_pred_test)\n",
    "    \n",
    "    # Almacenamos el AUC para la característica i eliminada en la lista de AUC\n",
    "    auc_scores.append(auc_test)\n",
    "\n",
    "# Calculamos la métrica Selectividad como el área bajo la curva ROC para el gráfico de AUC vs características eliminadas\n",
    "selectivity = np.trapz(auc_scores, dx=1)\n",
    "\n",
    "# Imprimimos el valor de la métrica Selectividad\n",
    "print(\"El valor de la métrica Selectividad es:\", selectivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97087be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo RandomForest de evaluación cumple la metrica identidad\n",
      "El modelo Red neuronal de evaluación cumple la metrica identidad\n",
      "El modelo Red neuronal de bikes cumple la metrica identidad\n",
      "El modelo RandomForest de bikes cumple la metrica identidad\n"
     ]
    }
   ],
   "source": [
    "#Comprobaremos la métrica identidad\n",
    "#Para comprobarla recorreremos 256 ejemplos en los cuatro modelos y para cada ejemplo en cada modelo generaremos la explicacion dos veces y comprobaremos que es la misma explicación\n",
    "atributivos = atributos[5553:5809,:]\n",
    "sonIguales = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "if(sonIguales):\n",
    "    print(\"El modelo RandomForest de evaluación cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de evaluación no cumple la métrica identidad\")\n",
    "\n",
    "sonIguales=True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(red_evaluation,x,2,atributos)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "\n",
    "if(sonIguales):\n",
    "    print(\"El modelo Red neuronal de evaluación cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de evaluación no cumple la métrica identidad\")\n",
    "\n",
    "X=attr[17122:17378,:]\n",
    "sonIguales=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    exp2 = explain_model(red_bikes,x,2,attr)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "    \n",
    "if(sonIguales):\n",
    "    print(\"El modelo Red neuronal de bikes cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de bikes no cumple la métrica identidad\")\n",
    "    \n",
    "sonIguales=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    exp2 = explain_model(forest_bikes,x,2,attr)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "    \n",
    "if(sonIguales):\n",
    "    print(\"El modelo RandomForest de bikes cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de bikes no cumple la métrica identidad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ccb9f6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo RandomForest de evaluación cumple la metrica separabilidad\n",
      "El modelo Red neuronal de evaluación cumple la metrica separabilidad\n",
      "El modelo Red neuronal de bikes cumple la metrica separabilidad\n",
      "El modelo RandomForest de bikes cumple la metrica separabilidad\n"
     ]
    }
   ],
   "source": [
    "#Comprobaremos la métrica separabilidad\n",
    "#Para comprobarla recorreremos 256 ejemplos en los cuatro modelos y los comparamos con otro ejemplo\n",
    "ejemplo1=atributos[5552]\n",
    "atributivos = atributos[5553:5809,:]\n",
    "cumpleSeparabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(forest_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo1,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo RandomForest de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "cumpleSeparabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(red_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo1,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "\n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo Red neuronal de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "ejemplo2 = attr[17121]\n",
    "X=attr[17122:17378,:]\n",
    "cumpleSeparabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    exp2 = explain_model(red_bikes,ejemplo2,2,attr)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo2,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo Red neuronal de bikes cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de bikes no cumple la métrica separabilidad\")\n",
    "    \n",
    "cumpleSeparabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo2,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo RandomForest de bikes cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de bikes no cumple la métrica separabilidad\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2455bbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo RandomForest de evaluación cumple la métrica separabilidad\n",
      "El modelo Red neuronal de evaluación cumple la métrica separabilidad\n",
      "El modelo Red neuronal de bikes cumple la métrica estabilidad\n",
      "El modelo RandomForest de bikes cumple la métrica estabilidad\n"
     ]
    }
   ],
   "source": [
    "#Comprobaremos la métrica estabilidad\n",
    "#Para comprobarla recorreremos 256 ejemplos en los cuatro modelos y los comparamos con otro ejemplo, del cual sabemos que hay ejemplos muy similares\n",
    "\n",
    "ejemplo1=atributos[5819]\n",
    "atributivos = atributos[5553:5819,:]\n",
    "cumpleEstabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(forest_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo1,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo RandomForest de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "cumpleEstabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(red_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo1,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "\n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo Red neuronal de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "ejemplo2 = attr[17376]\n",
    "X=attr[17122:17378,:]\n",
    "cumpleEstabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    exp2 = explain_model(red_bikes,ejemplo2,2,attr)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo2,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo Red neuronal de bikes cumple la métrica estabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de bikes no cumple la métrica estabilidad\")\n",
    "    \n",
    "cumpleEstabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo2,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo RandomForest de bikes cumple la métrica estabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de bikes no cumple la métrica estabilidad\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
