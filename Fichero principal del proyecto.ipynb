{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0210de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "#Leemos el csv\n",
    "evaluation = pandas.read_csv('turkiye-student-evaluation_R_Specific.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40fd7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  ...  \\\n",
       "1       1      2          1           0           4   3   3   3   3   3  ...   \n",
       "2       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "3       1      2          1           2           4   5   5   5   5   5  ...   \n",
       "4       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "5       1      2          1           0           1   1   1   1   1   1  ...   \n",
       "6       1      2          1           3           3   4   4   4   4   4  ...   \n",
       "7       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "8       1      2          1           1           3   5   5   5   5   5  ...   \n",
       "9       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "10      1      2          1           4           4   4   4   4   4   4  ...   \n",
       "\n",
       "    Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  \n",
       "1     3    3    3    3    3    3    3    3    3    3  \n",
       "2     3    3    3    3    3    3    3    3    3    3  \n",
       "3     5    5    5    5    5    5    5    5    5    5  \n",
       "4     3    3    3    3    3    3    3    3    3    3  \n",
       "5     1    1    1    1    1    1    1    1    1    1  \n",
       "6     4    4    4    4    4    4    4    4    4    4  \n",
       "7     4    4    4    4    4    4    4    4    4    4  \n",
       "8     5    5    5    5    5    5    5    5    5    5  \n",
       "9     4    4    4    4    4    4    4    4    4    4  \n",
       "10    4    4    4    4    4    4    4    4    4    4  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bien\n",
    "evaluation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9259e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08333333 0.         0.         ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.25       ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.5        ... 1.         1.         1.        ]\n",
      " ...\n",
      " [1.         0.         0.         ... 1.         1.         1.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos \n",
    "atributos = evaluation.loc[:, 'class':'Q27']\n",
    "atributos = atributos.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "atributos = scaler.fit_transform(atributos)\n",
    "print(atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b22a5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 5. ... 5. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "objetivo = evaluation['Q28']\n",
    "objetivo = evaluation['Q28'].to_numpy(dtype=np.float32)\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#objetivo = scaler.fit_transform(objetivo.reshape(-1, 1))\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "141c7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6ff2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()\n",
    "normalizador.adapt(atributos_entrenamiento)\n",
    "red_evaluation = keras.Sequential()\n",
    "red_evaluation.add(keras.layers.Input(shape=(31,)))\n",
    "red_evaluation.add(normalizador)\n",
    "red_evaluation.add(keras.layers.Dense(70, activation='relu'))\n",
    "red_evaluation.add(keras.layers.Dense(70, activation='sigmoid'))\n",
    "red_evaluation.add(keras.layers.Dense(1, activation='linear'))\n",
    "#red_evaluation.add(keras.layers.Lambda(lambda x: x * 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b8a17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 31)               63        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 70)                2240      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,344\n",
      "Trainable params: 7,281\n",
      "Non-trainable params: 63\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_evaluation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3114e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 964us/step - loss: 2.6540 - accuracy: 0.1326 - mae: 1.1152\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 993us/step - loss: 0.4520 - accuracy: 0.1399 - mae: 0.4531\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.1399 - mae: 0.3757\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 994us/step - loss: 0.3340 - accuracy: 0.1399 - mae: 0.3509\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.1399 - mae: 0.3385\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.1399 - mae: 0.3253\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2960 - accuracy: 0.1399 - mae: 0.3178\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2883 - accuracy: 0.1399 - mae: 0.3114\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2819 - accuracy: 0.1399 - mae: 0.3058\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.1399 - mae: 0.3016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a3e7d5ed90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "red_evaluation.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29d4f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 658us/step - loss: 0.2614 - accuracy: 0.1375 - mae: 0.2933\n",
      "0.2613915205001831\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "perdObj = 1.0\n",
    "x=red_evaluation.evaluate(atributos_prueba, objetivo_prueba)\n",
    "while x[0]>perdObj:\n",
    "    red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_evaluation.evaluate(atributos_prueba, objetivo_prueba)\n",
    "    \n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ad4c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.1375 - mae: 0.2933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2613915205001831, 0.13745704293251038, 0.2933053970336914]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_evaluation.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84bc4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 31) for input KerasTensor(type_spec=TensorSpec(shape=(None, 31), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None,).\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Esperado 4: [[3.973354]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Esperado 3: [[2.9804742]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Esperado 3: [[3.1799424]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Esperado 1: [[1.067123]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Esperado 3: [[3.171642]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Esperado 1: [[1.2556722]]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Esperado 1: [[1.067123]]\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "Esperado 5: [[4.783162]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Esperado 5: [[4.779622]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Esperado 1: [[1.0752364]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Esperado 1: [[1.0752364]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "\n",
    "X=atributos[5809]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 4:',predicciones)\n",
    "X=atributos[5810]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5811]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5812]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5813]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5814]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5815]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5816]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos[5817]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos[5818]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5819]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55821bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 0.24193685577884677\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_evaluation = RandomForestRegressor()\n",
    "forest_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "evaluaciones = forest_evaluation.predict(atributos_prueba)\n",
    "mse = mean_squared_error(objetivo_prueba, evaluaciones)\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a83c67dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 4: [4.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 1: [1.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 1: [1.01]\n",
      "Esperado 1: [1.]\n",
      "Esperado 5: [4.97]\n",
      "Esperado 5: [5.]\n",
      "Esperado 1: [1.]\n",
      "Esperado 1: [1.]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "atributos2 = atributos[:, np.newaxis]\n",
    "X=atributos2[5809]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 4:',predicciones)\n",
    "X=atributos2[5810]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5811]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5812]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5813]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5814]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5815]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5816]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos2[5817]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos2[5818]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5819]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "250f3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#Leemos el csv\n",
    "#bikes = pandas.read_csv('hour.csv', header=0)\n",
    "bikes = pandas.read_csv('hour2.csv',header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0073ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0       1   0     1   0        0        6           0           1  0.24   \n",
       "1       1   0     1   1        0        6           0           1  0.22   \n",
       "2       1   0     1   2        0        6           0           1  0.22   \n",
       "3       1   0     1   3        0        6           0           1  0.24   \n",
       "4       1   0     1   4        0        6           0           1  0.24   \n",
       "5       1   0     1   5        0        6           0           2  0.24   \n",
       "6       1   0     1   6        0        6           0           1  0.22   \n",
       "7       1   0     1   7        0        6           0           1  0.20   \n",
       "8       1   0     1   8        0        6           0           1  0.24   \n",
       "9       1   0     1   9        0        6           0           1  0.32   \n",
       "\n",
       "    atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.2879  0.81     0.0000       3          13   16  \n",
       "1  0.2727  0.80     0.0000       8          32   40  \n",
       "2  0.2727  0.80     0.0000       5          27   32  \n",
       "3  0.2879  0.75     0.0000       3          10   13  \n",
       "4  0.2879  0.75     0.0000       0           1    1  \n",
       "5  0.2576  0.75     0.0896       0           1    1  \n",
       "6  0.2727  0.80     0.0000       2           0    2  \n",
       "7  0.2576  0.86     0.0000       1           2    3  \n",
       "8  0.2879  0.75     0.0000       1           7    8  \n",
       "9  0.3485  0.76     0.0000       8           6   14  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bién\n",
    "bikes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890b5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.00817439 0.01467269]\n",
      " [0.         0.         0.         ... 0.         0.02179837 0.03611738]\n",
      " [0.         0.         0.         ... 0.         0.01362398 0.03047404]\n",
      " ...\n",
      " [0.         1.         1.         ... 0.19301751 0.01907357 0.09367946]\n",
      " [0.         1.         1.         ... 0.15786999 0.03542234 0.05417607]\n",
      " [0.         1.         1.         ... 0.15786999 0.03269755 0.04176072]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos y los nomalizamos\n",
    "attr = bikes.loc[:, 'season':'registered']\n",
    "attr = attr.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "attr = scaler.fit_transform(attr)\n",
    "print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e783ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16. 40. 32. ... 90. 61. 49.]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los objetivos\n",
    "obj = bikes['cnt']\n",
    "obj = bikes['cnt'].to_numpy(dtype=np.float32)\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#objetivo = scaler.fit_transform(objetivo.reshape(-1, 1))\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bec2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cogemos un 85% de los datos para entrenar y un 15% de los datos para evaluar el modelo\n",
    "(attr_entrenamiento, attr_prueba,\n",
    " obj_entrenamiento, obj_prueba) = model_selection.train_test_split(\n",
    "    attr, obj, test_size=.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01172681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la red neuronal \n",
    "normalizador = keras.layers.Normalization()\n",
    "normalizador.adapt(attr_entrenamiento)\n",
    "red_bikes = keras.Sequential()\n",
    "red_bikes.add(keras.layers.Input(shape=(14,))) #añadimos la capa de entrada con 14 neuronas\n",
    "red_bikes.add(normalizador)#Aplicamos un normalizador\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(1, activation='linear'))#Necesitamos una capa de salida linear ya que los valores objetivos son lineares\n",
    "#red_bikes.add(keras.layers.Lambda(lambda x: tf.cast(tf.round(x), dtype=tf.int32)))\n",
    "#red_bikes.add(keras.layers.Lambda(lambda x: round(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9f0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 14)               29        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               1500      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,730\n",
      "Trainable params: 11,701\n",
      "Non-trainable params: 29\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Vemos un resumen de la red\n",
    "red_bikes.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e5d4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 11486.8076 - accuracy: 0.0093 - mae: 74.2236 \n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1629.2836 - accuracy: 0.0094 - mae: 30.0533\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 995.9356 - accuracy: 0.0094 - mae: 21.1480\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 547.6118 - accuracy: 0.0094 - mae: 17.0715\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 978us/step - loss: 420.9388 - accuracy: 0.0094 - mae: 15.0551\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 241.7918 - accuracy: 0.0094 - mae: 11.8898\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 963us/step - loss: 173.7476 - accuracy: 0.0094 - mae: 9.3768\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 975us/step - loss: 267.7085 - accuracy: 0.0094 - mae: 12.0059\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 105.6550 - accuracy: 0.0094 - mae: 7.5048\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 974us/step - loss: 134.2660 - accuracy: 0.0094 - mae: 8.8073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a3e3a84850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compilamos y entrenamos la red neuronal, buscamos minimizar la función de perdida\n",
    "red_bikes.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa4bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 642us/step - loss: 377.4158 - accuracy: 0.0063 - mae: 15.9515\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 965us/step - loss: 164.1133 - accuracy: 0.0094 - mae: 7.6483\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 938us/step - loss: 161.7738 - accuracy: 0.0094 - mae: 10.0794\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 980us/step - loss: 89.4426 - accuracy: 0.0094 - mae: 7.4439\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 951us/step - loss: 80.7528 - accuracy: 0.0094 - mae: 6.4921\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 961us/step - loss: 130.1151 - accuracy: 0.0094 - mae: 8.2472\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 958us/step - loss: 123.1936 - accuracy: 0.0094 - mae: 8.9086\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 43.6097 - accuracy: 0.0094 - mae: 5.0640\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 958us/step - loss: 127.2874 - accuracy: 0.0094 - mae: 9.0824\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 973us/step - loss: 58.9297 - accuracy: 0.0094 - mae: 5.9028\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 976us/step - loss: 97.0428 - accuracy: 0.0094 - mae: 7.0357\n",
      "55/55 [==============================] - 0s 698us/step - loss: 102.0826 - accuracy: 0.0063 - mae: 5.0659\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 988us/step - loss: 45.6761 - accuracy: 0.0094 - mae: 4.7471\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 932us/step - loss: 57.7782 - accuracy: 0.0094 - mae: 5.9607\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 959us/step - loss: 39.2925 - accuracy: 0.0094 - mae: 4.6049\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 974us/step - loss: 13.7672 - accuracy: 0.0094 - mae: 2.4648\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 964us/step - loss: 49.5480 - accuracy: 0.0094 - mae: 5.5091\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 51.0983 - accuracy: 0.0094 - mae: 5.4436\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 65.5121 - accuracy: 0.0094 - mae: 6.3904\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 42.8696 - accuracy: 0.0094 - mae: 4.8350\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 947us/step - loss: 25.4527 - accuracy: 0.0094 - mae: 3.8101\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 938us/step - loss: 47.2182 - accuracy: 0.0094 - mae: 5.4157\n",
      "55/55 [==============================] - 0s 753us/step - loss: 43.2222 - accuracy: 0.0063 - mae: 5.1819\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 950us/step - loss: 17.9184 - accuracy: 0.0094 - mae: 2.9427\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 908us/step - loss: 39.5126 - accuracy: 0.0094 - mae: 4.9888\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 44.0158 - accuracy: 0.0094 - mae: 4.8877\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 976us/step - loss: 24.8649 - accuracy: 0.0094 - mae: 3.3932\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 40.9990 - accuracy: 0.0094 - mae: 4.7887\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 26.8802 - accuracy: 0.0094 - mae: 3.8319\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 947us/step - loss: 47.1530 - accuracy: 0.0094 - mae: 5.1666\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 979us/step - loss: 52.6589 - accuracy: 0.0094 - mae: 5.4215\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 943us/step - loss: 8.2859 - accuracy: 0.0094 - mae: 1.9840\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 958us/step - loss: 55.3606 - accuracy: 0.0094 - mae: 5.5777\n",
      "55/55 [==============================] - 0s 602us/step - loss: 240.8235 - accuracy: 0.0063 - mae: 11.7600\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 983us/step - loss: 40.3605 - accuracy: 0.0094 - mae: 4.0440\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 959us/step - loss: 18.1799 - accuracy: 0.0094 - mae: 3.2666\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 993us/step - loss: 16.7330 - accuracy: 0.0094 - mae: 3.0408\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 985us/step - loss: 12.1649 - accuracy: 0.0094 - mae: 2.6046\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 991us/step - loss: 11.5177 - accuracy: 0.0094 - mae: 2.3713\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 984us/step - loss: 25.5052 - accuracy: 0.0094 - mae: 4.0034\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 997us/step - loss: 5.7502 - accuracy: 0.0094 - mae: 1.6694\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 970us/step - loss: 28.9179 - accuracy: 0.0094 - mae: 4.3093\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 962us/step - loss: 5.7841 - accuracy: 0.0094 - mae: 1.6252\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 987us/step - loss: 24.7765 - accuracy: 0.0094 - mae: 3.6943\n",
      "55/55 [==============================] - 0s 559us/step - loss: 104.7602 - accuracy: 0.0063 - mae: 8.1099\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 964us/step - loss: 22.2371 - accuracy: 0.0094 - mae: 3.3102\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 938us/step - loss: 30.5539 - accuracy: 0.0094 - mae: 3.9048\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 940us/step - loss: 22.0708 - accuracy: 0.0094 - mae: 3.4029\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 953us/step - loss: 8.1008 - accuracy: 0.0094 - mae: 1.9434\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 953us/step - loss: 25.1423 - accuracy: 0.0094 - mae: 3.3047\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 948us/step - loss: 5.5181 - accuracy: 0.0094 - mae: 1.7042\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 968us/step - loss: 49.6721 - accuracy: 0.0094 - mae: 5.3276\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 955us/step - loss: 9.9579 - accuracy: 0.0094 - mae: 2.4154\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 948us/step - loss: 22.9049 - accuracy: 0.0094 - mae: 3.7968\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 941us/step - loss: 22.4854 - accuracy: 0.0094 - mae: 3.7040\n",
      "55/55 [==============================] - 0s 868us/step - loss: 34.5094 - accuracy: 0.0063 - mae: 4.6524\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 956us/step - loss: 17.6803 - accuracy: 0.0094 - mae: 3.4381\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 13.3899 - accuracy: 0.0094 - mae: 2.8711\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 949us/step - loss: 22.2235 - accuracy: 0.0094 - mae: 3.7299\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 986us/step - loss: 26.3262 - accuracy: 0.0094 - mae: 2.9823\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 970us/step - loss: 8.8563 - accuracy: 0.0094 - mae: 2.1590\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 960us/step - loss: 21.8020 - accuracy: 0.0094 - mae: 3.7308\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 26.3821 - accuracy: 0.0094 - mae: 3.9638\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 950us/step - loss: 7.9782 - accuracy: 0.0094 - mae: 2.1630\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 945us/step - loss: 10.1274 - accuracy: 0.0094 - mae: 2.4719\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 947us/step - loss: 17.1881 - accuracy: 0.0094 - mae: 3.2059\n",
      "55/55 [==============================] - 0s 593us/step - loss: 23.4377 - accuracy: 0.0063 - mae: 3.7965\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 11.8786 - accuracy: 0.0094 - mae: 2.7348\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 932us/step - loss: 6.2133 - accuracy: 0.0094 - mae: 1.8822\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 20.8523 - accuracy: 0.0094 - mae: 3.3417\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 12.5096 - accuracy: 0.0094 - mae: 2.5892\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 1ms/step - loss: 9.2684 - accuracy: 0.0094 - mae: 2.1162\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.3419 - accuracy: 0.0094 - mae: 2.8500\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 14.7151 - accuracy: 0.0094 - mae: 3.0179\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 13.6335 - accuracy: 0.0094 - mae: 2.8166\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 22.7489 - accuracy: 0.0094 - mae: 3.8766\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 12.9068 - accuracy: 0.0094 - mae: 2.7309\n",
      "55/55 [==============================] - 0s 790us/step - loss: 6.7037 - accuracy: 0.0063 - mae: 2.0025\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 5.6421 - accuracy: 0.0094 - mae: 1.8327\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 11.5584 - accuracy: 0.0094 - mae: 2.7929\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 10.2648 - accuracy: 0.0094 - mae: 2.4929\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 9.7651 - accuracy: 0.0094 - mae: 2.4468\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 17.5209 - accuracy: 0.0094 - mae: 3.3894\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 10.7623 - accuracy: 0.0094 - mae: 2.5377\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 17.9274 - accuracy: 0.0094 - mae: 3.3415\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 5.5885 - accuracy: 0.0094 - mae: 1.4928\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 19.0081 - accuracy: 0.0094 - mae: 3.2840\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 2.4517 - accuracy: 0.0094 - mae: 1.1017\n",
      "55/55 [==============================] - 0s 680us/step - loss: 2.8280 - accuracy: 0.0063 - mae: 1.1540\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 22.9774 - accuracy: 0.0094 - mae: 3.6620\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.2133 - accuracy: 0.0094 - mae: 1.7866\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 18.8690 - accuracy: 0.0094 - mae: 3.3412\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 2.6209 - accuracy: 0.0094 - mae: 1.1604\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 8.4132 - accuracy: 0.0094 - mae: 2.1706\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 6.8013 - accuracy: 0.0094 - mae: 2.0714\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 942us/step - loss: 5.3484 - accuracy: 0.0094 - mae: 1.8558\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 978us/step - loss: 13.8853 - accuracy: 0.0094 - mae: 3.0903\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 924us/step - loss: 11.4272 - accuracy: 0.0094 - mae: 2.7975\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 932us/step - loss: 4.8321 - accuracy: 0.0094 - mae: 1.5809\n",
      "55/55 [==============================] - 0s 579us/step - loss: 4.7432 - accuracy: 0.0063 - mae: 1.3899\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 908us/step - loss: 14.3302 - accuracy: 0.0094 - mae: 2.9824\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 5.0044 - accuracy: 0.0094 - mae: 1.6351\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 980us/step - loss: 14.7321 - accuracy: 0.0094 - mae: 3.1665\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 955us/step - loss: 9.3914 - accuracy: 0.0094 - mae: 2.4736\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 913us/step - loss: 15.2098 - accuracy: 0.0094 - mae: 3.2625\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 4.9539 - accuracy: 0.0094 - mae: 1.7328\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 924us/step - loss: 2.8456 - accuracy: 0.0094 - mae: 1.2081\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 10.2663 - accuracy: 0.0094 - mae: 2.6204\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 978us/step - loss: 15.6152 - accuracy: 0.0094 - mae: 3.2910\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 971us/step - loss: 5.9663 - accuracy: 0.0094 - mae: 1.7906\n",
      "55/55 [==============================] - 0s 799us/step - loss: 8.9581 - accuracy: 0.0063 - mae: 2.2521\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 948us/step - loss: 6.3204 - accuracy: 0.0094 - mae: 1.9880\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 953us/step - loss: 16.6559 - accuracy: 0.0094 - mae: 3.2888\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 947us/step - loss: 9.8250 - accuracy: 0.0094 - mae: 2.3262\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 899us/step - loss: 2.0115 - accuracy: 0.0094 - mae: 1.0283\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 14.4726 - accuracy: 0.0094 - mae: 3.0108\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 924us/step - loss: 5.2982 - accuracy: 0.0094 - mae: 1.7333\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 919us/step - loss: 10.2133 - accuracy: 0.0094 - mae: 2.6134\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 922us/step - loss: 10.6024 - accuracy: 0.0094 - mae: 2.6837\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 966us/step - loss: 2.4359 - accuracy: 0.0094 - mae: 1.1151\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 959us/step - loss: 6.4288 - accuracy: 0.0094 - mae: 1.8356\n",
      "55/55 [==============================] - 0s 641us/step - loss: 4.1420 - accuracy: 0.0063 - mae: 1.1526\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 912us/step - loss: 8.3414 - accuracy: 0.0094 - mae: 2.2508\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 910us/step - loss: 6.5363 - accuracy: 0.0094 - mae: 2.0367\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 899us/step - loss: 5.9045 - accuracy: 0.0094 - mae: 1.9815\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 946us/step - loss: 16.0084 - accuracy: 0.0094 - mae: 3.0906\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 909us/step - loss: 2.6333 - accuracy: 0.0094 - mae: 1.1654\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 13.4013 - accuracy: 0.0094 - mae: 2.9293\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 10.9831 - accuracy: 0.0094 - mae: 2.6030\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 968us/step - loss: 9.0287 - accuracy: 0.0094 - mae: 2.4215\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 5.1507 - accuracy: 0.0094 - mae: 1.6781\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 901us/step - loss: 5.7668 - accuracy: 0.0094 - mae: 1.9270\n",
      "55/55 [==============================] - 0s 580us/step - loss: 21.1664 - accuracy: 0.0063 - mae: 3.3660\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 906us/step - loss: 13.8043 - accuracy: 0.0094 - mae: 2.4034\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 900us/step - loss: 1.7563 - accuracy: 0.0094 - mae: 0.9838\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 6.6336 - accuracy: 0.0094 - mae: 1.9044\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 972us/step - loss: 17.5951 - accuracy: 0.0094 - mae: 3.4812\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 950us/step - loss: 4.5061 - accuracy: 0.0094 - mae: 1.6863\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 910us/step - loss: 8.6753 - accuracy: 0.0094 - mae: 2.4649\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 907us/step - loss: 8.0018 - accuracy: 0.0094 - mae: 2.2750\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 925us/step - loss: 4.2609 - accuracy: 0.0094 - mae: 1.5930\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 9.3622 - accuracy: 0.0094 - mae: 2.5879\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 925us/step - loss: 7.2342 - accuracy: 0.0094 - mae: 2.2586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 880us/step - loss: 14.9664 - accuracy: 0.0063 - mae: 2.4870\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 922us/step - loss: 8.0922 - accuracy: 0.0094 - mae: 2.3458\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 917us/step - loss: 5.1750 - accuracy: 0.0094 - mae: 1.8315\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 900us/step - loss: 4.5158 - accuracy: 0.0094 - mae: 1.7150\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 892us/step - loss: 6.2483 - accuracy: 0.0094 - mae: 1.9929\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 912us/step - loss: 1.4014 - accuracy: 0.0094 - mae: 0.8404\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 919us/step - loss: 10.9452 - accuracy: 0.0094 - mae: 2.7594\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 899us/step - loss: 2.3724 - accuracy: 0.0094 - mae: 1.1623\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 900us/step - loss: 6.2497 - accuracy: 0.0094 - mae: 2.0473\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 7.9185 - accuracy: 0.0094 - mae: 2.3408\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 977us/step - loss: 1.7593 - accuracy: 0.0094 - mae: 1.0059\n",
      "55/55 [==============================] - 0s 581us/step - loss: 2.1383 - accuracy: 0.0063 - mae: 1.1044\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 896us/step - loss: 1.8602 - accuracy: 0.0094 - mae: 1.0322\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 901us/step - loss: 9.8493 - accuracy: 0.0094 - mae: 2.6103\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 22.0730 - accuracy: 0.0094 - mae: 3.3127\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 966us/step - loss: 3.6206 - accuracy: 0.0094 - mae: 1.5262\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 977us/step - loss: 10.2405 - accuracy: 0.0094 - mae: 2.5893\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 973us/step - loss: 2.3556 - accuracy: 0.0094 - mae: 1.1238\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 973us/step - loss: 9.2480 - accuracy: 0.0094 - mae: 2.4376\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 975us/step - loss: 1.2512 - accuracy: 0.0094 - mae: 0.8227\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.5887 - accuracy: 0.0094 - mae: 0.9264\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.7335 - accuracy: 0.0094 - mae: 2.3811\n",
      "55/55 [==============================] - 0s 931us/step - loss: 16.6233 - accuracy: 0.0063 - mae: 3.4947\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.3708 - accuracy: 0.0094 - mae: 2.2552\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 984us/step - loss: 4.7018 - accuracy: 0.0094 - mae: 1.7003\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 4.8024 - accuracy: 0.0094 - mae: 1.7467\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 4.9831 - accuracy: 0.0094 - mae: 1.7865\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 937us/step - loss: 5.6962 - accuracy: 0.0094 - mae: 1.9708\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 1.2676 - accuracy: 0.0094 - mae: 0.8277\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 947us/step - loss: 3.2884 - accuracy: 0.0094 - mae: 1.3532\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 6.6680 - accuracy: 0.0094 - mae: 2.2130\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 971us/step - loss: 9.9454 - accuracy: 0.0094 - mae: 2.6091\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 952us/step - loss: 11.2262 - accuracy: 0.0094 - mae: 2.7167\n",
      "55/55 [==============================] - 0s 712us/step - loss: 18.0299 - accuracy: 0.0063 - mae: 3.4773\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 915us/step - loss: 7.7266 - accuracy: 0.0094 - mae: 2.1397\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 1.1264 - accuracy: 0.0094 - mae: 0.7744\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 2.6098 - accuracy: 0.0094 - mae: 1.1888\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.1852 - accuracy: 0.0094 - mae: 2.0058\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 5.3858 - accuracy: 0.0094 - mae: 1.8823\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 9.4157 - accuracy: 0.0094 - mae: 2.6212\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 973us/step - loss: 10.0910 - accuracy: 0.0094 - mae: 2.5958\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 940us/step - loss: 2.7240 - accuracy: 0.0094 - mae: 1.3094\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 3.2407 - accuracy: 0.0094 - mae: 1.4629\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.2027 - accuracy: 0.0094 - mae: 2.0927\n",
      "55/55 [==============================] - 0s 608us/step - loss: 2.1547 - accuracy: 0.0063 - mae: 1.0397\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 943us/step - loss: 0.9779 - accuracy: 0.0094 - mae: 0.7302\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.0957 - accuracy: 0.0094 - mae: 0.7612\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 4.9785 - accuracy: 0.0094 - mae: 1.7502\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 13.2773 - accuracy: 0.0094 - mae: 3.0558\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 988us/step - loss: 5.5998 - accuracy: 0.0094 - mae: 1.7532\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 3.8295 - accuracy: 0.0094 - mae: 1.5249\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 947us/step - loss: 11.3472 - accuracy: 0.0094 - mae: 2.8342\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 877us/step - loss: 6.3351 - accuracy: 0.0094 - mae: 2.1254\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.5934 - accuracy: 0.0094 - mae: 1.9668\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.1782 - accuracy: 0.0094 - mae: 2.1305\n",
      "55/55 [==============================] - 0s 834us/step - loss: 6.7059 - accuracy: 0.0063 - mae: 1.9366\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 941us/step - loss: 2.6657 - accuracy: 0.0094 - mae: 1.2240\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 972us/step - loss: 5.5010 - accuracy: 0.0094 - mae: 1.9088\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 949us/step - loss: 2.7576 - accuracy: 0.0094 - mae: 1.2925\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 902us/step - loss: 2.9702 - accuracy: 0.0094 - mae: 1.3781\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 5.1731 - accuracy: 0.0094 - mae: 1.8982\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 956us/step - loss: 1.3615 - accuracy: 0.0094 - mae: 0.8780\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 8.3815 - accuracy: 0.0094 - mae: 2.1100\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 925us/step - loss: 13.9447 - accuracy: 0.0094 - mae: 2.6240\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 1.2581 - accuracy: 0.0094 - mae: 0.8354\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 943us/step - loss: 2.0732 - accuracy: 0.0094 - mae: 1.1234\n",
      "55/55 [==============================] - 0s 799us/step - loss: 1.9838 - accuracy: 0.0063 - mae: 0.8657\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 928us/step - loss: 5.7783 - accuracy: 0.0094 - mae: 2.0003\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 920us/step - loss: 4.5892 - accuracy: 0.0094 - mae: 1.7178\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 1.9016 - accuracy: 0.0094 - mae: 0.9981\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 908us/step - loss: 2.0372 - accuracy: 0.0094 - mae: 1.1098\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 925us/step - loss: 8.3793 - accuracy: 0.0094 - mae: 2.2609\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 928us/step - loss: 1.1540 - accuracy: 0.0094 - mae: 0.8044\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 942us/step - loss: 8.0059 - accuracy: 0.0094 - mae: 2.3950\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 970us/step - loss: 1.1105 - accuracy: 0.0094 - mae: 0.7686\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 954us/step - loss: 4.8057 - accuracy: 0.0094 - mae: 1.7909\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 6.8960 - accuracy: 0.0094 - mae: 2.1833\n",
      "55/55 [==============================] - 0s 581us/step - loss: 10.9192 - accuracy: 0.0063 - mae: 2.5017\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 931us/step - loss: 1.6516 - accuracy: 0.0094 - mae: 0.9264\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 959us/step - loss: 2.3998 - accuracy: 0.0094 - mae: 1.2286\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.8011 - accuracy: 0.0094 - mae: 2.3872\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 3.6105 - accuracy: 0.0094 - mae: 1.5727\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 917us/step - loss: 2.7196 - accuracy: 0.0094 - mae: 1.2515\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 919us/step - loss: 6.5744 - accuracy: 0.0094 - mae: 2.1563\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 958us/step - loss: 3.6383 - accuracy: 0.0094 - mae: 1.4157\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 953us/step - loss: 1.2206 - accuracy: 0.0094 - mae: 0.8469\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 7.9027 - accuracy: 0.0094 - mae: 2.3187\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.6780 - accuracy: 0.0094 - mae: 1.9611\n",
      "55/55 [==============================] - 0s 714us/step - loss: 2.5151 - accuracy: 0.0063 - mae: 1.1687\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 930us/step - loss: 1.6250 - accuracy: 0.0094 - mae: 1.0158\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 974us/step - loss: 1.6676 - accuracy: 0.0094 - mae: 1.0224\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.6989 - accuracy: 0.0094 - mae: 2.2588\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.7105 - accuracy: 0.0094 - mae: 2.4905\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.9928 - accuracy: 0.0094 - mae: 1.1116\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 916us/step - loss: 2.7537 - accuracy: 0.0094 - mae: 1.3807\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 953us/step - loss: 4.4947 - accuracy: 0.0094 - mae: 1.7508\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 977us/step - loss: 6.1814 - accuracy: 0.0094 - mae: 2.0870\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.8333 - accuracy: 0.0094 - mae: 1.0520\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 960us/step - loss: 1.5268 - accuracy: 0.0094 - mae: 0.9523\n",
      "55/55 [==============================] - 0s 582us/step - loss: 3.9090 - accuracy: 0.0063 - mae: 1.5729\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 924us/step - loss: 4.2567 - accuracy: 0.0094 - mae: 1.7598\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 959us/step - loss: 1.6208 - accuracy: 0.0094 - mae: 0.9884\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 6.3187 - accuracy: 0.0094 - mae: 2.0236\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.5683 - accuracy: 0.0094 - mae: 0.9906\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.4355 - accuracy: 0.0094 - mae: 0.9150\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 4.8878 - accuracy: 0.0094 - mae: 1.7086\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 3.8228 - accuracy: 0.0094 - mae: 1.6760\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 914us/step - loss: 4.5641 - accuracy: 0.0094 - mae: 1.7775\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 943us/step - loss: 1.8796 - accuracy: 0.0094 - mae: 1.0764\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 949us/step - loss: 1.7461 - accuracy: 0.0094 - mae: 0.9389\n",
      "55/55 [==============================] - 0s 733us/step - loss: 1.6842 - accuracy: 0.0063 - mae: 0.8157\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 938us/step - loss: 1.8184 - accuracy: 0.0094 - mae: 1.0395\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 911us/step - loss: 8.2815 - accuracy: 0.0094 - mae: 2.4757\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 928us/step - loss: 4.4156 - accuracy: 0.0094 - mae: 1.5891\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 932us/step - loss: 0.7280 - accuracy: 0.0094 - mae: 0.6409\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 1.6953 - accuracy: 0.0094 - mae: 1.0197\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 973us/step - loss: 8.6037 - accuracy: 0.0094 - mae: 2.3058\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 2.9792 - accuracy: 0.0094 - mae: 1.3642\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 1.8853 - accuracy: 0.0094 - mae: 1.0951\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 916us/step - loss: 5.0437 - accuracy: 0.0094 - mae: 1.8805\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 940us/step - loss: 3.5475 - accuracy: 0.0094 - mae: 1.5751\n",
      "55/55 [==============================] - 0s 694us/step - loss: 23.2583 - accuracy: 0.0063 - mae: 3.7268\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 987us/step - loss: 9.5786 - accuracy: 0.0094 - mae: 2.3776\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 0.8547 - accuracy: 0.0094 - mae: 0.6863\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 971us/step - loss: 2.4418 - accuracy: 0.0094 - mae: 1.1988\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 958us/step - loss: 3.7685 - accuracy: 0.0094 - mae: 1.5410\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 929us/step - loss: 2.4278 - accuracy: 0.0094 - mae: 1.2957\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 919us/step - loss: 0.8966 - accuracy: 0.0094 - mae: 0.7191\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 949us/step - loss: 1.7130 - accuracy: 0.0094 - mae: 0.9852\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 928us/step - loss: 9.0215 - accuracy: 0.0094 - mae: 2.4724\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 940us/step - loss: 6.9474 - accuracy: 0.0094 - mae: 2.0390\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 7.3376 - accuracy: 0.0094 - mae: 2.3452\n",
      "55/55 [==============================] - 0s 657us/step - loss: 5.7699 - accuracy: 0.0063 - mae: 1.9420\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 916us/step - loss: 1.3992 - accuracy: 0.0094 - mae: 0.9285\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 4.8733 - accuracy: 0.0094 - mae: 1.8806\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 2.5200 - accuracy: 0.0094 - mae: 1.2535\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 932us/step - loss: 4.6773 - accuracy: 0.0094 - mae: 1.8401\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 3.2338 - accuracy: 0.0094 - mae: 1.4741\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 6.2190 - accuracy: 0.0094 - mae: 2.0250\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 986us/step - loss: 3.6474 - accuracy: 0.0094 - mae: 1.6492\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 5.0530 - accuracy: 0.0094 - mae: 1.9270\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 961us/step - loss: 1.6079 - accuracy: 0.0094 - mae: 0.8897\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 940us/step - loss: 0.9121 - accuracy: 0.0094 - mae: 0.7292\n",
      "55/55 [==============================] - 0s 853us/step - loss: 3.5567 - accuracy: 0.0063 - mae: 1.3832\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 936us/step - loss: 4.3342 - accuracy: 0.0094 - mae: 1.7518\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 5.3329 - accuracy: 0.0094 - mae: 1.9160\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 980us/step - loss: 0.5484 - accuracy: 0.0094 - mae: 0.5526\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 919us/step - loss: 0.8336 - accuracy: 0.0094 - mae: 0.7010\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 946us/step - loss: 4.9876 - accuracy: 0.0094 - mae: 1.9049\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 936us/step - loss: 3.7059 - accuracy: 0.0094 - mae: 1.6258\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 961us/step - loss: 3.7001 - accuracy: 0.0094 - mae: 1.6205\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 7.3628 - accuracy: 0.0094 - mae: 2.2585\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.3085 - accuracy: 0.0094 - mae: 0.8918\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 974us/step - loss: 3.8237 - accuracy: 0.0094 - mae: 1.4905\n",
      "55/55 [==============================] - 0s 582us/step - loss: 6.7392 - accuracy: 0.0063 - mae: 2.1891\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 975us/step - loss: 6.9748 - accuracy: 0.0094 - mae: 2.2469\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 986us/step - loss: 3.3430 - accuracy: 0.0094 - mae: 1.4698\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 956us/step - loss: 2.2324 - accuracy: 0.0094 - mae: 1.1298\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 0.7601 - accuracy: 0.0094 - mae: 0.6645\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 925us/step - loss: 0.9889 - accuracy: 0.0094 - mae: 0.7592\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 907us/step - loss: 4.9284 - accuracy: 0.0094 - mae: 1.8678\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 940us/step - loss: 5.2922 - accuracy: 0.0094 - mae: 1.9706\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 1.1870 - accuracy: 0.0094 - mae: 0.8289\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 917us/step - loss: 0.7814 - accuracy: 0.0094 - mae: 0.6705\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 920us/step - loss: 4.5102 - accuracy: 0.0094 - mae: 1.7177\n",
      "55/55 [==============================] - 0s 579us/step - loss: 9.1360 - accuracy: 0.0063 - mae: 2.3038\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 947us/step - loss: 6.4517 - accuracy: 0.0094 - mae: 2.2271\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 931us/step - loss: 1.2933 - accuracy: 0.0094 - mae: 0.9072\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 4.2792 - accuracy: 0.0094 - mae: 1.7217\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 930us/step - loss: 1.5278 - accuracy: 0.0094 - mae: 0.9907\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 917us/step - loss: 1.1905 - accuracy: 0.0094 - mae: 0.8404\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 3.8006 - accuracy: 0.0094 - mae: 1.6810\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 919us/step - loss: 2.9778 - accuracy: 0.0094 - mae: 1.4008\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 942us/step - loss: 1.8040 - accuracy: 0.0094 - mae: 1.0852\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.8397 - accuracy: 0.0094 - mae: 0.6755\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 1.1827 - accuracy: 0.0094 - mae: 0.8852\n",
      "55/55 [==============================] - 0s 689us/step - loss: 1.4351 - accuracy: 0.0063 - mae: 0.7721\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 3.8010 - accuracy: 0.0094 - mae: 1.4905\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 897us/step - loss: 2.9026 - accuracy: 0.0094 - mae: 1.4411\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 5.2806 - accuracy: 0.0094 - mae: 1.9440\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 3.7577 - accuracy: 0.0094 - mae: 1.6406\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 1.2453 - accuracy: 0.0094 - mae: 0.8834\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 2.9211 - accuracy: 0.0094 - mae: 1.4392\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 1.7173 - accuracy: 0.0094 - mae: 1.0632\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 965us/step - loss: 5.1545 - accuracy: 0.0094 - mae: 1.9200\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 919us/step - loss: 0.9923 - accuracy: 0.0094 - mae: 0.7510\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 2.6160 - accuracy: 0.0094 - mae: 1.2655\n",
      "55/55 [==============================] - 0s 577us/step - loss: 4.8166 - accuracy: 0.0063 - mae: 1.7533\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 5.3220 - accuracy: 0.0094 - mae: 2.0104\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 1.8357 - accuracy: 0.0094 - mae: 1.1172\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 965us/step - loss: 3.2312 - accuracy: 0.0094 - mae: 1.5634\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 943us/step - loss: 7.3912 - accuracy: 0.0094 - mae: 2.3756\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 942us/step - loss: 2.8900 - accuracy: 0.0094 - mae: 1.4276\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 929us/step - loss: 3.0087 - accuracy: 0.0094 - mae: 1.4535\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 936us/step - loss: 3.2571 - accuracy: 0.0094 - mae: 1.4518\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 1.8283 - accuracy: 0.0094 - mae: 1.1361\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 2.2651 - accuracy: 0.0094 - mae: 1.2650\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 919us/step - loss: 1.4220 - accuracy: 0.0094 - mae: 0.9463\n",
      "55/55 [==============================] - 0s 584us/step - loss: 9.3313 - accuracy: 0.0063 - mae: 2.5021\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 919us/step - loss: 3.4302 - accuracy: 0.0094 - mae: 1.6028\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 924us/step - loss: 5.9005 - accuracy: 0.0094 - mae: 2.0794\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 925us/step - loss: 6.0959 - accuracy: 0.0094 - mae: 1.9141\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 915us/step - loss: 1.4957 - accuracy: 0.0094 - mae: 0.9691\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 925us/step - loss: 0.4926 - accuracy: 0.0094 - mae: 0.5337\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 909us/step - loss: 0.8265 - accuracy: 0.0094 - mae: 0.7208\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 4.2579 - accuracy: 0.0094 - mae: 1.7635\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 936us/step - loss: 0.8501 - accuracy: 0.0094 - mae: 0.5885\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 970us/step - loss: 0.8342 - accuracy: 0.0094 - mae: 0.6721\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 960us/step - loss: 4.6334 - accuracy: 0.0094 - mae: 1.8831\n",
      "55/55 [==============================] - 0s 879us/step - loss: 12.3310 - accuracy: 0.0063 - mae: 2.6974\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 3.5133 - accuracy: 0.0094 - mae: 1.5792\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 5.4110 - accuracy: 0.0094 - mae: 2.0285\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 936us/step - loss: 0.7009 - accuracy: 0.0094 - mae: 0.6195\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 910us/step - loss: 0.4202 - accuracy: 0.0094 - mae: 0.4923\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 0.5907 - accuracy: 0.0094 - mae: 0.5998\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 970us/step - loss: 2.0999 - accuracy: 0.0094 - mae: 1.1738\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 937us/step - loss: 3.2906 - accuracy: 0.0094 - mae: 1.5468\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 3.7978 - accuracy: 0.0094 - mae: 1.6746\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 908us/step - loss: 1.7980 - accuracy: 0.0094 - mae: 1.0813\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 932us/step - loss: 3.9297 - accuracy: 0.0094 - mae: 1.7038\n",
      "55/55 [==============================] - 0s 864us/step - loss: 3.1774 - accuracy: 0.0063 - mae: 1.2880\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 936us/step - loss: 0.6758 - accuracy: 0.0094 - mae: 0.6259\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 929us/step - loss: 0.4720 - accuracy: 0.0094 - mae: 0.5225\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 976us/step - loss: 4.0933 - accuracy: 0.0094 - mae: 1.7341\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 949us/step - loss: 5.0508 - accuracy: 0.0094 - mae: 1.9607\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 2.2537 - accuracy: 0.0094 - mae: 1.2634\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 936us/step - loss: 1.2289 - accuracy: 0.0094 - mae: 0.8966\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 2.6211 - accuracy: 0.0094 - mae: 1.3248\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 5.0272 - accuracy: 0.0094 - mae: 1.9325\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 956us/step - loss: 2.5790 - accuracy: 0.0094 - mae: 1.3197\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 941us/step - loss: 2.0290 - accuracy: 0.0094 - mae: 1.1839\n",
      "55/55 [==============================] - 0s 685us/step - loss: 4.0648 - accuracy: 0.0063 - mae: 1.5161\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 924us/step - loss: 7.5987 - accuracy: 0.0094 - mae: 2.3602\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 1.1827 - accuracy: 0.0094 - mae: 0.7974\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 938us/step - loss: 1.6604 - accuracy: 0.0094 - mae: 1.0794\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 967us/step - loss: 2.8726 - accuracy: 0.0094 - mae: 1.3489\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 3.4972 - accuracy: 0.0094 - mae: 1.5327\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 940us/step - loss: 1.2177 - accuracy: 0.0094 - mae: 0.8861\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 4.3794 - accuracy: 0.0094 - mae: 1.8105\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 1.3519 - accuracy: 0.0094 - mae: 0.8726\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 972us/step - loss: 2.3977 - accuracy: 0.0094 - mae: 1.2315\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 981us/step - loss: 4.1049 - accuracy: 0.0094 - mae: 1.7304\n",
      "55/55 [==============================] - 0s 623us/step - loss: 11.9723 - accuracy: 0.0063 - mae: 2.7734\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 913us/step - loss: 4.5498 - accuracy: 0.0094 - mae: 1.8600\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 910us/step - loss: 1.4103 - accuracy: 0.0094 - mae: 0.9284\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 0.6146 - accuracy: 0.0094 - mae: 0.6106\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 928us/step - loss: 0.9627 - accuracy: 0.0094 - mae: 0.7921\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 2.2071 - accuracy: 0.0094 - mae: 1.2664\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 921us/step - loss: 8.0316 - accuracy: 0.0092 - mae: 2.3637\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 916us/step - loss: 2.2244 - accuracy: 0.0094 - mae: 1.2672\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 3.1672 - accuracy: 0.0094 - mae: 1.5229\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 951us/step - loss: 1.4292 - accuracy: 0.0094 - mae: 0.9785\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 956us/step - loss: 1.1321 - accuracy: 0.0094 - mae: 0.8504\n",
      "55/55 [==============================] - 0s 588us/step - loss: 5.0782 - accuracy: 0.0063 - mae: 1.8085\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 964us/step - loss: 5.5517 - accuracy: 0.0094 - mae: 2.0598\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 929us/step - loss: 0.5540 - accuracy: 0.0094 - mae: 0.5658\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 958us/step - loss: 0.4432 - accuracy: 0.0094 - mae: 0.5045\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 996us/step - loss: 2.2006 - accuracy: 0.0094 - mae: 1.0877\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 942us/step - loss: 2.8653 - accuracy: 0.0094 - mae: 1.4587\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 942us/step - loss: 3.0556 - accuracy: 0.0094 - mae: 1.5197\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 925us/step - loss: 2.7121 - accuracy: 0.0094 - mae: 1.3329\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 931us/step - loss: 5.5151 - accuracy: 0.0094 - mae: 2.0396\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 3.1872 - accuracy: 0.0094 - mae: 1.5014\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 1.8393 - accuracy: 0.0094 - mae: 1.0967\n",
      "55/55 [==============================] - 0s 889us/step - loss: 5.1507 - accuracy: 0.0063 - mae: 1.7939\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 1.7877 - accuracy: 0.0094 - mae: 1.0795\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 910us/step - loss: 0.7653 - accuracy: 0.0094 - mae: 0.6835\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 4.2776 - accuracy: 0.0094 - mae: 1.6700\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 920us/step - loss: 2.2930 - accuracy: 0.0094 - mae: 1.2962\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 972us/step - loss: 4.3315 - accuracy: 0.0094 - mae: 1.6544\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 7.1991 - accuracy: 0.0094 - mae: 2.2017\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 3.1778 - accuracy: 0.0094 - mae: 1.4753\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 925us/step - loss: 0.4101 - accuracy: 0.0094 - mae: 0.4850\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 990us/step - loss: 0.3746 - accuracy: 0.0094 - mae: 0.4650\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 977us/step - loss: 1.2353 - accuracy: 0.0094 - mae: 0.8738\n",
      "55/55 [==============================] - 0s 885us/step - loss: 3.0241 - accuracy: 0.0063 - mae: 1.3499\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 8.6587 - accuracy: 0.0092 - mae: 2.4709\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 945us/step - loss: 2.5453 - accuracy: 0.0094 - mae: 1.2897\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 0.5452 - accuracy: 0.0094 - mae: 0.5627\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 0.6195 - accuracy: 0.0094 - mae: 0.6061\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 946us/step - loss: 1.9840 - accuracy: 0.0094 - mae: 1.1176\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 949us/step - loss: 5.4133 - accuracy: 0.0094 - mae: 2.0563\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 974us/step - loss: 2.7495 - accuracy: 0.0094 - mae: 1.3097\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 943us/step - loss: 1.3686 - accuracy: 0.0094 - mae: 0.8654\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 1.2228 - accuracy: 0.0094 - mae: 0.8940\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 938us/step - loss: 0.4263 - accuracy: 0.0094 - mae: 0.4937\n",
      "55/55 [==============================] - 0s 871us/step - loss: 0.7894 - accuracy: 0.0063 - mae: 0.5543\n",
      "0.7893959879875183\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "perdidaObj = 1.0\n",
    "x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "while x[0]>perdidaObj:\n",
    "    red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "    \n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c731f011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 701us/step - loss: 0.7894 - accuracy: 0.0063 - mae: 0.5543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7893959879875183, 0.006329114083200693, 0.5543447136878967]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_bikes.evaluate(attr_prueba, obj_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e05ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 14) for input KerasTensor(type_spec=TensorSpec(shape=(None, 14), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Esperado 203: [[202.50415]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Esperado 247: [[247.2549]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Esperado 315: [[315.3409]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Esperado 214: [[214.46617]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Esperado 164: [[163.41026]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Esperado 122: [[122.441765]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Esperado 119: [[118.79737]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Esperado 89: [[89.13305]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Esperado 90: [[90.23541]]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Esperado 61: [[60.603382]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Esperado 49: [[47.291622]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "\n",
    "X=attr[17368]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr[17369]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr[17370]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr[17371]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr[17372]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr[17373]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr[17374]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr[17375]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr[17376]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr[17377]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr[17378]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9aa5e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 14.48789223245109\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_bikes = RandomForestRegressor()\n",
    "forest_bikes.fit(attr_entrenamiento, obj_entrenamiento)\n",
    "evaluaciones = forest_bikes.predict(attr_prueba)\n",
    "mse = mean_squared_error(obj_prueba, evaluaciones)\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16b5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 203: [202.79]\n",
      "Esperado 247: [246.87]\n",
      "Esperado 315: [314.42]\n",
      "Esperado 214: [214.84]\n",
      "Esperado 164: [163.88]\n",
      "Esperado 122: [121.97]\n",
      "Esperado 119: [118.83]\n",
      "Esperado 89: [89.03]\n",
      "Esperado 90: [90.14]\n",
      "Esperado 61: [60.95]\n",
      "Esperado 49: [49.03]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "attr2 = attr[:, np.newaxis]\n",
    "X=attr2[17368]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr2[17369]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr2[17370]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr2[17371]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr2[17372]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr2[17373]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr2[17374]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr2[17375]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr2[17376]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr2[17377]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr2[17378]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc6c7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo LIME\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "N es el n´umero de permutaciones a realizar\n",
    "f es el modelo a explicar\n",
    "X′ ← {} muestras perturbadas\n",
    "R ← {} representaciones\n",
    "W ← {} las distancias entre la muestra x y sus perturbaciones\n",
    "for 1\n",
    "to\n",
    "N do\n",
    "Selecciona k atributos aleatoriamente\n",
    "x′ ← una perturbaci´on de x donde se perturban los k atributos anteriores.\n",
    "w ← la distancia entre x y x′\n",
    "r ← la representaci´on de x′ respecto a x\n",
    "X′ ← X′ ∪ x′\n",
    "R ← R ∪ r\n",
    "W ← R ∪ w\n",
    "end for\n",
    "Y ′ ← f(X′) las predicciones de las perturbaciones\n",
    "G ← modelo ridge entrenado con R para predecir Y ′ y ponderando cada\n",
    "muestra con W\n",
    "return los par´ametros de G\n",
    "\"\"\"\n",
    "\n",
    "def explain_model(f, x, N,M):\n",
    "    #f es el modelo a explicar\n",
    "    #N es el número de permutaciones a realizar\n",
    "    Xi = [] #muestras perturbadas\n",
    "    R = [] #representaciones\n",
    "    W = [] #Las distancias entre la muestra x y sus pertubaciones\n",
    "    for i in range(N):\n",
    "        k = random.randint(1, len(x)) #Escojo un número aletario que representa el número de los atributos a seleccionar\n",
    "        perturbed_x = x.copy() #copio la muestra original\n",
    "        for j in range(k): \n",
    "            perturbed_attr = random.randint(0,len(x)-1)#random.choice(list(x.keys())) Voy escojiento los atributos que perturbare de forma aleatoria\n",
    "            mx = abs(max([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor máximo\n",
    "            mn = abs(min([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor mínimo\n",
    "            perturbed_x[perturbed_attr] = random.uniform(mn, mx) # pertubo el atributo con un valor aleatorio ente mn y mx\n",
    "        w = abs(sum([x[attr] - perturbed_x[attr] for attr in range(0,len(x)-1)])) #Calculo la distancia entre el original y el perturbado\n",
    "        r = [0  if perturbed_x[attr] == x[attr] else 1 for attr in range(0,len(x)-1)] #miramos la representacion del pertubado respecto al original utilizando un operador ternario como solemos hacer en java\n",
    "        Xi.append(perturbed_x) #Acumulo en la lista los perturbados\n",
    "        R.append(r)#Acumulamos en la lista de representaciones\n",
    "        W.append(w)#Añadimos las distancias a la lista\n",
    "    Y_perturbed = f(Xi)#aplicamos el modelo f\n",
    "    G = Ridge()\n",
    "    G.fit(R, Y_perturbed, sample_weight=W)\n",
    "    return G.get_params() #Devolvemos los parametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "634110b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': 'deprecated',\n",
       " 'positive': False,\n",
       " 'random_state': None,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain_model(red_evaluation,atributos[5809],1,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c2effc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_model(f, X, N, M):\n",
    "    # f es el modelo a explicar\n",
    "    # X es una lista de ejemplos a los que se aplicará LIME\n",
    "    # N es el número de permutaciones a realizar\n",
    "    # M es una matriz de ejemplos para calcular mx y mn\n",
    "\n",
    "    explanations = []  # Lista para almacenar las explicaciones de cada ejemplo\n",
    "\n",
    "    for x in X:\n",
    "        Xi = []  # muestras perturbadas\n",
    "        R = []  # representaciones\n",
    "        W = []  # Las distancias entre el ejemplo x y sus perturbaciones\n",
    "\n",
    "        for i in range(N):\n",
    "            k = random.randint(1, len(x))  # Escojo un número aleatorio que representa el número de atributos a seleccionar\n",
    "            perturbed_x = x.copy()  # Copio el ejemplo original\n",
    "\n",
    "            for j in range(k):\n",
    "                perturbed_attr = random.randint(0, len(x)-1)  # Voy seleccionando los atributos que perturbaré de forma aleatoria\n",
    "                mx = abs(max([a[perturbed_attr] for a in M]))  # Calculo el valor máximo para el atributo seleccionado\n",
    "                mn = abs(min([a[perturbed_attr] for a in M]))  # Calculo el valor mínimo para el atributo seleccionado\n",
    "                perturbed_x[perturbed_attr] = random.uniform(mn, mx)  # Perturbo el atributo con un valor aleatorio entre mn y mx\n",
    "\n",
    "            w = abs(sum([x[attr] - perturbed_x[attr] for attr in range(len(x))]))  # Calculo la distancia entre el original y el perturbado\n",
    "            r = [0 if perturbed_x[attr] == x[attr] else 1 for attr in range(len(x))]  # Calculo la representación del perturbado respecto al original utilizando un operador ternario\n",
    "\n",
    "            Xi.append(perturbed_x)  # Acumulo en la lista los ejemplos perturbados\n",
    "            R.append(r)  # Acumulo en la lista de representaciones\n",
    "            W.append(w)  # Añado las distancias a la lista\n",
    "\n",
    "        Y_perturbed = f(Xi)  # Aplico el modelo f a los ejemplos perturbados\n",
    "        G = Ridge()\n",
    "        G.fit(R, Y_perturbed, sample_weight=W)\n",
    "        explanations.append(G.get_params())  # Almaceno los parámetros del modelo G como la explicación para el ejemplo x\n",
    "\n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d5191d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alpha': 1.0,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'normalize': 'deprecated',\n",
       "  'positive': False,\n",
       "  'random_state': None,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.001},\n",
       " {'alpha': 1.0,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'normalize': 'deprecated',\n",
       "  'positive': False,\n",
       "  'random_state': None,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.001},\n",
       " {'alpha': 1.0,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'normalize': 'deprecated',\n",
       "  'positive': False,\n",
       "  'random_state': None,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.001},\n",
       " {'alpha': 1.0,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'normalize': 'deprecated',\n",
       "  'positive': False,\n",
       "  'random_state': None,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.001},\n",
       " {'alpha': 1.0,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'normalize': 'deprecated',\n",
       "  'positive': False,\n",
       "  'random_state': None,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.001},\n",
       " {'alpha': 1.0,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'normalize': 'deprecated',\n",
       "  'positive': False,\n",
       "  'random_state': None,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.001},\n",
       " {'alpha': 1.0,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'normalize': 'deprecated',\n",
       "  'positive': False,\n",
       "  'random_state': None,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.001},\n",
       " {'alpha': 1.0,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'normalize': 'deprecated',\n",
       "  'positive': False,\n",
       "  'random_state': None,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.001},\n",
       " {'alpha': 1.0,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'normalize': 'deprecated',\n",
       "  'positive': False,\n",
       "  'random_state': None,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.001}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atributibos = atributos[5800:5809, :]\n",
    "\n",
    "explain_model(red_evaluation,atributibos,1,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO IDENTIDAD\n",
    "import pandas\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import lambertw\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Creamos dos instancias de datos y sus respectivas explicaciones LIME\n",
    "xa = np.array([0.5, 0.7, 0.1, 0.3])\n",
    "xb = np.array([0.3, 0.9, 0.2, 0.1])\n",
    "ea = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "eb = np.array([0.3, 0.4, 0.5, 0.1])\n",
    "\n",
    "# Calculamos la distancia entre las instancias de datos\n",
    "data_distance = cdist(xa.reshape(1,-1), xb.reshape(1,-1))\n",
    "\n",
    "# Calculamos la distancia entre las explicaciones LIME\n",
    "exp_distance = cdist(ea.reshape(1,-1), eb.reshape(1,-1))\n",
    "\n",
    "# Verificamos si la métrica Identidad se cumple\n",
    "if data_distance == 0 and exp_distance != 0:\n",
    "    print(\"La métrica Identidad no se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Identidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SEPARABILIDAD\n",
    "# Creamos dos instancias de datos y sus respectivas explicaciones LIME\n",
    "xa = np.array([0.5, 0.7, 0.1, 0.3])\n",
    "xb = np.array([0.3, 0.9, 0.2, 0.1])\n",
    "ea = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "eb = np.array([0.3, 0.4, 0.5, 0.1])\n",
    "\n",
    "# Calculamos la distancia entre las instancias de datos\n",
    "data_distance = cdist(xa.reshape(1,-1), xb.reshape(1,-1))\n",
    "\n",
    "# Calculamos la distancia entre las explicaciones LIME\n",
    "exp_distance = cdist(ea.reshape(1,-1), eb.reshape(1,-1))\n",
    "\n",
    "# Verificamos si la métrica Separabilidad se cumple\n",
    "if data_distance != 0 and exp_distance <= 0:\n",
    "    print(\"La métrica Separabilidad no se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Separabilidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO ESTABILIDAD\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Creamos las distancias entre las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_distances = cdist(x, x[0].reshape(1,-1))\n",
    "exp_distances = cdist(ex, ex[0].reshape(1,-1))\n",
    "\n",
    "# Calculamos el coeficiente de correlación de Pearson entre las distancias\n",
    "correlation, _ = pearsonr(data_distances.flatten(), exp_distances.flatten())\n",
    "\n",
    "# Verificamos si la métrica Estabilidad se cumple\n",
    "if correlation > 0:\n",
    "    print(\"La métrica Estabilidad se cumple para este conjunto de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Estabilidad no se cumple para este conjunto de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0722bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO COHERENCIA\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=1))\n",
    "exp_weights = np.exp(-np.linalg.norm(ex - ex.mean(axis=0), axis=1))\n",
    "\n",
    "# Calculamos los logaritmos naturales de los pesos y los sumamos\n",
    "log_sum_data = np.sum(np.log(data_weights))\n",
    "log_sum_exp = np.sum(np.log(exp_weights))\n",
    "\n",
    "# Calculamos la métrica Coherencia\n",
    "alpha = np.exp(log_sum_data - log_sum_exp + lambertw(0.0, -np.exp(log_sum_data - log_sum_exp)).real)\n",
    "alpha /= len(x)\n",
    "\n",
    "# Imprimimos el valor de la métrica Coherencia\n",
    "print(\"El valor de la métrica Coherencia es:\", alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97773e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO COMPLETITUD\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=1))\n",
    "exp_weights = np.exp(-np.linalg.norm(ex - ex.mean(axis=0), axis=1))\n",
    "\n",
    "# Calculamos los valores de ei y pi\n",
    "ei = np.sum(exp_weights)\n",
    "pi = np.sum(data_weights)\n",
    "\n",
    "# Calculamos la métrica Completitud\n",
    "gamma = ei / pi\n",
    "\n",
    "# Imprimimos el valor de la métrica Completitud\n",
    "print(\"El valor de la métrica Completitud es:\", gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO CONGRUENCIA\n",
    "# Creamos una lista de valores de coherencia para un conjunto de N muestras\n",
    "alpha_values = [0.8, 0.6, 0.7, 0.9, 0.5]\n",
    "\n",
    "# Calculamos el valor promedio de la coherencia\n",
    "alpha = np.mean(alpha_values)\n",
    "\n",
    "# Creamos una lista de valores de alpha_i para cada instancia de datos\n",
    "alpha_i_values = [0.9, 0.7, 0.6, 0.8, 0.4]\n",
    "\n",
    "# Calculamos el número de instancias de datos\n",
    "N = len(alpha_i_values)\n",
    "\n",
    "# Calculamos la suma de las diferencias cuadráticas entre alpha_i y alpha\n",
    "diff_squares_sum = np.sum((np.array(alpha_i_values) - alpha) ** 2)\n",
    "\n",
    "# Calculamos la métrica Congruencia\n",
    "delta = np.sqrt((diff_squares_sum / N) / alpha)\n",
    "\n",
    "# Imprimimos el valor de la métrica Congruencia\n",
    "print(\"El valor de la métrica Congruencia es:\", delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5de2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SELECTIVIDAD\n",
    "# Cargamos el dataset de cáncer de mama de scikit-learn\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Definimos las características y la variable objetivo\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "# Creamos un modelo de regresión logística\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(X, y)\n",
    "\n",
    "# Obtenemos las predicciones del modelo en el conjunto de datos completo\n",
    "y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculamos el AUC para el modelo entrenado en el conjunto de datos completo\n",
    "auc_full = roc_auc_score(y, y_pred)\n",
    "\n",
    "# Ordenamos las características de más a menos relevantes según el modelo\n",
    "idx_sorted = np.argsort(np.abs(model.coef_))[0][::-1]\n",
    "\n",
    "# Creamos una lista para almacenar los AUC para cada característica eliminada\n",
    "auc_scores = []\n",
    "\n",
    "# Iteramos sobre las características de más a menos relevantes según el modelo\n",
    "for i in range(X.shape[1]):\n",
    "    # Establecemos la característica i en cero\n",
    "    X_test = X.copy()\n",
    "    X_test[:, idx_sorted[i]] = 0\n",
    "    \n",
    "    # Obtenemos las predicciones del modelo en el conjunto de datos con la característica i eliminada\n",
    "    y_pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculamos el AUC para el modelo entrenado en el conjunto de datos con la característica i eliminada\n",
    "    auc_test = roc_auc_score(y, y_pred_test)\n",
    "    \n",
    "    # Almacenamos el AUC para la característica i eliminada en la lista de AUC\n",
    "    auc_scores.append(auc_test)\n",
    "\n",
    "# Calculamos la métrica Selectividad como el área bajo la curva ROC para el gráfico de AUC vs características eliminadas\n",
    "selectivity = np.trapz(auc_scores, dx=1)\n",
    "\n",
    "# Imprimimos el valor de la métrica Selectividad\n",
    "print(\"El valor de la métrica Selectividad es:\", selectivity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
