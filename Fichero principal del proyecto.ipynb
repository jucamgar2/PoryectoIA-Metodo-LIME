{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0210de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "#Leemos el csv\n",
    "evaluation = pandas.read_csv('turkiye-student-evaluation_R_Specific.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fd7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  ...  \\\n",
       "1       1      2          1           0           4   3   3   3   3   3  ...   \n",
       "2       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "3       1      2          1           2           4   5   5   5   5   5  ...   \n",
       "4       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "5       1      2          1           0           1   1   1   1   1   1  ...   \n",
       "6       1      2          1           3           3   4   4   4   4   4  ...   \n",
       "7       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "8       1      2          1           1           3   5   5   5   5   5  ...   \n",
       "9       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "10      1      2          1           4           4   4   4   4   4   4  ...   \n",
       "\n",
       "    Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  \n",
       "1     3    3    3    3    3    3    3    3    3    3  \n",
       "2     3    3    3    3    3    3    3    3    3    3  \n",
       "3     5    5    5    5    5    5    5    5    5    5  \n",
       "4     3    3    3    3    3    3    3    3    3    3  \n",
       "5     1    1    1    1    1    1    1    1    1    1  \n",
       "6     4    4    4    4    4    4    4    4    4    4  \n",
       "7     4    4    4    4    4    4    4    4    4    4  \n",
       "8     5    5    5    5    5    5    5    5    5    5  \n",
       "9     4    4    4    4    4    4    4    4    4    4  \n",
       "10    4    4    4    4    4    4    4    4    4    4  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bién\n",
    "evaluation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9259e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08333333 0.         0.         ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.25       ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.5        ... 1.         1.         1.        ]\n",
      " ...\n",
      " [1.         0.         0.         ... 1.         1.         1.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos \n",
    "atributos = evaluation.loc[:, 'class':'Q27']\n",
    "atributos = atributos.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "atributos = scaler.fit_transform(atributos)\n",
    "print(atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22a5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5]\n",
      " [0.5]\n",
      " [1. ]\n",
      " ...\n",
      " [1. ]\n",
      " [0. ]\n",
      " [0. ]]\n"
     ]
    }
   ],
   "source": [
    "objetivo = evaluation['Q28']\n",
    "objetivo = evaluation['Q28'].to_numpy(dtype=np.float32)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "objetivo = scaler.fit_transform(objetivo.reshape(-1, 1))\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141c7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ff2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()\n",
    "normalizador.adapt(atributos_entrenamiento)\n",
    "red_evaluation = keras.Sequential()\n",
    "red_evaluation.add(keras.layers.Input(shape=(31,)))\n",
    "red_evaluation.add(normalizador)\n",
    "red_evaluation.add(keras.layers.Dense(75, activation='relu'))\n",
    "red_evaluation.add(keras.layers.Dense(75, activation='sigmoid'))\n",
    "red_evaluation.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "red_evaluation.add(keras.layers.Lambda(lambda x: x * 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8a17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 31)               63        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 75)                2400      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 75)                5700      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 76        \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,239\n",
      "Trainable params: 8,176\n",
      "Non-trainable params: 63\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_evaluation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3114e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s 4ms/step - loss: 0.2356 - accuracy: 0.2203 - mae: 0.3602\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.3107 - mae: 0.2350\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.3162 - mae: 0.2042\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.3174 - mae: 0.1802\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.3184 - mae: 0.1620\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.3184 - mae: 0.1499\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.3182 - mae: 0.1406\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.3184 - mae: 0.1334\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.3178 - mae: 0.1278\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.3178 - mae: 0.1230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1eabcc910>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "red_evaluation.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d4f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 703us/step - loss: 0.0315 - accuracy: 0.3322 - mae: 0.1270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.031479619443416595, 0.33218786120414734, 0.127012699842453]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_evaluation.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "250f3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "#Leemos el csv\n",
    "#bikes = pandas.read_csv('hour.csv', header=0)\n",
    "bikes = pandas.read_csv('hour2.csv',header = 0)\n",
    "\n",
    "# Eliminar la columna\n",
    "#bikes = bikes.drop('dteday', axis=1)\n",
    "#bikes = bikes.drop('instant', axis=1)\n",
    "# Guardar el DataFrame resultante en un nuevo archivo CSV\n",
    "#bikes.to_csv('hour2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0073ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0       1   0     1   0        0        6           0           1  0.24   \n",
       "1       1   0     1   1        0        6           0           1  0.22   \n",
       "2       1   0     1   2        0        6           0           1  0.22   \n",
       "3       1   0     1   3        0        6           0           1  0.24   \n",
       "4       1   0     1   4        0        6           0           1  0.24   \n",
       "5       1   0     1   5        0        6           0           2  0.24   \n",
       "6       1   0     1   6        0        6           0           1  0.22   \n",
       "7       1   0     1   7        0        6           0           1  0.20   \n",
       "8       1   0     1   8        0        6           0           1  0.24   \n",
       "9       1   0     1   9        0        6           0           1  0.32   \n",
       "\n",
       "    atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.2879  0.81     0.0000       3          13   16  \n",
       "1  0.2727  0.80     0.0000       8          32   40  \n",
       "2  0.2727  0.80     0.0000       5          27   32  \n",
       "3  0.2879  0.75     0.0000       3          10   13  \n",
       "4  0.2879  0.75     0.0000       0           1    1  \n",
       "5  0.2576  0.75     0.0896       0           1    1  \n",
       "6  0.2727  0.80     0.0000       2           0    2  \n",
       "7  0.2576  0.86     0.0000       1           2    3  \n",
       "8  0.2879  0.75     0.0000       1           7    8  \n",
       "9  0.3485  0.76     0.0000       8           6   14  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bién\n",
    "bikes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "890b5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.      0.      1.     ...  0.      3.     13.    ]\n",
      " [ 1.      0.      1.     ...  0.      8.     32.    ]\n",
      " [ 1.      0.      1.     ...  0.      5.     27.    ]\n",
      " ...\n",
      " [ 1.      1.     12.     ...  0.1642  7.     83.    ]\n",
      " [ 1.      1.     12.     ...  0.1343 13.     48.    ]\n",
      " [ 1.      1.     12.     ...  0.1343 12.     37.    ]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos \n",
    "attr = bikes.loc[:, 'season':'registered']\n",
    "attr = attr.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "#attr = scaler.fit_transform(attr)\n",
    "print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e783ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16. 40. 32. ... 90. 61. 49.]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los objetivos\n",
    "obj = bikes['cnt']\n",
    "obj = bikes['cnt'].to_numpy(dtype=np.float32)\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#objetivo = scaler.fit_transform(objetivo.reshape(-1, 1))\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bec2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cogemos un 85% de los datos para entrenar y un 15% de los datos para evaluar el modelo\n",
    "(attr_entrenamiento, attr_prueba,\n",
    " obj_entrenamiento, obj_prueba) = model_selection.train_test_split(\n",
    "    attr, obj, test_size=.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01172681",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"normalization_1\" (type Normalization).\n\nDimensions must be equal, but are 15 and 14 for '{{node normalization_1/sub}} = Sub[T=DT_FLOAT](Placeholder, normalization_1/sub/y)' with input shapes: [?,15], [1,14].\n\nCall arguments received by layer \"normalization_1\" (type Normalization):\n  • inputs=tf.Tensor(shape=(None, 15), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24892\\2496994999.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mred_bikes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mred_bikes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mred_bikes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalizador\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mred_bikes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mred_bikes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1965\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m   \u001b[1;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"normalization_1\" (type Normalization).\n\nDimensions must be equal, but are 15 and 14 for '{{node normalization_1/sub}} = Sub[T=DT_FLOAT](Placeholder, normalization_1/sub/y)' with input shapes: [?,15], [1,14].\n\nCall arguments received by layer \"normalization_1\" (type Normalization):\n  • inputs=tf.Tensor(shape=(None, 15), dtype=float32)"
     ]
    }
   ],
   "source": [
    "#Creamos la red neuronal\n",
    "normalizador = keras.layers.Normalization()\n",
    "normalizador.adapt(attr_entrenamiento)\n",
    "red_bikes = keras.Sequential()\n",
    "red_bikes.add(keras.layers.Input(shape=(15,)))\n",
    "red_bikes.add(normalizador)\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))\n",
    "red_bikes.add(keras.layers.Dense(75, activation='sigmoid'))\n",
    "red_bikes.add(keras.layers.Dense(50, activation='sigmoid'))\n",
    "red_bikes.add(keras.layers.Dense(1, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos un resumen de la red\n",
    "red_bikes.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_bikes.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_bikes.evaluate(attr_prueba, obj_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=attr[2]\n",
    "X=attr[10]\n",
    "X = X.reshape((1, 15))\n",
    "\n",
    "predicciones = red_bikes.predict(X)\n",
    "print(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo LIME\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "N es el n´umero de permutaciones a realizar\n",
    "f es el modelo a explicar\n",
    "X′ ← {} muestras perturbadas\n",
    "R ← {} representaciones\n",
    "W ← {} las distancias entre la muestra x y sus perturbaciones\n",
    "for 1\n",
    "to\n",
    "N do\n",
    "Selecciona k atributos aleatoriamente\n",
    "x′ ← una perturbaci´on de x donde se perturban los k atributos anteriores.\n",
    "w ← la distancia entre x y x′\n",
    "r ← la representaci´on de x′ respecto a x\n",
    "X′ ← X′ ∪ x′\n",
    "R ← R ∪ r\n",
    "W ← R ∪ w\n",
    "end for\n",
    "Y ′ ← f(X′) las predicciones de las perturbaciones\n",
    "G ← modelo ridge entrenado con R para predecir Y ′ y ponderando cada\n",
    "muestra con W\n",
    "return los par´ametros de G\n",
    "\"\"\"\n",
    "\n",
    "def explain_model(f, x, N,M):\n",
    "    #f es el modelo a explicar\n",
    "    #N es el número de permutaciones a realizar\n",
    "    Xi = [] #muestras perturbadas\n",
    "    R = [] #representaciones\n",
    "    W = [] #Las distancias entre la muestra x y sus pertubaciones\n",
    "    for i in range(N):\n",
    "        k = random.randint(1, len(x)) #Escojo un número aletario que representa el número de los atributos a seleccionar\n",
    "        perturbed_x = x.copy() #copio la muestra original\n",
    "        for i in range(k): \n",
    "            perturbed_attr = random.choice(list(x.keys())) #Voy escojiento los atributos que perturbare de forma aleatoria\n",
    "            mx = abs(max([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor máximo\n",
    "            mn = abs(min([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor mínimo\n",
    "            perturbed_x[perturbed_attr] = random.uniform(mn, mx) # pertubo el atributo con un valor aleatorio ente mn y mx\n",
    "        w = abs(sum([x[attr] - perturbed_x[attr] for attr in x.keys()])) #Calculo la distancia entre el original y el perturbado\n",
    "        r = {attr: 0  if x_perturbed[attr] = x[attr] else 1 for attr in x.keys()} #miramos la representacion del pertubado respecto al original utilizando un operador ternario como solemos hacer en java\n",
    "        Xi.append(x_perturbed) #Acumulo en la lista los perturbados\n",
    "        R.append(r)#Acumulamos en la lista de representaciones\n",
    "        W.append(w)#Añadimos las distancias a la lista\n",
    "    Y_perturbed = f(Xi)#aplicamos el modelo f\n",
    "    G = Ridge().fit(R, Y_perturbed, sample_weight=W) #Utilizamos Ridge \n",
    "    return G.get_params() #Devolvemos los parametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO IDENTIDAD\n",
    "import pandas\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import lambertw\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Creamos dos instancias de datos y sus respectivas explicaciones LIME\n",
    "xa = np.array([0.5, 0.7, 0.1, 0.3])\n",
    "xb = np.array([0.3, 0.9, 0.2, 0.1])\n",
    "ea = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "eb = np.array([0.3, 0.4, 0.5, 0.1])\n",
    "\n",
    "# Calculamos la distancia entre las instancias de datos\n",
    "data_distance = cdist(xa.reshape(1,-1), xb.reshape(1,-1))\n",
    "\n",
    "# Calculamos la distancia entre las explicaciones LIME\n",
    "exp_distance = cdist(ea.reshape(1,-1), eb.reshape(1,-1))\n",
    "\n",
    "# Verificamos si la métrica Identidad se cumple\n",
    "if data_distance == 0 and exp_distance != 0:\n",
    "    print(\"La métrica Identidad no se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Identidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SEPARABILIDAD\n",
    "# Creamos dos instancias de datos y sus respectivas explicaciones LIME\n",
    "xa = np.array([0.5, 0.7, 0.1, 0.3])\n",
    "xb = np.array([0.3, 0.9, 0.2, 0.1])\n",
    "ea = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "eb = np.array([0.3, 0.4, 0.5, 0.1])\n",
    "\n",
    "# Calculamos la distancia entre las instancias de datos\n",
    "data_distance = cdist(xa.reshape(1,-1), xb.reshape(1,-1))\n",
    "\n",
    "# Calculamos la distancia entre las explicaciones LIME\n",
    "exp_distance = cdist(ea.reshape(1,-1), eb.reshape(1,-1))\n",
    "\n",
    "# Verificamos si la métrica Separabilidad se cumple\n",
    "if data_distance != 0 and exp_distance <= 0:\n",
    "    print(\"La métrica Separabilidad no se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Separabilidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO ESTABILIDAD\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Creamos las distancias entre las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_distances = cdist(x, x[0].reshape(1,-1))\n",
    "exp_distances = cdist(ex, ex[0].reshape(1,-1))\n",
    "\n",
    "# Calculamos el coeficiente de correlación de Pearson entre las distancias\n",
    "correlation, _ = pearsonr(data_distances.flatten(), exp_distances.flatten())\n",
    "\n",
    "# Verificamos si la métrica Estabilidad se cumple\n",
    "if correlation > 0:\n",
    "    print(\"La métrica Estabilidad se cumple para este conjunto de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Estabilidad no se cumple para este conjunto de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0722bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO COHERENCIA\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=1))\n",
    "exp_weights = np.exp(-np.linalg.norm(ex - ex.mean(axis=0), axis=1))\n",
    "\n",
    "# Calculamos los logaritmos naturales de los pesos y los sumamos\n",
    "log_sum_data = np.sum(np.log(data_weights))\n",
    "log_sum_exp = np.sum(np.log(exp_weights))\n",
    "\n",
    "# Calculamos la métrica Coherencia\n",
    "alpha = np.exp(log_sum_data - log_sum_exp + lambertw(0.0, -np.exp(log_sum_data - log_sum_exp)).real)\n",
    "alpha /= len(x)\n",
    "\n",
    "# Imprimimos el valor de la métrica Coherencia\n",
    "print(\"El valor de la métrica Coherencia es:\", alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97773e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO COMPLETITUD\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=1))\n",
    "exp_weights = np.exp(-np.linalg.norm(ex - ex.mean(axis=0), axis=1))\n",
    "\n",
    "# Calculamos los valores de ei y pi\n",
    "ei = np.sum(exp_weights)\n",
    "pi = np.sum(data_weights)\n",
    "\n",
    "# Calculamos la métrica Completitud\n",
    "gamma = ei / pi\n",
    "\n",
    "# Imprimimos el valor de la métrica Completitud\n",
    "print(\"El valor de la métrica Completitud es:\", gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO CONGRUENCIA\n",
    "# Creamos una lista de valores de coherencia para un conjunto de N muestras\n",
    "alpha_values = [0.8, 0.6, 0.7, 0.9, 0.5]\n",
    "\n",
    "# Calculamos el valor promedio de la coherencia\n",
    "alpha = np.mean(alpha_values)\n",
    "\n",
    "# Creamos una lista de valores de alpha_i para cada instancia de datos\n",
    "alpha_i_values = [0.9, 0.7, 0.6, 0.8, 0.4]\n",
    "\n",
    "# Calculamos el número de instancias de datos\n",
    "N = len(alpha_i_values)\n",
    "\n",
    "# Calculamos la suma de las diferencias cuadráticas entre alpha_i y alpha\n",
    "diff_squares_sum = np.sum((np.array(alpha_i_values) - alpha) ** 2)\n",
    "\n",
    "# Calculamos la métrica Congruencia\n",
    "delta = np.sqrt((diff_squares_sum / N) / alpha)\n",
    "\n",
    "# Imprimimos el valor de la métrica Congruencia\n",
    "print(\"El valor de la métrica Congruencia es:\", delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5de2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SELECTIVIDAD\n",
    "# Cargamos el dataset de cáncer de mama de scikit-learn\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Definimos las características y la variable objetivo\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "# Creamos un modelo de regresión logística\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(X, y)\n",
    "\n",
    "# Obtenemos las predicciones del modelo en el conjunto de datos completo\n",
    "y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculamos el AUC para el modelo entrenado en el conjunto de datos completo\n",
    "auc_full = roc_auc_score(y, y_pred)\n",
    "\n",
    "# Ordenamos las características de más a menos relevantes según el modelo\n",
    "idx_sorted = np.argsort(np.abs(model.coef_))[0][::-1]\n",
    "\n",
    "# Creamos una lista para almacenar los AUC para cada característica eliminada\n",
    "auc_scores = []\n",
    "\n",
    "# Iteramos sobre las características de más a menos relevantes según el modelo\n",
    "for i in range(X.shape[1]):\n",
    "    # Establecemos la característica i en cero\n",
    "    X_test = X.copy()\n",
    "    X_test[:, idx_sorted[i]] = 0\n",
    "    \n",
    "    # Obtenemos las predicciones del modelo en el conjunto de datos con la característica i eliminada\n",
    "    y_pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculamos el AUC para el modelo entrenado en el conjunto de datos con la característica i eliminada\n",
    "    auc_test = roc_auc_score(y, y_pred_test)\n",
    "    \n",
    "    # Almacenamos el AUC para la característica i eliminada en la lista de AUC\n",
    "    auc_scores.append(auc_test)\n",
    "\n",
    "# Calculamos la métrica Selectividad como el área bajo la curva ROC para el gráfico de AUC vs características eliminadas\n",
    "selectivity = np.trapz(auc_scores, dx=1)\n",
    "\n",
    "# Imprimimos el valor de la métrica Selectividad\n",
    "print(\"El valor de la métrica Selectividad es:\", selectivity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
