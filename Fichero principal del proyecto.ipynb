{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0210de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "#Leemos el csv\n",
    "evaluation = pandas.read_csv('turkiye-student-evaluation_R_Specific.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fd7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  ...  \\\n",
       "1       1      2          1           0           4   3   3   3   3   3  ...   \n",
       "2       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "3       1      2          1           2           4   5   5   5   5   5  ...   \n",
       "4       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "5       1      2          1           0           1   1   1   1   1   1  ...   \n",
       "6       1      2          1           3           3   4   4   4   4   4  ...   \n",
       "7       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "8       1      2          1           1           3   5   5   5   5   5  ...   \n",
       "9       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "10      1      2          1           4           4   4   4   4   4   4  ...   \n",
       "\n",
       "    Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  \n",
       "1     3    3    3    3    3    3    3    3    3    3  \n",
       "2     3    3    3    3    3    3    3    3    3    3  \n",
       "3     5    5    5    5    5    5    5    5    5    5  \n",
       "4     3    3    3    3    3    3    3    3    3    3  \n",
       "5     1    1    1    1    1    1    1    1    1    1  \n",
       "6     4    4    4    4    4    4    4    4    4    4  \n",
       "7     4    4    4    4    4    4    4    4    4    4  \n",
       "8     5    5    5    5    5    5    5    5    5    5  \n",
       "9     4    4    4    4    4    4    4    4    4    4  \n",
       "10    4    4    4    4    4    4    4    4    4    4  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bien\n",
    "evaluation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9259e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.   0.25 0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos \n",
    "atributos = evaluation.loc[:, 'class':'Q27']\n",
    "atributos = atributos.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "atributos = scaler.fit_transform(atributos)\n",
    "print(atributos[5818,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22a5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 5. ... 5. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos el objetivo\n",
    "objetivo = evaluation['Q28']\n",
    "objetivo = evaluation['Q28'].to_numpy(dtype=np.float32)\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141c7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos los datos que se usaran para entrenar y los que se usarán para evaluar los modelos\n",
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ff2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()#Definimos un normalizador\n",
    "normalizador.adapt(atributos_entrenamiento)\n",
    "red_evaluation = keras.Sequential()#Creamos la red neuronal\n",
    "red_evaluation.add(keras.layers.Input(shape=(31,)))#Definimos la capa de entrada con una neurona por cada atributo\n",
    "red_evaluation.add(normalizador)#Aplicamos el normalizador\n",
    "red_evaluation.add(keras.layers.Dense(70, activation='relu'))#Definimos una capa con 70 neuronas y función de activación relu\n",
    "red_evaluation.add(keras.layers.Dense(70, activation='sigmoid'))#Definimos una capa de 70 neuronas y función de activación sigmoide\n",
    "red_evaluation.add(keras.layers.Dense(1, activation='linear')) #Defnimios una capa de salida con función de activación lienal ya que los valores esperados son números lineales entre 0 y 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8a17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 31)               63        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 70)                2240      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,344\n",
      "Trainable params: 7,281\n",
      "Non-trainable params: 63\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_evaluation.summary()#Mostramos un resumen de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3114e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 1.9919 - accuracy: 0.1346 - mae: 1.0578 \n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.1427 - mae: 0.5036\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.1427 - mae: 0.3892\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.1427 - mae: 0.3527\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.1427 - mae: 0.3370\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.1427 - mae: 0.3288\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2861 - accuracy: 0.1427 - mae: 0.3222\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.1427 - mae: 0.3173\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2766 - accuracy: 0.1427 - mae: 0.3125\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.2723 - accuracy: 0.1427 - mae: 0.3065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1705bbb8df0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "red_evaluation.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])#Compilamos la red neuronal definiendo el optimizaodr, la función de perdida y dos metricas\n",
    "red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)#Entrenamos la red neuronal con 10 epocas y lotes de 256 elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d4f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 809us/step - loss: 0.2400 - accuracy: 0.1214 - mae: 0.2912\n",
      "0.23995287716388702\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "#Para este conjunto de datos esto practicamente no es necesario pero así nos aseguramos de cometer un error muy pequeño\n",
    "perdObj = 1.0\n",
    "x=red_evaluation.evaluate(atributos_prueba, objetivo_prueba)\n",
    "while x[0]>perdObj:\n",
    "    red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_evaluation.evaluate(atributos_prueba, objetivo_prueba)\n",
    "    \n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad4c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 850us/step - loss: 0.2400 - accuracy: 0.1214 - mae: 0.2912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23995287716388702, 0.12142039090394974, 0.291249543428421]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_evaluation.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84bc4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 31) for input KerasTensor(type_spec=TensorSpec(shape=(None, 31), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None,).\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Esperado 4: [[4.1052794]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Esperado 3: [[3.1378324]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Esperado 3: [[3.1663136]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Esperado 1: [[1.1188084]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Esperado 3: [[2.946276]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Esperado 1: [[1.233192]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Esperado 1: [[1.1188084]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Esperado 5: [[4.582268]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Esperado 5: [[4.8298216]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Esperado 1: [[1.1196302]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Esperado 1: [[1.1196302]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "X=atributos[5809]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 4:',predicciones)\n",
    "X=atributos[5810]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5811]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5812]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5813]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5814]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5815]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5816]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos[5817]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos[5818]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5819]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55821bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 0.19683515682260577\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_evaluation = RandomForestRegressor() #Creamos el modelo\n",
    "forest_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento)#Lo entrenamos\n",
    "evaluaciones = forest_evaluation.predict(atributos_prueba)#Evaluamos\n",
    "mse = mean_squared_error(objetivo_prueba, evaluaciones)#Calculamos la perdida\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)\n",
    "#Como este modelo suele tener una perdida muy pequeña tras entrenarlo una vez, no hacemos nada más para mejorarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a83c67dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 4: [4.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 1: [1.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 1: [1.18]\n",
      "Esperado 1: [1.]\n",
      "Esperado 5: [4.95]\n",
      "Esperado 5: [5.]\n",
      "Esperado 1: [1.]\n",
      "Esperado 1: [1.]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "atributos2 = atributos[:, np.newaxis]\n",
    "X=atributos2[5809]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 4:',predicciones)\n",
    "X=atributos2[5810]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5811]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5812]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5813]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5814]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5815]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5816]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos2[5817]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos2[5818]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5819]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "250f3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear otra red neuronal\n",
    "#Volemos a importar por si se quiere ejecutar este fragmento sin ejecutar el anterior\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#Leemos el csv\n",
    "#bikes = pandas.read_csv('hour.csv', header=0)\n",
    "bikes = pandas.read_csv('hour2.csv',header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0073ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0       1   0     1   0        0        6           0           1  0.24   \n",
       "1       1   0     1   1        0        6           0           1  0.22   \n",
       "2       1   0     1   2        0        6           0           1  0.22   \n",
       "3       1   0     1   3        0        6           0           1  0.24   \n",
       "4       1   0     1   4        0        6           0           1  0.24   \n",
       "5       1   0     1   5        0        6           0           2  0.24   \n",
       "6       1   0     1   6        0        6           0           1  0.22   \n",
       "7       1   0     1   7        0        6           0           1  0.20   \n",
       "8       1   0     1   8        0        6           0           1  0.24   \n",
       "9       1   0     1   9        0        6           0           1  0.32   \n",
       "\n",
       "    atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.2879  0.81     0.0000       3          13   16  \n",
       "1  0.2727  0.80     0.0000       8          32   40  \n",
       "2  0.2727  0.80     0.0000       5          27   32  \n",
       "3  0.2879  0.75     0.0000       3          10   13  \n",
       "4  0.2879  0.75     0.0000       0           1    1  \n",
       "5  0.2576  0.75     0.0896       0           1    1  \n",
       "6  0.2727  0.80     0.0000       2           0    2  \n",
       "7  0.2576  0.86     0.0000       1           2    3  \n",
       "8  0.2879  0.75     0.0000       1           7    8  \n",
       "9  0.3485  0.76     0.0000       8           6   14  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bién\n",
    "bikes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "890b5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.00817439 0.01467269]\n",
      " [0.         0.         0.         ... 0.         0.02179837 0.03611738]\n",
      " [0.         0.         0.         ... 0.         0.01362398 0.03047404]\n",
      " ...\n",
      " [0.         1.         1.         ... 0.19301751 0.01907357 0.09367946]\n",
      " [0.         1.         1.         ... 0.15786999 0.03542234 0.05417607]\n",
      " [0.         1.         1.         ... 0.15786999 0.03269755 0.04176072]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos y los nomalizamos\n",
    "attr = bikes.loc[:, 'season':'registered']\n",
    "attr = attr.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "attr = scaler.fit_transform(attr)\n",
    "\n",
    "print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e783ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16. 40. 32. ... 90. 61. 49.]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los objetivos\n",
    "obj = bikes['cnt']\n",
    "obj = bikes['cnt'].to_numpy(dtype=np.float32)\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bec2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cogemos un 85% de los datos para entrenar y un 15% de los datos para evaluar el modelo\n",
    "(attr_entrenamiento, attr_prueba,\n",
    " obj_entrenamiento, obj_prueba) = model_selection.train_test_split(\n",
    "    attr, obj, test_size=.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01172681",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()#Definimos un normalizador\n",
    "normalizador.adapt(attr_entrenamiento)\n",
    "red_bikes = keras.Sequential()#Creamos la red neuronal\n",
    "red_bikes.add(keras.layers.Input(shape=(14,))) #Añadimos la capa de entrada con 14 neuronas, una por cada atributo\n",
    "red_bikes.add(normalizador)#Aplicamos un normalizador\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(1, activation='linear'))#Necesitamos una capa de salida linear ya que los valores objetivos son lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b9f0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 14)               29        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               1500      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,730\n",
      "Trainable params: 11,701\n",
      "Non-trainable params: 29\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Vemos un resumen de la red\n",
    "red_bikes.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e5d4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 956us/step - loss: 10471.9834 - accuracy: 0.0084 - mae: 67.5405\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 986us/step - loss: 1819.6385 - accuracy: 0.0086 - mae: 30.1496\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 949us/step - loss: 689.3970 - accuracy: 0.0086 - mae: 18.6280\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 567.4750 - accuracy: 0.0086 - mae: 16.7272\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 264.2011 - accuracy: 0.0086 - mae: 11.7844\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 314.1512 - accuracy: 0.0086 - mae: 13.1818\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 204.5233 - accuracy: 0.0086 - mae: 9.8005\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 951us/step - loss: 122.5611 - accuracy: 0.0086 - mae: 7.4955\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 951us/step - loss: 234.1092 - accuracy: 0.0086 - mae: 10.0420\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 955us/step - loss: 67.7621 - accuracy: 0.0086 - mae: 5.8721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1705e3ed670>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compilamos y entrenamos la red neuronal, buscamos minimizar la función de perdida\n",
    "red_bikes.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aa4bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 874us/step - loss: 22.8093 - accuracy: 0.0138 - mae: 3.0984\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 914us/step - loss: 73.0563 - accuracy: 0.0086 - mae: 6.2002\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 147.9087 - accuracy: 0.0086 - mae: 8.3603\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 76.6229 - accuracy: 0.0086 - mae: 5.7397 \n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 70.0050 - accuracy: 0.0086 - mae: 6.3591\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 976us/step - loss: 139.8824 - accuracy: 0.0086 - mae: 7.5473\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 917us/step - loss: 78.6147 - accuracy: 0.0086 - mae: 6.7568\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 980us/step - loss: 55.4464 - accuracy: 0.0086 - mae: 5.2435\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 954us/step - loss: 78.6549 - accuracy: 0.0086 - mae: 6.3132\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 32.7519 - accuracy: 0.0086 - mae: 3.7153\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 965us/step - loss: 87.0159 - accuracy: 0.0086 - mae: 6.0972\n",
      "55/55 [==============================] - 0s 771us/step - loss: 363.8181 - accuracy: 0.0138 - mae: 15.0506\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 987us/step - loss: 50.7284 - accuracy: 0.0086 - mae: 4.7901\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 895us/step - loss: 20.4132 - accuracy: 0.0086 - mae: 3.0916\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 978us/step - loss: 34.2133 - accuracy: 0.0086 - mae: 4.2719\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 971us/step - loss: 39.4633 - accuracy: 0.0086 - mae: 4.7757\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 963us/step - loss: 80.2359 - accuracy: 0.0086 - mae: 6.5634\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 964us/step - loss: 12.8115 - accuracy: 0.0086 - mae: 2.2572\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 945us/step - loss: 38.0174 - accuracy: 0.0086 - mae: 4.5440\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 21.6112 - accuracy: 0.0086 - mae: 3.3174\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 10.5998 - accuracy: 0.0086 - mae: 2.2539\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 962us/step - loss: 45.8275 - accuracy: 0.0086 - mae: 4.7910\n",
      "55/55 [==============================] - 0s 587us/step - loss: 23.5949 - accuracy: 0.0138 - mae: 2.7382\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 24.5465 - accuracy: 0.0086 - mae: 3.9016\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 31.0487 - accuracy: 0.0086 - mae: 4.4690\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 10.7340 - accuracy: 0.0086 - mae: 2.3458\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 32.8255 - accuracy: 0.0086 - mae: 4.4193\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 16.5029 - accuracy: 0.0086 - mae: 3.0114\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.4890 - accuracy: 0.0086 - mae: 2.0663\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 974us/step - loss: 22.3606 - accuracy: 0.0086 - mae: 3.7382\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 30.5675 - accuracy: 0.0086 - mae: 4.2937\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 7.0739 - accuracy: 0.0086 - mae: 1.8758\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 930us/step - loss: 27.7451 - accuracy: 0.0086 - mae: 3.7599\n",
      "55/55 [==============================] - 0s 662us/step - loss: 73.0524 - accuracy: 0.0138 - mae: 5.5001\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 17.0140 - accuracy: 0.0086 - mae: 2.7394\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 941us/step - loss: 26.6518 - accuracy: 0.0086 - mae: 3.9182\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 954us/step - loss: 4.1903 - accuracy: 0.0086 - mae: 1.2948\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 979us/step - loss: 43.8769 - accuracy: 0.0086 - mae: 4.0144\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 920us/step - loss: 8.7158 - accuracy: 0.0086 - mae: 1.7102\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 931us/step - loss: 6.9256 - accuracy: 0.0086 - mae: 1.8651\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 30.2113 - accuracy: 0.0086 - mae: 4.3378\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 903us/step - loss: 5.5602 - accuracy: 0.0086 - mae: 1.6610\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 900us/step - loss: 18.7197 - accuracy: 0.0086 - mae: 3.1352\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 948us/step - loss: 24.6614 - accuracy: 0.0086 - mae: 3.7099\n",
      "55/55 [==============================] - 0s 657us/step - loss: 148.3397 - accuracy: 0.0138 - mae: 5.7882\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 901us/step - loss: 28.9073 - accuracy: 0.0086 - mae: 2.8157\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 954us/step - loss: 10.7373 - accuracy: 0.0086 - mae: 2.4663\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 961us/step - loss: 21.0428 - accuracy: 0.0086 - mae: 3.3381\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 21.3537 - accuracy: 0.0086 - mae: 3.4792\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 952us/step - loss: 23.7570 - accuracy: 0.0086 - mae: 3.5590\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 951us/step - loss: 4.2046 - accuracy: 0.0086 - mae: 1.4380\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 898us/step - loss: 9.2937 - accuracy: 0.0086 - mae: 2.4101\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 956us/step - loss: 11.8601 - accuracy: 0.0086 - mae: 2.6654\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 965us/step - loss: 29.7721 - accuracy: 0.0086 - mae: 3.9642\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 941us/step - loss: 4.5906 - accuracy: 0.0086 - mae: 1.4728\n",
      "55/55 [==============================] - 0s 725us/step - loss: 12.4636 - accuracy: 0.0138 - mae: 2.5699\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 889us/step - loss: 21.9200 - accuracy: 0.0086 - mae: 3.7474\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 963us/step - loss: 10.0032 - accuracy: 0.0086 - mae: 2.4851\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 946us/step - loss: 3.1366 - accuracy: 0.0086 - mae: 1.1984\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 913us/step - loss: 7.5834 - accuracy: 0.0086 - mae: 2.2180\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 889us/step - loss: 6.4020 - accuracy: 0.0086 - mae: 1.9436\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 937us/step - loss: 17.1794 - accuracy: 0.0086 - mae: 3.3408\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 932us/step - loss: 8.1442 - accuracy: 0.0086 - mae: 1.9884\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 945us/step - loss: 5.9186 - accuracy: 0.0086 - mae: 1.7605\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 940us/step - loss: 8.4608 - accuracy: 0.0086 - mae: 1.9017\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 21.9315 - accuracy: 0.0086 - mae: 2.7734\n",
      "55/55 [==============================] - 0s 584us/step - loss: 4.8360 - accuracy: 0.0138 - mae: 1.4095\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 937us/step - loss: 6.7632 - accuracy: 0.0086 - mae: 1.8316\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 995us/step - loss: 2.1409 - accuracy: 0.0086 - mae: 1.0682\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 4.3475 - accuracy: 0.0086 - mae: 1.6524\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 9.3351 - accuracy: 0.0086 - mae: 2.3875\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 3.9536 - accuracy: 0.0086 - mae: 1.4996\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 20.6196 - accuracy: 0.0086 - mae: 3.7340\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 969us/step - loss: 5.4905 - accuracy: 0.0086 - mae: 1.7421\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 1.6456 - accuracy: 0.0086 - mae: 0.9243\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 979us/step - loss: 14.1336 - accuracy: 0.0086 - mae: 2.5663\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 931us/step - loss: 7.0674 - accuracy: 0.0086 - mae: 2.0201\n",
      "55/55 [==============================] - 0s 596us/step - loss: 19.6895 - accuracy: 0.0138 - mae: 3.2954\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 902us/step - loss: 7.5460 - accuracy: 0.0086 - mae: 2.2577\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 12.7029 - accuracy: 0.0086 - mae: 2.9245\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 993us/step - loss: 2.5826 - accuracy: 0.0086 - mae: 1.0668\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 888us/step - loss: 9.1225 - accuracy: 0.0086 - mae: 2.4973\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 916us/step - loss: 8.7849 - accuracy: 0.0086 - mae: 2.2653\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 2.4383 - accuracy: 0.0086 - mae: 1.1629\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 921us/step - loss: 3.1269 - accuracy: 0.0086 - mae: 1.3160\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 906us/step - loss: 5.5790 - accuracy: 0.0086 - mae: 1.9916\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 974us/step - loss: 7.2279 - accuracy: 0.0086 - mae: 2.2317\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 945us/step - loss: 11.3592 - accuracy: 0.0086 - mae: 2.7092\n",
      "55/55 [==============================] - 0s 703us/step - loss: 17.0566 - accuracy: 0.0138 - mae: 3.0992\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 986us/step - loss: 4.4321 - accuracy: 0.0086 - mae: 1.6487\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 897us/step - loss: 3.6806 - accuracy: 0.0086 - mae: 1.4203\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 949us/step - loss: 4.6710 - accuracy: 0.0086 - mae: 1.6980\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 948us/step - loss: 3.8309 - accuracy: 0.0086 - mae: 1.4964\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 883us/step - loss: 11.5262 - accuracy: 0.0086 - mae: 2.7145\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 931us/step - loss: 1.2291 - accuracy: 0.0086 - mae: 0.7649\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 928us/step - loss: 5.0350 - accuracy: 0.0086 - mae: 1.8111\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 898us/step - loss: 14.5547 - accuracy: 0.0086 - mae: 3.1673\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 905us/step - loss: 7.3297 - accuracy: 0.0086 - mae: 2.0004\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 958us/step - loss: 1.4124 - accuracy: 0.0086 - mae: 0.8722\n",
      "55/55 [==============================] - 0s 582us/step - loss: 4.9434 - accuracy: 0.0138 - mae: 1.6902\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 3.3973 - accuracy: 0.0086 - mae: 1.4979\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 970us/step - loss: 3.5274 - accuracy: 0.0086 - mae: 1.4792\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 909us/step - loss: 2.2742 - accuracy: 0.0086 - mae: 1.1861\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 891us/step - loss: 2.3503 - accuracy: 0.0086 - mae: 1.1902\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 973us/step - loss: 5.1067 - accuracy: 0.0086 - mae: 1.8618\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 938us/step - loss: 7.1638 - accuracy: 0.0086 - mae: 2.1908\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 972us/step - loss: 3.6586 - accuracy: 0.0086 - mae: 1.5323\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 885us/step - loss: 2.8121 - accuracy: 0.0086 - mae: 1.2954\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 952us/step - loss: 3.5868 - accuracy: 0.0086 - mae: 1.4938\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 959us/step - loss: 1.9861 - accuracy: 0.0086 - mae: 1.0776\n",
      "55/55 [==============================] - 0s 600us/step - loss: 8.9945 - accuracy: 0.0138 - mae: 2.1985\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 887us/step - loss: 6.2614 - accuracy: 0.0086 - mae: 2.0396\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 964us/step - loss: 7.6663 - accuracy: 0.0086 - mae: 2.2457\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 3.0575 - accuracy: 0.0086 - mae: 1.3830\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 882us/step - loss: 1.9222 - accuracy: 0.0086 - mae: 1.0885\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 946us/step - loss: 2.4977 - accuracy: 0.0086 - mae: 1.2007\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 945us/step - loss: 9.0911 - accuracy: 0.0086 - mae: 2.5769\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 946us/step - loss: 2.3116 - accuracy: 0.0086 - mae: 1.1320\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 934us/step - loss: 4.1156 - accuracy: 0.0086 - mae: 1.6232\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 938us/step - loss: 5.4186 - accuracy: 0.0086 - mae: 1.9198\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 906us/step - loss: 7.3095 - accuracy: 0.0086 - mae: 2.2680\n",
      "55/55 [==============================] - 0s 954us/step - loss: 4.9485 - accuracy: 0.0138 - mae: 1.7185\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 1.1228 - accuracy: 0.0086 - mae: 0.7806\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 931us/step - loss: 1.8431 - accuracy: 0.0086 - mae: 1.0533\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 997us/step - loss: 5.3305 - accuracy: 0.0086 - mae: 1.8940\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 974us/step - loss: 6.0800 - accuracy: 0.0086 - mae: 2.0235\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 945us/step - loss: 2.9707 - accuracy: 0.0086 - mae: 1.3393\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 993us/step - loss: 13.9895 - accuracy: 0.0086 - mae: 3.2054\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 901us/step - loss: 7.1757 - accuracy: 0.0086 - mae: 2.0875\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 938us/step - loss: 0.8317 - accuracy: 0.0086 - mae: 0.6735\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 951us/step - loss: 1.3880 - accuracy: 0.0086 - mae: 0.8586\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 921us/step - loss: 2.7103 - accuracy: 0.0086 - mae: 1.3244\n",
      "55/55 [==============================] - 0s 879us/step - loss: 4.7421 - accuracy: 0.0138 - mae: 1.6045\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 2.7868 - accuracy: 0.0086 - mae: 1.3502\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 922us/step - loss: 4.9989 - accuracy: 0.0086 - mae: 1.7117\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 973us/step - loss: 3.8665 - accuracy: 0.0086 - mae: 1.4965\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 7.4270 - accuracy: 0.0086 - mae: 2.2154\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 941us/step - loss: 5.0900 - accuracy: 0.0086 - mae: 1.8753\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 5.0249 - accuracy: 0.0086 - mae: 1.8741\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 981us/step - loss: 7.5458 - accuracy: 0.0086 - mae: 2.2141\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 930us/step - loss: 5.4043 - accuracy: 0.0086 - mae: 1.8803\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 2.4977 - accuracy: 0.0086 - mae: 1.2590\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 890us/step - loss: 0.6784 - accuracy: 0.0086 - mae: 0.6066\n",
      "55/55 [==============================] - 0s 868us/step - loss: 1.4329 - accuracy: 0.0138 - mae: 0.8849\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 877us/step - loss: 1.2897 - accuracy: 0.0086 - mae: 0.8621\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 880us/step - loss: 10.3893 - accuracy: 0.0086 - mae: 2.7646\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 936us/step - loss: 7.1189 - accuracy: 0.0086 - mae: 2.2155\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 945us/step - loss: 2.2889 - accuracy: 0.0086 - mae: 1.0833\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 967us/step - loss: 1.1046 - accuracy: 0.0086 - mae: 0.7967\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 950us/step - loss: 0.6771 - accuracy: 0.0086 - mae: 0.6118\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 927us/step - loss: 1.3230 - accuracy: 0.0086 - mae: 0.8609\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 894us/step - loss: 7.7994 - accuracy: 0.0086 - mae: 2.3779\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 3.8016 - accuracy: 0.0086 - mae: 1.5705\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.6454 - accuracy: 0.0086 - mae: 0.5981\n",
      "55/55 [==============================] - 0s 581us/step - loss: 1.3332 - accuracy: 0.0138 - mae: 0.8985\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.9451 - accuracy: 0.0086 - mae: 0.7458\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 958us/step - loss: 5.3648 - accuracy: 0.0086 - mae: 1.9009\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 924us/step - loss: 9.1084 - accuracy: 0.0086 - mae: 2.5143\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 7.7397 - accuracy: 0.0086 - mae: 2.1131\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 977us/step - loss: 0.9166 - accuracy: 0.0086 - mae: 0.7121\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 973us/step - loss: 3.2139 - accuracy: 0.0086 - mae: 1.4461\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 937us/step - loss: 0.9686 - accuracy: 0.0086 - mae: 0.7465\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 958us/step - loss: 0.5699 - accuracy: 0.0086 - mae: 0.5481\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 979us/step - loss: 1.4777 - accuracy: 0.0086 - mae: 0.9001\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 948us/step - loss: 5.3911 - accuracy: 0.0086 - mae: 1.9541\n",
      "55/55 [==============================] - 0s 507us/step - loss: 10.9053 - accuracy: 0.0138 - mae: 2.3470\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 8.6837 - accuracy: 0.0086 - mae: 2.5439\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 962us/step - loss: 1.8098 - accuracy: 0.0086 - mae: 0.8446\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 938us/step - loss: 0.7866 - accuracy: 0.0086 - mae: 0.6445\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 951us/step - loss: 1.7974 - accuracy: 0.0086 - mae: 1.0847\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 2.2879 - accuracy: 0.0086 - mae: 1.1930\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 976us/step - loss: 6.7927 - accuracy: 0.0086 - mae: 2.0999\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 933us/step - loss: 8.0255 - accuracy: 0.0086 - mae: 2.0556\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 950us/step - loss: 0.7160 - accuracy: 0.0086 - mae: 0.6259\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 980us/step - loss: 0.7725 - accuracy: 0.0086 - mae: 0.6691\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 907us/step - loss: 1.9727 - accuracy: 0.0086 - mae: 1.0641\n",
      "55/55 [==============================] - 0s 580us/step - loss: 4.5297 - accuracy: 0.0138 - mae: 1.6776\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 901us/step - loss: 3.2708 - accuracy: 0.0086 - mae: 1.5161\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 879us/step - loss: 2.2715 - accuracy: 0.0086 - mae: 1.1855\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 922us/step - loss: 1.9612 - accuracy: 0.0086 - mae: 1.0870\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 879us/step - loss: 1.0911 - accuracy: 0.0086 - mae: 0.7296\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 961us/step - loss: 7.3647 - accuracy: 0.0086 - mae: 2.2170\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 965us/step - loss: 1.4697 - accuracy: 0.0086 - mae: 0.8834\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 4.6098 - accuracy: 0.0086 - mae: 1.6833\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 931us/step - loss: 0.6305 - accuracy: 0.0086 - mae: 0.5775\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 964us/step - loss: 3.2474 - accuracy: 0.0086 - mae: 1.5231\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 987us/step - loss: 2.6435 - accuracy: 0.0086 - mae: 1.2524\n",
      "55/55 [==============================] - 0s 642us/step - loss: 5.8686 - accuracy: 0.0138 - mae: 1.5656\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 978us/step - loss: 3.6731 - accuracy: 0.0086 - mae: 1.6183\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 875us/step - loss: 1.8059 - accuracy: 0.0086 - mae: 1.0613\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 3.3712 - accuracy: 0.0086 - mae: 1.5305\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 3.9653 - accuracy: 0.0086 - mae: 1.6848\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 944us/step - loss: 2.8945 - accuracy: 0.0086 - mae: 1.3353\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 992us/step - loss: 0.7641 - accuracy: 0.0086 - mae: 0.6561\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 952us/step - loss: 1.5223 - accuracy: 0.0086 - mae: 0.9344\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 967us/step - loss: 1.7940 - accuracy: 0.0086 - mae: 1.1105\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 6.0988 - accuracy: 0.0086 - mae: 1.9983\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 917us/step - loss: 1.2430 - accuracy: 0.0086 - mae: 0.8741\n",
      "55/55 [==============================] - 0s 696us/step - loss: 1.0982 - accuracy: 0.0138 - mae: 0.7713\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.0086 - mae: 0.4855\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 876us/step - loss: 0.4698 - accuracy: 0.0086 - mae: 0.5173\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 894us/step - loss: 6.3255 - accuracy: 0.0081 - mae: 1.9822\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 900us/step - loss: 0.8700 - accuracy: 0.0086 - mae: 0.6833\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 894us/step - loss: 1.4692 - accuracy: 0.0086 - mae: 0.9349\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 931us/step - loss: 4.2362 - accuracy: 0.0086 - mae: 1.7829\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 963us/step - loss: 4.8077 - accuracy: 0.0086 - mae: 1.7548\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 926us/step - loss: 1.1262 - accuracy: 0.0086 - mae: 0.8264\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 921us/step - loss: 0.6328 - accuracy: 0.0086 - mae: 0.5893\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 945us/step - loss: 4.5722 - accuracy: 0.0086 - mae: 1.8247\n",
      "55/55 [==============================] - 0s 696us/step - loss: 13.2861 - accuracy: 0.0138 - mae: 2.6635\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 2.1035 - accuracy: 0.0086 - mae: 1.1211\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 972us/step - loss: 1.7536 - accuracy: 0.0086 - mae: 1.0952\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 909us/step - loss: 1.2738 - accuracy: 0.0086 - mae: 0.8385\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 899us/step - loss: 0.6856 - accuracy: 0.0086 - mae: 0.6313\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 923us/step - loss: 4.1087 - accuracy: 0.0086 - mae: 1.5818\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 963us/step - loss: 5.3059 - accuracy: 0.0086 - mae: 1.9069\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 932us/step - loss: 2.1348 - accuracy: 0.0086 - mae: 1.1768\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 981us/step - loss: 0.7301 - accuracy: 0.0086 - mae: 0.6536\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 936us/step - loss: 1.0195 - accuracy: 0.0086 - mae: 0.7948\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 897us/step - loss: 2.9477 - accuracy: 0.0086 - mae: 1.4168\n",
      "55/55 [==============================] - 0s 847us/step - loss: 9.9621 - accuracy: 0.0138 - mae: 2.4964\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 8.8781 - accuracy: 0.0086 - mae: 2.4369\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 954us/step - loss: 13.1870 - accuracy: 0.0086 - mae: 1.8189\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 890us/step - loss: 0.4329 - accuracy: 0.0086 - mae: 0.4824\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 880us/step - loss: 0.9199 - accuracy: 0.0086 - mae: 0.7595\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 954us/step - loss: 2.1179 - accuracy: 0.0086 - mae: 1.1887\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 931us/step - loss: 5.6495 - accuracy: 0.0086 - mae: 1.6807\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.7823 - accuracy: 0.0086 - mae: 1.0172\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.0086 - mae: 0.5865\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 949us/step - loss: 2.4646 - accuracy: 0.0086 - mae: 1.2945\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 918us/step - loss: 1.2902 - accuracy: 0.0086 - mae: 0.8387\n",
      "55/55 [==============================] - 0s 828us/step - loss: 7.3911 - accuracy: 0.0138 - mae: 2.1632\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 2.8812 - accuracy: 0.0086 - mae: 1.3696\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 939us/step - loss: 2.4901 - accuracy: 0.0086 - mae: 1.3020\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 900us/step - loss: 1.8264 - accuracy: 0.0086 - mae: 1.1143\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 962us/step - loss: 0.8221 - accuracy: 0.0086 - mae: 0.7196\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 950us/step - loss: 2.2368 - accuracy: 0.0086 - mae: 1.2687\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 911us/step - loss: 5.7418 - accuracy: 0.0086 - mae: 2.0427\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 909us/step - loss: 2.5365 - accuracy: 0.0086 - mae: 1.3194\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 964us/step - loss: 2.6505 - accuracy: 0.0086 - mae: 1.1670\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 979us/step - loss: 2.0823 - accuracy: 0.0086 - mae: 1.1030\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 980us/step - loss: 1.3250 - accuracy: 0.0086 - mae: 0.9456\n",
      "55/55 [==============================] - 0s 766us/step - loss: 1.6802 - accuracy: 0.0138 - mae: 1.0368\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.0086 - mae: 0.5838\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 3.5365 - accuracy: 0.0086 - mae: 1.2961\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 957us/step - loss: 3.7410 - accuracy: 0.0086 - mae: 1.6655\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 977us/step - loss: 2.6712 - accuracy: 0.0086 - mae: 1.3604\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 970us/step - loss: 3.7432 - accuracy: 0.0086 - mae: 1.5991\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 958us/step - loss: 1.0840 - accuracy: 0.0086 - mae: 0.8247\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 969us/step - loss: 2.1647 - accuracy: 0.0086 - mae: 1.2365\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 886us/step - loss: 0.3962 - accuracy: 0.0086 - mae: 0.4729\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 992us/step - loss: 0.4726 - accuracy: 0.0086 - mae: 0.5236\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 956us/step - loss: 0.4802 - accuracy: 0.0086 - mae: 0.5288\n",
      "55/55 [==============================] - 0s 873us/step - loss: 0.4857 - accuracy: 0.0138 - mae: 0.4909\n",
      "0.4856893718242645\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "perdidaObj = 1.0\n",
    "x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "while x[0]>perdidaObj:\n",
    "    red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "    \n",
    "#La forma más efectiva que hemos encontrado para mejorar nuestra red ha sido la de hacer este bulce ya que es la unica forma de asegurarnos que la red obtendrá la precisión que busquemos\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c731f011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 869us/step - loss: 0.4857 - accuracy: 0.0138 - mae: 0.4909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4856893718242645, 0.01380897592753172, 0.4908984899520874]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_bikes.evaluate(attr_prueba, obj_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e05ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 14) for input KerasTensor(type_spec=TensorSpec(shape=(None, 14), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None,).\n",
      "Esperado 203: [[203.32864]]\n",
      "Esperado 247: [[247.82838]]\n",
      "Esperado 315: [[314.24667]]\n",
      "Esperado 214: [[214.22534]]\n",
      "Esperado 164: [[163.69948]]\n",
      "Esperado 122: [[122.4286]]\n",
      "Esperado 119: [[119.35513]]\n",
      "Esperado 89: [[88.881035]]\n",
      "Esperado 90: [[89.82107]]\n",
      "Esperado 61: [[60.653378]]\n",
      "Esperado 49: [[49.06395]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "\n",
    "X=attr[17368]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr[17369]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr[17370]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr[17371]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr[17372]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr[17373]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr[17374]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr[17375]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr[17376]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr[17377]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr[17378]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9aa5e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 4.718690736478711\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_bikes = RandomForestRegressor()#Creamos el randomForest\n",
    "forest_bikes.fit(attr_entrenamiento, obj_entrenamiento)#Lo entrenamos\n",
    "evaluaciones = forest_bikes.predict(attr_prueba)#Evaluamos el modelo\n",
    "mse = mean_squared_error(obj_prueba, evaluaciones)#Calculamos la perdida\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d16b5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 203: [202.83]\n",
      "Esperado 247: [246.56]\n",
      "Esperado 315: [314.63]\n",
      "Esperado 214: [214.57]\n",
      "Esperado 164: [164.08]\n",
      "Esperado 122: [122.11]\n",
      "Esperado 119: [118.88]\n",
      "Esperado 89: [88.98]\n",
      "Esperado 90: [89.76]\n",
      "Esperado 61: [61.05]\n",
      "Esperado 49: [49.18]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "attr2 = attr[:, np.newaxis]\n",
    "X=attr2[17368]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr2[17369]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr2[17370]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr2[17371]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr2[17372]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr2[17373]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr2[17374]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr2[17375]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr2[17376]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr2[17377]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr2[17378]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc6c7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo LIME\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Partiremos de este seudocódigo para implementar el metodo\n",
    "N es el n´umero de permutaciones a realizar\n",
    "f es el modelo a explicar\n",
    "X′ ← {} muestras perturbadas\n",
    "R ← {} representaciones\n",
    "W ← {} las distancias entre la muestra x y sus perturbaciones\n",
    "for 1\n",
    "to\n",
    "N do\n",
    "Selecciona k atributos aleatoriamente\n",
    "x′ ← una perturbaci´on de x donde se perturban los k atributos anteriores.\n",
    "w ← la distancia entre x y x′\n",
    "r ← la representaci´on de x′ respecto a x\n",
    "X′ ← X′ ∪ x′\n",
    "R ← R ∪ r\n",
    "W ← R ∪ w\n",
    "end for\n",
    "Y ′ ← f(X′) las predicciones de las perturbaciones\n",
    "G ← modelo ridge entrenado con R para predecir Y ′ y ponderando cada\n",
    "muestra con W\n",
    "return los par´ametros de G\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def explain_model(f, x, N,M):\n",
    "    #f es el modelo a explicar\n",
    "    #X es una lista de ejemplos a los que se aplicará LIME\n",
    "    #N es el número de permutaciones a realizar\n",
    "    #M contiene todos los ejemplos\n",
    "    #Si queremos que el algoritmo cumpla la metrica identidad necesitamos fijar semillas para la aleatoriedad\n",
    "    random.seed(11)\n",
    "    Xi = [] #Aqui guardaremos las muestras perturbadas\n",
    "    R = []  #Aqui guardaremos las representaciones\n",
    "    W = []  #Aqui guradaremos las distancias\n",
    "    for i in range(N):\n",
    "        k = random.randint(1, len(x)) #Escojo un número aletario que representa el número de los atributos a seleccionar\n",
    "        perturbed_x = x.copy() #copio la muestra original\n",
    "        for j in range(k): \n",
    "            perturbed_attr = random.randint(0,len(x)-1)#Voy escojiento los atributos que perturbare de forma aleatoria\n",
    "            mx = abs(max([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor máximo\n",
    "            mn = abs(min([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor mínimo\n",
    "            perturbed_x[perturbed_attr] = random.uniform(mn, mx) # pertubo el atributo con un valor aleatorio ente mn y mx para que el valor esté acotado\n",
    "        w = abs(sum([x[attr] - perturbed_x[attr] for attr in range(0,len(x)-1)])) #Calculo la distancia entre el original y el perturbado\n",
    "        r = [0  if perturbed_x[attr] == x[attr] else 1 for attr in range(0,len(x)-1)] #Calculo la representación del perturbado respecto al original utilizando un operador ternario\n",
    "        Xi.append(perturbed_x) #Acumulo en la lista los perturbados\n",
    "        R.append(r)#Acumulamos en la lista de representaciones\n",
    "        W.append(w)#Añadimos las distancias a la lista\n",
    "    Y_perturbed = []#Aqui guardaremos las predicciones de las perturbaciones\n",
    "    for i in range(len(Xi)):\n",
    "        y = 1\n",
    "            #En los siguiente if y else comprobamos el tipo de modelo que tenemos ya que dependiendo del tipo necesita recibir los atributos de una forma u otra\n",
    "        if isinstance(f, keras.Sequential):#Comprueba si el modelo es una red neuronal\n",
    "            xi = Xi[i]\n",
    "            y = f.predict(xi,verbose=0)#Hacemos la prediccion con verbose=0 para no cargar la salida de lineas generadas por keras\n",
    "        else: #Si no, es un randomForest\n",
    "            xi = Xi[i]\n",
    "            array = np.array(xi)\n",
    "            xi = array.reshape(1, -1)\n",
    "            y = f.predict(xi)#RandomForest no tiene verbose porque no genera nada\n",
    "                \n",
    "            \n",
    "        Y_perturbed.append(y) #Aplico el modelo f a los ejemplos perturbados\n",
    "            \n",
    "    Y_perturbed = np.squeeze(Y_perturbed) #Por alguna razón aparece el error Found array with dim 3. Estimator expected <= 2\" y lo arreglamos con esta linea que quita una dimensión al array\n",
    "    G = Ridge()\n",
    "    G.fit(R, Y_perturbed, sample_weight=W)\n",
    "    return G.coef_#Devolvemos los parametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd8cf2d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02432406,  0.01243588,  0.01662844, -0.05516985,  0.00396146,\n",
       "       -0.02734023, -0.04393756, -0.05084051, -0.04591982,  0.01510503,\n",
       "        0.01737612, -0.01700965, -0.05885665,  0.00405327, -0.03006711,\n",
       "       -0.07217951, -0.00999771, -0.02601384, -0.05599222,  0.03124656,\n",
       "       -0.01269099, -0.01405098, -0.0430235 ,  0.04410394, -0.04393756,\n",
       "       -0.01205467, -0.02797656, -0.04434989, -0.04121068, -0.01719019])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos varias pruebas para comprobar que funciona el metodo LIME\n",
    "atributivos = atributos[5809]\n",
    "\n",
    "explain_model(red_evaluation,atributivos,10,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5173d8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02432406,  0.01243588,  0.01662844, -0.05516985,  0.00396146,\n",
       "       -0.02734023, -0.04393756, -0.05084051, -0.04591982,  0.01510503,\n",
       "        0.01737612, -0.01700965, -0.05885665,  0.00405327, -0.03006711,\n",
       "       -0.07217951, -0.00999771, -0.02601384, -0.05599222,  0.03124656,\n",
       "       -0.01269099, -0.01405098, -0.0430235 ,  0.04410394, -0.04393756,\n",
       "       -0.01205467, -0.02797656, -0.04434989, -0.04121068, -0.01719019])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos varias pruebas para comprobar que funciona el metodo LIME\n",
    "atributivos = atributos[5809]\n",
    "\n",
    "explain_model(red_evaluation,atributivos,10,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8f33d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05329193,  0.05785083, -0.02938303, -0.00121754,  0.03118763,\n",
       "        0.02368814, -0.0924245 , -0.04637594, -0.07885433, -0.12118314,\n",
       "        0.06010089, -0.0124536 , -0.00507487,  0.05150461, -0.11055356,\n",
       "       -0.01367114, -0.01184712, -0.05904895, -0.10843869,  0.04197182,\n",
       "       -0.05045268, -0.06335174, -0.07150255,  0.02386253, -0.0924245 ,\n",
       "       -0.0160142 , -0.01075033,  0.01123454,  0.04181721, -0.0939344 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atributivos = atributos[5809]\n",
    "\n",
    "explain_model(forest_evaluation,atributivos,10,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "634110b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -14.41166898, -108.19534129,  183.00625567,   76.05185988,\n",
       "         34.30216426, -164.87356029,  133.62825227,  -97.76374446,\n",
       "         37.47019646,   -3.57918921,  -51.81973685,  -48.83394444,\n",
       "        150.88655541])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attri = attr[17378]\n",
    "\n",
    "explain_model(red_bikes,attri,10,attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c2effc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -26.3872849 ,  -95.85683724,  190.29437754,   63.31487811,\n",
       "         50.39551782, -160.89999858,  147.04929586, -111.50024267,\n",
       "         20.8976087 ,  -18.79098559,  -52.05029761,  -64.21018778,\n",
       "        127.66247407])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attri = attr[17378]\n",
    "\n",
    "explain_model(forest_bikes,attri,10,attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a56246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#En la definición de cada metrica se importarán las cosas necesarias por si solo se quiere probar una metrica\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def identidad(x1,x2,exp1,exp2):\n",
    "    #Definición: El principio de identidad establece que objetos idénticos deben recibir explicaciones idénticas.\n",
    "\n",
    "    res = True #Si los objetos no son identicos no hay que valuar\n",
    "    distance = np.linalg.norm(x1 - x2)#Calcula las distancias entre los dos ejemplos\n",
    "    if(distance ==0):   #Solo comprobamos si las explicaciones sean identicas si los objetos son identicos\n",
    "        res = np.linalg.norm(exp1 - exp2) ==0#Comprobamos si ambas explicaciones son iguales\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b089f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ejemplo2=attr[17375]\n",
    "ejemplo1 = attr[17375]\n",
    "print(ejemplo2)\n",
    "print(ejemplo1)\n",
    "exp1 = explain_model(forest_bikes,ejemplo1,2,attr)\n",
    "exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "print(identidad(ejemplo1,ejemplo2,exp1,exp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a59b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def separabilidad(x1,x2,exp1,exp2):\n",
    "#Definición:#Separabilidad: Objetos no idénticos no pueden tener explicaciones idénticas. Para simplificar, cada característica \n",
    "#tiene un nivel mínimo de importancia, positivo o negativo, en las predicciones.\n",
    "\n",
    "    res = True\n",
    "    distance = np.linalg.norm(x1 - x2)#Calcula las distancias entre los dos ejemplos\n",
    "    if(distance >0):   #Si la distancia es distinta de cero\n",
    "        res = not(np.linalg.norm(exp1 - exp2) ==0)#Si las explicaciones son distintas se cumple la separabilidad\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "018fbb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         1.         0.91304348 0.         0.16666667\n",
      " 1.         0.         0.24489796 0.2576     0.6        0.19301751\n",
      " 0.01907357 0.09367946]\n",
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ejemplo2=attr[17376]\n",
    "ejemplo1 = attr[17375]\n",
    "print(ejemplo2)\n",
    "print(ejemplo1)\n",
    "exp1 = explain_model(forest_bikes,ejemplo1,2,attr)\n",
    "exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "print(separabilidad(ejemplo1,ejemplo2,exp1,exp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ce5cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def estabilidad(x1,x2,exp1,exp2,umbEj,umbExp):\n",
    "    #Objetos similares deben tener explicaciones similares\n",
    "    #Para esto calcularemos la correlacion de Spearman para los ejemplos, si superan el limite que se pasará a la función\n",
    "    #Calcularemos la correlación de Spearman para las explicaciones y comprobaremos si supera el umbral, en ese caso, cumpliran la estabilidad\n",
    "    res = True\n",
    "    correlacionEj, _ = spearmanr(x1, x2)\n",
    "    if(abs(correlacionEj) >= umbEj):\n",
    "        correlacionExp, _ = spearmanr(exp1,exp2)\n",
    "        res = abs(correlacionExp)>=umbExp \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1abc14ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         1.         0.91304348 0.         0.16666667\n",
      " 1.         0.         0.24489796 0.2576     0.6        0.19301751\n",
      " 0.01907357 0.09367946]\n",
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "SpearmanrResult(correlation=0.8770812523243259, pvalue=3.801615077865054e-05)\n",
      "SpearmanrResult(correlation=1.0, pvalue=0.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ejemplo2=attr[17376]\n",
    "ejemplo1 = attr[17375]\n",
    "print(ejemplo2)\n",
    "print(ejemplo1)\n",
    "print(spearmanr(ejemplo1, ejemplo2))\n",
    "exp1 = explain_model(forest_bikes,ejemplo1,2,attr)\n",
    "exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "print(spearmanr(exp1, exp2))\n",
    "print(estabilidad(ejemplo1,ejemplo2,exp1,exp2,0.75,0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0dc5db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherencia(mae1, mae2):\n",
    "    #Se calcula la diferencia entre el error de predicción (mae1) sobre la señal original y el error de predicción mae2\n",
    "    #de una nueva señaal donde se eliminan las características no importantes.\n",
    "    alpha_i = abs(mae1 - mae2)\n",
    "    return alpha_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "96098651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completitud(ei, pi):\n",
    "    #Evalúa el porcentaje de error de explicaci´on con respecto al error de predicci´on.\n",
    "    gamma_i = ei / pi\n",
    "    return gamma_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1f997bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def congruencia(coherencias):\n",
    "    #Esta m´etrica ayuda a capturar la variabilidad de la coherencia.\n",
    "    coherencia_media = np.mean(coherencias)\n",
    "    res = (sum((c - coherencia_media)**2 for c in coherencias)/len(coherencias))*0.5\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobaremos la métrica identidad\n",
    "#Para comprobarla recorreremos 256 ejemplos en los cuatro modelos y para cada ejemplo en cada modelo generaremos la explicacion dos veces y comprobaremos que es la misma explicación\n",
    "atributivos = atributos[5553:5809,:]\n",
    "sonIguales = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "if(sonIguales):\n",
    "    print(\"El modelo RandomForest de evaluación cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de evaluación no cumple la métrica identidad\")\n",
    "\n",
    "sonIguales=True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(red_evaluation,x,2,atributos)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "\n",
    "if(sonIguales):\n",
    "    print(\"El modelo Red neuronal de evaluación cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de evaluación no cumple la métrica identidad\")\n",
    "\n",
    "X=attr[17122:17378,:]\n",
    "sonIguales=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    exp2 = explain_model(red_bikes,x,2,attr)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "    \n",
    "if(sonIguales):\n",
    "    print(\"El modelo Red neuronal de bikes cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de bikes no cumple la métrica identidad\")\n",
    "    \n",
    "sonIguales=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    exp2 = explain_model(forest_bikes,x,2,attr)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "    \n",
    "if(sonIguales):\n",
    "    print(\"El modelo RandomForest de bikes cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de bikes no cumple la métrica identidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobaremos la métrica separabilidad\n",
    "#Para comprobarla recorreremos 256 ejemplos en los cuatro modelos y los comparamos con otro ejemplo\n",
    "ejemplo1=atributos[5552]\n",
    "atributivos = atributos[5553:5809,:]\n",
    "cumpleSeparabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(forest_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo1,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo RandomForest de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "cumpleSeparabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(red_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo1,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "\n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo Red neuronal de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "ejemplo2 = attr[17121]\n",
    "X=attr[17122:17378,:]\n",
    "cumpleSeparabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    exp2 = explain_model(red_bikes,ejemplo2,2,attr)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo2,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo Red neuronal de bikes cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de bikes no cumple la métrica separabilidad\")\n",
    "    \n",
    "cumpleSeparabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo2,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo RandomForest de bikes cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de bikes no cumple la métrica separabilidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e820b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobaremos la métrica estabilidad\n",
    "#Para comprobarla recorreremos 256 ejemplos en los cuatro modelos y los comparamos con otro ejemplo, del cual sabemos que hay ejemplos muy similares\n",
    "\n",
    "ejemplo1=atributos[5819]\n",
    "atributivos = atributos[5553:5819,:]\n",
    "cumpleEstabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(forest_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo1,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo RandomForest de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "cumpleEstabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(red_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo1,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "\n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo Red neuronal de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "ejemplo2 = attr[17376]\n",
    "X=attr[17122:17378,:]\n",
    "cumpleEstabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    exp2 = explain_model(red_bikes,ejemplo2,2,attr)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo2,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo Red neuronal de bikes cumple la métrica estabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de bikes no cumple la métrica estabilidad\")\n",
    "    \n",
    "cumpleEstabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo2,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo RandomForest de bikes cumple la métrica estabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de bikes no cumple la métrica estabilidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "de4d1b73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo Red Neuronal de evaluación tiene unas coherencias de  [array([[0.41273785]], dtype=float32), array([[0.3842566]], dtype=float32), array([[0.02560365]], dtype=float32), array([[0.4968462]], dtype=float32), array([[0.03610516]], dtype=float32), array([[0.02560365]], dtype=float32), array([[3.2215283]], dtype=float32), array([[3.4691548]], dtype=float32), array([[0.02642548]], dtype=float32)]\n",
      "El modelo RandomForest de evaluación tiene una coherencia de  [array([0.14]), array([0.14]), array([2.]), array([0.14]), array([1.48]), array([2.]), array([1.51]), array([1.56]), array([2.])]\n",
      "El modelo Red Neuronal de bikes tiene unas coherencias de  [array([[28.369654]], dtype=float32), array([[0.65042496]], dtype=float32), array([[43.60202]], dtype=float32), array([[146.46884]], dtype=float32), array([[103.78969]], dtype=float32), array([[47.369095]], dtype=float32), array([[74.311806]], dtype=float32), array([[131.6389]], dtype=float32), array([[124.86778]], dtype=float32), array([[143.6443]], dtype=float32), array([[201.2306]], dtype=float32), array([[143.23056]], dtype=float32), array([[109.68829]], dtype=float32), array([[72.21177]], dtype=float32), array([[67.98506]], dtype=float32), array([[42.233673]], dtype=float32), array([[43.848274]], dtype=float32), array([[8.839615]], dtype=float32)]\n",
      "El modelo RandomForest de bikes tiene una coherencia de  [array([31.]), array([0.05]), array([43.86]), array([150.39]), array([107.75]), array([45.74]), array([74.95]), array([136.26]), array([128.12]), array([147.36]), array([208.42]), array([145.64]), array([111.98]), array([72.91]), array([69.17]), array([43.57]), array([44.09]), array([8.46])]\n"
     ]
    }
   ],
   "source": [
    "#Para probar la coherencia lo que haremos será para varias muestras muestras, generar una predicción, generar su explicación \n",
    "#y a partir de su explicación quitaremos los N atributos menos importantes y generaremos otra explicación, a partir de ambas predicciones \n",
    "#calcularemos dos MAE y con ello calcularemos la coherencia\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "atributivos = atributos[5810:5819,:]\n",
    "objetivos = objetivo[5810:5819]\n",
    "\n",
    "N=2\n",
    "#predicciones1 = []\n",
    "#predicciones2 = []\n",
    "coherencias = []\n",
    "\n",
    "for i in range(len(atributivos)):\n",
    "    x = atributivos[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    prediccion1 = red_evaluation.predict(x,verbose=0)\n",
    "    #predicciones1.append(prediccion1)np.squeeze(predicciones1)  \n",
    "    errp = abs(objetivos[i]-prediccion1)\n",
    "   \n",
    "    for j in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 99999999999999999\n",
    "    prediccion2 = red_evaluation.predict(y,verbose=0)\n",
    "   \n",
    "    errexp = abs(objetivos[i]-prediccion2)\n",
    "    coherencias.append(abs(errp-errexp))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "print(\"El modelo Red Neuronal de evaluación tiene unas coherencias de \",coherencias)\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "for i in range(len(atributivos)):\n",
    "    x = atributivos[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    x = x.reshape(1, -1)\n",
    "    prediccion1 = forest_evaluation.predict(x)\n",
    "    errp = abs(objetivos[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 999999999999999999\n",
    "    y = y.reshape(1, -1)\n",
    "    prediccion2 = forest_evaluation.predict(y)\n",
    "      \n",
    "    errexp = abs(objetivos[i]-prediccion2)\n",
    "    coherencias.append(abs(errp-errexp))\n",
    "    \n",
    "\n",
    "print(\"El modelo RandomForest de evaluación tiene una coherencia de \",coherencias)\n",
    "\n",
    "X=attr[17360:17378,:]\n",
    "objs = obj[17360:17378]\n",
    "\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "    x = X[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    prediccion1 = red_bikes.predict(x,verbose=0)\n",
    "    errp = abs(objs[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 99999999999999999\n",
    "    prediccion2 = red_bikes.predict(y,verbose=0)\n",
    "       \n",
    "    errexp = abs(objs[i]-prediccion2)\n",
    "    coherencias.append(abs(errp-errexp))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "print(\"El modelo Red Neuronal de bikes tiene unas coherencias de \",coherencias)\n",
    "\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "for i in range(0,len(X)):\n",
    "    x = X[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    x = x.reshape(1, -1)\n",
    "    prediccion1 = forest_bikes.predict(x)\n",
    "    errp = abs(objs[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 999999999999999999\n",
    "    y = y.reshape(1, -1)\n",
    "    prediccion2 = forest_bikes.predict(y)\n",
    "    errexp = abs(objs[i]-prediccion2)\n",
    "    coherencias.append(abs(errp-errexp))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "print(\"El modelo RandomForest de bikes tiene una coherencia de \",coherencias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5fe7681a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo Red Neuronal de evaluación tiene una completitud de  13.392608405429794\n",
      "El modelo RandomForest de evaluación tiene una completitud de  102.73186202676735\n",
      "El modelo Red Neuronal de bikes tiene una completitud de  787.5287067597895\n",
      "El modelo RandomForest de bikes tiene una completitud de  774.6354066321936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "atributivos = atributos[5810:5819,:]\n",
    "objetivos = objetivo[5810:5819]\n",
    "\n",
    "atributos2 = evaluation.loc[:, 'class':'Q27']\n",
    "atributos2 = atributos2.to_numpy()\n",
    "atributos2 = atributos2[5810:5819,:]\n",
    "predicciones1 = []\n",
    "predicciones2 = []\n",
    "for j in range(len(atributivos)):\n",
    "    x = atributivos[j]\n",
    "    pred1 = red_evaluation.predict(x,verbose = 0)\n",
    "    predicciones1.append(pred1)\n",
    "    y = 0\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    atributo2 = atributos2[j]\n",
    "    for i in range(len(exp1)):\n",
    "        y += exp1[i]*atributo2[i]\n",
    "    predicciones2.append(y)\n",
    "\n",
    "predicciones1 = np.squeeze(predicciones1)  \n",
    "predicciones2 = np.squeeze(predicciones2) \n",
    "mae1 = mean_absolute_error(objetivos, predicciones1)\n",
    "mae2 = mean_absolute_error(objetivos, predicciones2)\n",
    "\n",
    "completitud = mae2/mae1\n",
    "print(\"El modelo Red Neuronal de evaluación tiene unas completitudes de \",completitud)\n",
    "\n",
    "predicciones1 = []\n",
    "predicciones2 = []\n",
    "for j in range(len(atributivos)):\n",
    "    x = atributivos[j]\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    x = x.reshape(1,-1)\n",
    "    pred1 = forest_evaluation.predict(x)\n",
    "    predicciones1.append(pred1)\n",
    "    y = 0\n",
    "    atributo2 = atributos2[j]\n",
    "    for i in range(len(exp1)):\n",
    "        y += exp1[i]*atributo2[i]\n",
    "    predicciones2.append(y)\n",
    "\n",
    "predicciones1 = np.squeeze(predicciones1)  \n",
    "predicciones2 = np.squeeze(predicciones2) \n",
    "mae1 = mean_absolute_error(objetivos, predicciones1)\n",
    "mae2 = mean_absolute_error(objetivos, predicciones2)\n",
    "\n",
    "completitud = mae2/mae1\n",
    "print(\"El modelo RandomForest de evaluación tiene una completitud de \",completitud)\n",
    "\n",
    "\n",
    "X = attr[17360:17378,:]\n",
    "objs = obj[17360:17378]\n",
    "\n",
    "attr2 = bikes.loc[:, 'season':'registered']\n",
    "attr2 = attr2.to_numpy()\n",
    "attr2 = attr2[17360:17378,:]\n",
    "predicciones1 = []\n",
    "predicciones2 = []\n",
    "for j in range(len(X)):\n",
    "    x = X[j]\n",
    "    pred1 = red_bikes.predict(x,verbose = 0)\n",
    "    predicciones1.append(pred1)\n",
    "    y = 0\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    atributo2 = attr2[j]\n",
    "    for i in range(len(exp1)):\n",
    "        y += exp1[i]*atributo2[i]\n",
    "    predicciones2.append(y)\n",
    "\n",
    "predicciones1 = np.squeeze(predicciones1)  \n",
    "predicciones2 = np.squeeze(predicciones2) \n",
    "mae1 = mean_absolute_error(objs, predicciones1)\n",
    "mae2 = mean_absolute_error(objs, predicciones2)\n",
    "\n",
    "completitud = mae2/mae1\n",
    "print(\"El modelo Red Neuronal de bikes tiene una completitud de \",completitud)\n",
    "\n",
    "predicciones1 = []\n",
    "predicciones2 = []\n",
    "for j in range(len(X)):\n",
    "    x = X[j]\n",
    "    exp1 = explain_model(forest_bikes,x,2,atributos)\n",
    "    x = x.reshape(1,-1)\n",
    "    pred1 = forest_bikes.predict(x)\n",
    "    predicciones1.append(pred1)\n",
    "    y = 0\n",
    "    atributo2 = attr2[j]\n",
    "    for i in range(len(exp1)):\n",
    "        y += exp1[i]*atributo2[i]\n",
    "    predicciones2.append(y)\n",
    "\n",
    "predicciones1 = np.squeeze(predicciones1)  \n",
    "predicciones2 = np.squeeze(predicciones2) \n",
    "mae1 = mean_absolute_error(objs, predicciones1)\n",
    "mae2 = mean_absolute_error(objs, predicciones2)\n",
    "\n",
    "completitud = mae2/mae1\n",
    "print(\"El modelo RandomForest de bikes tiene una completitud de \",completitud)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b2d5d020",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4236\\1700179002.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mcoherencias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoherencias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mcongruencia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcongruencia\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoherencias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "atributivos = atributos[5810:5819,:]\n",
    "objetivos = objetivo[5810:5819]\n",
    "\n",
    "N=2\n",
    "#predicciones1 = []\n",
    "#predicciones2 = []\n",
    "coherencias = []\n",
    "\n",
    "for i in range(len(atributivos)):\n",
    "    x = atributivos[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    prediccion1 = red_evaluation.predict(x,verbose=0)\n",
    "    #predicciones1.append(prediccion1)np.squeeze(predicciones1)  \n",
    "    errp = abs(objetivos[i]-prediccion1)\n",
    "   \n",
    "    for j in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 99999999999999999\n",
    "    prediccion2 = red_evaluation.predict(y,verbose=0)\n",
    "   \n",
    "    errexp = abs(objetivos[i]-prediccion2)\n",
    "    coherencias.append(abs(errp-errexp))\n",
    "    \n",
    "\n",
    "coherencias = list(coherencias)\n",
    "congruencia = congruencia(coherencias)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"El modelo Red Neuronal de evaluación tiene una congruencia de \",congruencia)\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "for i in range(len(atributivos)):\n",
    "    x = atributivos[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    x = x.reshape(1, -1)\n",
    "    prediccion1 = forest_evaluation.predict(x)\n",
    "    errp = abs(objetivos[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 999999999999999999\n",
    "    y = y.reshape(1, -1)\n",
    "    prediccion2 = forest_evaluation.predict(y)\n",
    "      \n",
    "    errexp = abs(objetivos[i]-prediccion2)\n",
    "    coherencias.append(abs(errp-errexp))\n",
    "    \n",
    "coherencias = list(coherencias)\n",
    "congruencia = congruencia(coherencias)\n",
    "\n",
    "print(\"El modelo RandomForest de evaluación tiene una congruencia de \",congruencia)\n",
    "\n",
    "X=attr[17360:17378,:]\n",
    "objs = obj[17360:17378]\n",
    "\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "    x = X[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    prediccion1 = red_bikes.predict(x,verbose=0)\n",
    "    errp = abs(objs[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 99999999999999999\n",
    "    prediccion2 = red_bikes.predict(y,verbose=0)\n",
    "       \n",
    "    errexp = abs(objs[i]-prediccion2)\n",
    "    coherencias.append(abs(errp-errexp))\n",
    "\n",
    "coherencias = list(coherencias)\n",
    "congruencia = congruencia(coherencias)    \n",
    "\n",
    "print(\"El modelo Red Neuronal de bikes tiene una congruencia de \",congruencia)\n",
    "\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "for i in range(0,len(X)):\n",
    "    x = X[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    x = x.reshape(1, -1)\n",
    "    prediccion1 = forest_bikes.predict(x)\n",
    "    errp = abs(objs[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 999999999999999999\n",
    "    y = y.reshape(1, -1)\n",
    "    prediccion2 = forest_bikes.predict(y)\n",
    "    errexp = abs(objs[i]-prediccion2)\n",
    "    coherencias.append(abs(errp-errexp))\n",
    "    \n",
    "coherencias = list(coherencias)\n",
    "congruencia = congruencia(coherencias)\n",
    "\n",
    "print(\"El modelo RandomForest de bikes tiene una congruencia de \",congruencia)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
