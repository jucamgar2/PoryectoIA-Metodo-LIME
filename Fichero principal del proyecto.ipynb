{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0210de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "#Leemos el csv\n",
    "evaluation = pandas.read_csv('turkiye-student-evaluation_R_Specific.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "40fd7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  ...  \\\n",
       "1       1      2          1           0           4   3   3   3   3   3  ...   \n",
       "2       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "3       1      2          1           2           4   5   5   5   5   5  ...   \n",
       "4       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "5       1      2          1           0           1   1   1   1   1   1  ...   \n",
       "6       1      2          1           3           3   4   4   4   4   4  ...   \n",
       "7       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "8       1      2          1           1           3   5   5   5   5   5  ...   \n",
       "9       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "10      1      2          1           4           4   4   4   4   4   4  ...   \n",
       "\n",
       "    Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  \n",
       "1     3    3    3    3    3    3    3    3    3    3  \n",
       "2     3    3    3    3    3    3    3    3    3    3  \n",
       "3     5    5    5    5    5    5    5    5    5    5  \n",
       "4     3    3    3    3    3    3    3    3    3    3  \n",
       "5     1    1    1    1    1    1    1    1    1    1  \n",
       "6     4    4    4    4    4    4    4    4    4    4  \n",
       "7     4    4    4    4    4    4    4    4    4    4  \n",
       "8     5    5    5    5    5    5    5    5    5    5  \n",
       "9     4    4    4    4    4    4    4    4    4    4  \n",
       "10    4    4    4    4    4    4    4    4    4    4  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bien\n",
    "evaluation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9259e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.   0.25 0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos \n",
    "atributos = evaluation.loc[:, 'class':'Q27']\n",
    "atributos = atributos.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "atributos = scaler.fit_transform(atributos)\n",
    "print(atributos[5818,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b22a5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 5. ... 5. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos el objetivo\n",
    "objetivo = evaluation['Q28']\n",
    "objetivo = evaluation['Q28'].to_numpy(dtype=np.float32)\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "141c7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos los datos que se usaran para entrenar y los que se usarán para evaluar los modelos\n",
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6ff2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()#Definimos un normalizador\n",
    "normalizador.adapt(atributos_entrenamiento)\n",
    "red_evaluation = keras.Sequential()#Creamos la red neuronal\n",
    "red_evaluation.add(keras.layers.Input(shape=(31,)))#Definimos la capa de entrada con una neurona por cada atributo\n",
    "red_evaluation.add(normalizador)#Aplicamos el normalizador\n",
    "red_evaluation.add(keras.layers.Dense(70, activation='relu'))#Definimos una capa con 70 neuronas y función de activación relu\n",
    "red_evaluation.add(keras.layers.Dense(70, activation='sigmoid'))#Definimos una capa de 70 neuronas y función de activación sigmoide\n",
    "red_evaluation.add(keras.layers.Dense(1, activation='linear')) #Defnimios una capa de salida con función de activación lienal ya que los valores esperados son números lineales entre 0 y 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b8a17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_2 (Normalizat  (None, 31)               63        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 70)                2240      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,344\n",
      "Trainable params: 7,281\n",
      "Non-trainable params: 63\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_evaluation.summary()#Mostramos un resumen de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3114e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s 2ms/step - loss: 2.7755 - accuracy: 0.1326 - mae: 1.1793 \n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.1405 - mae: 0.4605\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.1405 - mae: 0.3584\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.1405 - mae: 0.3329\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.1405 - mae: 0.3228\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.1405 - mae: 0.3217\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.1405 - mae: 0.3128\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.1405 - mae: 0.3104\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.1405 - mae: 0.3061\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.1405 - mae: 0.3033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b478b3a850>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "red_evaluation.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])#Compilamos la red neuronal definiendo el optimizaodr, la función de perdida y dos metricas\n",
    "red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)#Entrenamos la red neuronal con 10 epocas y lotes de 256 elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "29d4f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.1340 - mae: 0.2808\n",
      "0.24028357863426208\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "#Para este conjunto de datos esto practicamente no es necesario pero así nos aseguramos de cometer un error muy pequeño\n",
    "perdObj = 1.0\n",
    "x=red_evaluation.evaluate(atributos_prueba, objetivo_prueba)\n",
    "while x[0]>perdObj:\n",
    "    red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_evaluation.evaluate(atributos_prueba, objetivo_prueba)\n",
    "    \n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3ad4c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.1340 - mae: 0.2808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24028357863426208, 0.1340206116437912, 0.28082191944122314]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_evaluation.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "84bc4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 31) for input KerasTensor(type_spec=TensorSpec(shape=(None, 31), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None,).\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Esperado 4: [[4.0871906]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Esperado 3: [[3.0435562]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Esperado 3: [[3.1551712]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Esperado 1: [[1.0064591]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Esperado 3: [[3.0156977]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Esperado 1: [[1.1983334]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Esperado 1: [[1.0064591]]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Esperado 5: [[4.730139]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Esperado 5: [[4.845992]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Esperado 1: [[1.0261306]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Esperado 1: [[1.0261306]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "X=atributos[5809]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 4:',predicciones)\n",
    "X=atributos[5810]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5811]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5812]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5813]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5814]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5815]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5816]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos[5817]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos[5818]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5819]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "55821bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 0.24148652713073981\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_evaluation = RandomForestRegressor() #Creamos el modelo\n",
    "forest_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento)#Lo entrenamos\n",
    "evaluaciones = forest_evaluation.predict(atributos_prueba)#Evaluamos\n",
    "mse = mean_squared_error(objetivo_prueba, evaluaciones)#Calculamos la perdida\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)\n",
    "#Como este modelo suele tener una perdida muy pequeña tras entrenarlo una vez, no hacemos nada más para mejorarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a83c67dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 4: [4.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 1: [1.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 1: [1.2]\n",
      "Esperado 1: [1.]\n",
      "Esperado 5: [4.96]\n",
      "Esperado 5: [5.]\n",
      "Esperado 1: [1.]\n",
      "Esperado 1: [1.]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "atributos2 = atributos[:, np.newaxis]\n",
    "X=atributos2[5809]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 4:',predicciones)\n",
    "X=atributos2[5810]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5811]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5812]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5813]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5814]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5815]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5816]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos2[5817]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos2[5818]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5819]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "250f3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear otra red neuronal\n",
    "#Volemos a importar por si se quiere ejecutar este fragmento sin ejecutar el anterior\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#Leemos el csv\n",
    "#bikes = pandas.read_csv('hour.csv', header=0)\n",
    "bikes = pandas.read_csv('hour2.csv',header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0073ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0       1   0     1   0        0        6           0           1  0.24   \n",
       "1       1   0     1   1        0        6           0           1  0.22   \n",
       "2       1   0     1   2        0        6           0           1  0.22   \n",
       "3       1   0     1   3        0        6           0           1  0.24   \n",
       "4       1   0     1   4        0        6           0           1  0.24   \n",
       "5       1   0     1   5        0        6           0           2  0.24   \n",
       "6       1   0     1   6        0        6           0           1  0.22   \n",
       "7       1   0     1   7        0        6           0           1  0.20   \n",
       "8       1   0     1   8        0        6           0           1  0.24   \n",
       "9       1   0     1   9        0        6           0           1  0.32   \n",
       "\n",
       "    atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.2879  0.81     0.0000       3          13   16  \n",
       "1  0.2727  0.80     0.0000       8          32   40  \n",
       "2  0.2727  0.80     0.0000       5          27   32  \n",
       "3  0.2879  0.75     0.0000       3          10   13  \n",
       "4  0.2879  0.75     0.0000       0           1    1  \n",
       "5  0.2576  0.75     0.0896       0           1    1  \n",
       "6  0.2727  0.80     0.0000       2           0    2  \n",
       "7  0.2576  0.86     0.0000       1           2    3  \n",
       "8  0.2879  0.75     0.0000       1           7    8  \n",
       "9  0.3485  0.76     0.0000       8           6   14  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bién\n",
    "bikes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "890b5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.00817439 0.01467269]\n",
      " [0.         0.         0.         ... 0.         0.02179837 0.03611738]\n",
      " [0.         0.         0.         ... 0.         0.01362398 0.03047404]\n",
      " ...\n",
      " [0.         1.         1.         ... 0.19301751 0.01907357 0.09367946]\n",
      " [0.         1.         1.         ... 0.15786999 0.03542234 0.05417607]\n",
      " [0.         1.         1.         ... 0.15786999 0.03269755 0.04176072]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos y los nomalizamos\n",
    "attr = bikes.loc[:, 'season':'registered']\n",
    "attr = attr.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "attr = scaler.fit_transform(attr)\n",
    "\n",
    "print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e783ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16. 40. 32. ... 90. 61. 49.]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los objetivos\n",
    "obj = bikes['cnt']\n",
    "obj = bikes['cnt'].to_numpy(dtype=np.float32)\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6bec2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cogemos un 85% de los datos para entrenar y un 15% de los datos para evaluar el modelo\n",
    "(attr_entrenamiento, attr_prueba,\n",
    " obj_entrenamiento, obj_prueba) = model_selection.train_test_split(\n",
    "    attr, obj, test_size=.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "01172681",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()#Definimos un normalizador\n",
    "normalizador.adapt(attr_entrenamiento)\n",
    "red_bikes = keras.Sequential()#Creamos la red neuronal\n",
    "red_bikes.add(keras.layers.Input(shape=(14,))) #Añadimos la capa de entrada con 14 neuronas, una por cada atributo\n",
    "red_bikes.add(normalizador)#Aplicamos un normalizador\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(1, activation='linear'))#Necesitamos una capa de salida linear ya que los valores objetivos son lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6b9f0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_3 (Normalizat  (None, 14)               29        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               1500      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,730\n",
      "Trainable params: 11,701\n",
      "Non-trainable params: 29\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Vemos un resumen de la red\n",
    "red_bikes.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e5d4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 2ms/step - loss: 13533.7861 - accuracy: 0.0087 - mae: 80.8802\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2811.9653 - accuracy: 0.0088 - mae: 39.7757\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1598.3772 - accuracy: 0.0088 - mae: 31.1913\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 977.5739 - accuracy: 0.0086 - mae: 21.5425\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 796.2078 - accuracy: 0.0081 - mae: 21.0913\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 407.9771 - accuracy: 0.0088 - mae: 15.8295\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 419.1377 - accuracy: 0.0084 - mae: 15.6306\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 299.3969 - accuracy: 0.0088 - mae: 13.9114\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 235.9176 - accuracy: 0.0084 - mae: 11.4948\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 250.2126 - accuracy: 0.0083 - mae: 12.6987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b40cccc580>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compilamos y entrenamos la red neuronal, buscamos minimizar la función de perdida\n",
    "red_bikes.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6aa4bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 2ms/step - loss: 58.0273 - accuracy: 0.0121 - mae: 5.3620\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 167.7412 - accuracy: 0.0084 - mae: 9.6977\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 158.6113 - accuracy: 0.0088 - mae: 10.0131\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 187.0991 - accuracy: 0.0088 - mae: 11.1683\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 151.4776 - accuracy: 0.0088 - mae: 9.8628\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 172.1601 - accuracy: 0.0088 - mae: 10.6888\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 137.1284 - accuracy: 0.0085 - mae: 8.4927\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 88.5596 - accuracy: 0.0087 - mae: 7.2088\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 176.8708 - accuracy: 0.0085 - mae: 10.7779\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 67.4047 - accuracy: 0.0088 - mae: 5.9011\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 112.6705 - accuracy: 0.0088 - mae: 8.9393\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 140.5596 - accuracy: 0.0121 - mae: 9.7125\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 105.4900 - accuracy: 0.0088 - mae: 8.3315\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 117.0924 - accuracy: 0.0088 - mae: 8.1646\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 44.9396 - accuracy: 0.0088 - mae: 5.0611\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 91.6488 - accuracy: 0.0088 - mae: 7.8718\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 84.5941 - accuracy: 0.0088 - mae: 7.6489\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 51.6591 - accuracy: 0.0088 - mae: 5.7984\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 107.5913 - accuracy: 0.0088 - mae: 8.6463\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 82.6156 - accuracy: 0.0086 - mae: 7.4189\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 56.3067 - accuracy: 0.0087 - mae: 5.5132\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 49.8717 - accuracy: 0.0088 - mae: 5.6145\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 50.9335 - accuracy: 0.0121 - mae: 5.5775\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 51.9775 - accuracy: 0.0088 - mae: 5.5422\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 35.1346 - accuracy: 0.0088 - mae: 4.5817\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 61.9881 - accuracy: 0.0088 - mae: 6.4921\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 31.8767 - accuracy: 0.0088 - mae: 4.3481\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 78.7502 - accuracy: 0.0085 - mae: 7.1578\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 50.6509 - accuracy: 0.0088 - mae: 5.9217\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.8158 - accuracy: 0.0088 - mae: 3.9636\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 76.9386 - accuracy: 0.0083 - mae: 7.2690\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 84.0429 - accuracy: 0.0083 - mae: 6.0745\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 47.7977 - accuracy: 0.0084 - mae: 4.7773\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 246.2986 - accuracy: 0.0121 - mae: 11.4475\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.9623 - accuracy: 0.0088 - mae: 3.0002\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 37.9908 - accuracy: 0.0086 - mae: 4.4202\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 21.2290 - accuracy: 0.0088 - mae: 3.5226\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 62.4667 - accuracy: 0.0088 - mae: 6.6431\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 28.1926 - accuracy: 0.0088 - mae: 4.0959\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 55.8131 - accuracy: 0.0082 - mae: 5.2552\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 40.8617 - accuracy: 0.0088 - mae: 4.9702\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 79.5179 - accuracy: 0.0081 - mae: 7.0293\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 27.1334 - accuracy: 0.0088 - mae: 4.1382\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.4938 - accuracy: 0.0088 - mae: 2.3228\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11.7268 - accuracy: 0.0121 - mae: 2.5270\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 43.6463 - accuracy: 0.0088 - mae: 4.9918\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 43.1790 - accuracy: 0.0088 - mae: 5.3830\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 31.7430 - accuracy: 0.0088 - mae: 4.6618\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 30.1653 - accuracy: 0.0088 - mae: 4.2394\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 28.3389 - accuracy: 0.0088 - mae: 4.4423\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 30.7981 - accuracy: 0.0088 - mae: 4.6435\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 26.7212 - accuracy: 0.0088 - mae: 4.2078\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 22.7331 - accuracy: 0.0088 - mae: 3.9016\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 26.1451 - accuracy: 0.0088 - mae: 4.1588\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 26.6475 - accuracy: 0.0088 - mae: 4.2963\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 42.2024 - accuracy: 0.0121 - mae: 5.0093\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 45.8374 - accuracy: 0.0084 - mae: 5.2695\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.4470 - accuracy: 0.0088 - mae: 2.7072\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 48.1951 - accuracy: 0.0088 - mae: 5.9588\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 32.7044 - accuracy: 0.0088 - mae: 4.7550\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 48.1736 - accuracy: 0.0088 - mae: 5.6906\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 24.5437 - accuracy: 0.0088 - mae: 4.0683\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.1707 - accuracy: 0.0088 - mae: 2.6586\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 33.2292 - accuracy: 0.0088 - mae: 4.7130\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 36.6226 - accuracy: 0.0088 - mae: 4.0902\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.3787 - accuracy: 0.0088 - mae: 2.1700\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 6.6188 - accuracy: 0.0121 - mae: 1.9269\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 32.3800 - accuracy: 0.0088 - mae: 4.2813\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 19.0306 - accuracy: 0.0088 - mae: 3.3539\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 32.1943 - accuracy: 0.0088 - mae: 4.6948\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 21.6478 - accuracy: 0.0088 - mae: 3.8653\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 78.6748 - accuracy: 0.0086 - mae: 6.6453\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.8903 - accuracy: 0.0088 - mae: 2.2537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.4419 - accuracy: 0.0088 - mae: 2.0579\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 43.9864 - accuracy: 0.0088 - mae: 5.6472\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.8900 - accuracy: 0.0088 - mae: 4.2019\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.2972 - accuracy: 0.0088 - mae: 3.3588\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 79.1642 - accuracy: 0.0121 - mae: 6.4509\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 56.5566 - accuracy: 0.0086 - mae: 6.2378\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.7937 - accuracy: 0.0088 - mae: 3.5298\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.2237 - accuracy: 0.0088 - mae: 3.3820\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 28.1174 - accuracy: 0.0081 - mae: 3.7413\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 68.4894 - accuracy: 0.0082 - mae: 6.6943\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.2234 - accuracy: 0.0088 - mae: 1.8130\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 19.5654 - accuracy: 0.0088 - mae: 3.6192\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 35.0413 - accuracy: 0.0088 - mae: 4.9174\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.3488 - accuracy: 0.0088 - mae: 2.0879\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 30.7929 - accuracy: 0.0083 - mae: 4.6061\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 8.0697 - accuracy: 0.0121 - mae: 2.1349\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.0978 - accuracy: 0.0088 - mae: 2.0518\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 23.7509 - accuracy: 0.0088 - mae: 4.0372\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.1788 - accuracy: 0.0088 - mae: 3.8172\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 45.9053 - accuracy: 0.0086 - mae: 5.7924\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.2085 - accuracy: 0.0088 - mae: 2.6627\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.6410 - accuracy: 0.0088 - mae: 3.4988\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.7551 - accuracy: 0.0086 - mae: 3.7259\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.3388 - accuracy: 0.0088 - mae: 3.0387\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 49.9212 - accuracy: 0.0081 - mae: 5.1193\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.0496 - accuracy: 0.0088 - mae: 2.8498\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 5.7513 - accuracy: 0.0121 - mae: 1.8895\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 27.3320 - accuracy: 0.0088 - mae: 4.0382\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 33.0100 - accuracy: 0.0087 - mae: 4.3963\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.7451 - accuracy: 0.0088 - mae: 3.7863\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.8805 - accuracy: 0.0088 - mae: 1.8519\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6357 - accuracy: 0.0088 - mae: 1.4463\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 29.8805 - accuracy: 0.0088 - mae: 4.4676\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.4121 - accuracy: 0.0088 - mae: 3.8888\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.7362 - accuracy: 0.0088 - mae: 4.1498\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 23.9245 - accuracy: 0.0088 - mae: 4.1166\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.9201 - accuracy: 0.0088 - mae: 3.3407\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12.2094 - accuracy: 0.0121 - mae: 2.8291\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.9969 - accuracy: 0.0088 - mae: 2.2375\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 29.2323 - accuracy: 0.0088 - mae: 4.6559\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.1346 - accuracy: 0.0088 - mae: 2.9907\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.7487 - accuracy: 0.0088 - mae: 3.0685\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.8136 - accuracy: 0.0088 - mae: 1.8782\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 34.8859 - accuracy: 0.0088 - mae: 5.1396\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.9099 - accuracy: 0.0088 - mae: 1.7065\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.1728 - accuracy: 0.0088 - mae: 2.4400\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 22.2090 - accuracy: 0.0088 - mae: 4.1165\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.5486 - accuracy: 0.0088 - mae: 3.1003\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 14.1323 - accuracy: 0.0121 - mae: 1.9266\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.5130 - accuracy: 0.0088 - mae: 1.7695\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 23.7936 - accuracy: 0.0088 - mae: 4.0893\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.5714 - accuracy: 0.0088 - mae: 4.3136\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 31.2553 - accuracy: 0.0088 - mae: 4.7182\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.8583 - accuracy: 0.0088 - mae: 1.7204\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.2882 - accuracy: 0.0088 - mae: 1.3914\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 32.2199 - accuracy: 0.0082 - mae: 4.6523\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.7095 - accuracy: 0.0088 - mae: 2.5716\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 21.6342 - accuracy: 0.0088 - mae: 3.8954\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.2051 - accuracy: 0.0088 - mae: 2.2450\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 34.9791 - accuracy: 0.0121 - mae: 4.6860\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 24.9924 - accuracy: 0.0088 - mae: 4.3164\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1227 - accuracy: 0.0088 - mae: 2.2811\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.2105 - accuracy: 0.0088 - mae: 3.0269\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.0655 - accuracy: 0.0088 - mae: 3.3660\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 33.1444 - accuracy: 0.0084 - mae: 4.9165\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4394 - accuracy: 0.0088 - mae: 1.6312\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 29.6300 - accuracy: 0.0088 - mae: 4.5396\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.8935 - accuracy: 0.0088 - mae: 3.0654\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.2002 - accuracy: 0.0088 - mae: 2.3613\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.8559 - accuracy: 0.0088 - mae: 2.4634\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 21.6763 - accuracy: 0.0121 - mae: 4.0171\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.5514 - accuracy: 0.0088 - mae: 2.7117\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 21.2680 - accuracy: 0.0088 - mae: 3.9915\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.7861 - accuracy: 0.0088 - mae: 2.3723\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.3718 - accuracy: 0.0088 - mae: 3.3353\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.4642 - accuracy: 0.0088 - mae: 2.7034\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.8110 - accuracy: 0.0088 - mae: 2.9237\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.5412 - accuracy: 0.0088 - mae: 3.0270\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.1479 - accuracy: 0.0088 - mae: 1.5811\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 29.6278 - accuracy: 0.0088 - mae: 4.7835\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.0452 - accuracy: 0.0088 - mae: 2.4059\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 7.4087 - accuracy: 0.0121 - mae: 1.8369\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8284 - accuracy: 0.0088 - mae: 2.0015\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.3704 - accuracy: 0.0088 - mae: 3.8414\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.4254 - accuracy: 0.0088 - mae: 2.1223\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 19.5570 - accuracy: 0.0086 - mae: 3.3690\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 40.1566 - accuracy: 0.0086 - mae: 5.0982\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.3039 - accuracy: 0.0088 - mae: 3.0306\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.0660 - accuracy: 0.0088 - mae: 1.7713\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5990 - accuracy: 0.0088 - mae: 1.6501\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.9083 - accuracy: 0.0088 - mae: 4.0425\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.1761 - accuracy: 0.0088 - mae: 3.3333\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10.8484 - accuracy: 0.0121 - mae: 2.6848\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.3384 - accuracy: 0.0088 - mae: 3.0322\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.2861 - accuracy: 0.0088 - mae: 2.4676\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.4160 - accuracy: 0.0086 - mae: 4.2376\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.6514 - accuracy: 0.0088 - mae: 2.8840\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.4953 - accuracy: 0.0088 - mae: 2.3994\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.8652 - accuracy: 0.0088 - mae: 3.1916\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.8781 - accuracy: 0.0088 - mae: 2.9217\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.2063 - accuracy: 0.0088 - mae: 3.1216\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 21.6914 - accuracy: 0.0088 - mae: 4.1050\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.6437 - accuracy: 0.0088 - mae: 2.8241\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 35.1015 - accuracy: 0.0121 - mae: 4.9452\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.8772 - accuracy: 0.0088 - mae: 3.0084\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.8695 - accuracy: 0.0088 - mae: 2.8111\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.7737 - accuracy: 0.0088 - mae: 3.4892\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.9473 - accuracy: 0.0088 - mae: 2.1895\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.7149 - accuracy: 0.0088 - mae: 2.9734\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.5045 - accuracy: 0.0088 - mae: 3.4895\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.2825 - accuracy: 0.0088 - mae: 2.9713\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 19.9555 - accuracy: 0.0088 - mae: 3.5688\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.3392 - accuracy: 0.0088 - mae: 2.8182\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.6069 - accuracy: 0.0088 - mae: 3.0498\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 16.1848 - accuracy: 0.0121 - mae: 3.2887\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.3277 - accuracy: 0.0088 - mae: 3.3393\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.1810 - accuracy: 0.0088 - mae: 2.8532\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.1290 - accuracy: 0.0088 - mae: 1.6305\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6435 - accuracy: 0.0088 - mae: 1.5232\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.2281 - accuracy: 0.0088 - mae: 2.8344\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 26.4066 - accuracy: 0.0086 - mae: 4.4488\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.6304 - accuracy: 0.0088 - mae: 2.6282\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.7834 - accuracy: 0.0088 - mae: 1.7577\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.5429 - accuracy: 0.0088 - mae: 3.4924\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 22.8811 - accuracy: 0.0088 - mae: 4.2420\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 105.8538 - accuracy: 0.0121 - mae: 6.6182\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.7505 - accuracy: 0.0088 - mae: 3.3953\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4961 - accuracy: 0.0088 - mae: 1.2309\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.1459 - accuracy: 0.0088 - mae: 3.0067\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.0107 - accuracy: 0.0088 - mae: 1.1216\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.3222 - accuracy: 0.0088 - mae: 1.8711\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.1531 - accuracy: 0.0088 - mae: 2.8217\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.5812 - accuracy: 0.0088 - mae: 2.9623\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.6344 - accuracy: 0.0085 - mae: 3.8975\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.0759 - accuracy: 0.0088 - mae: 1.7462\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 18.6507 - accuracy: 0.0088 - mae: 3.7946\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13.4589 - accuracy: 0.0121 - mae: 3.1244\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.6225 - accuracy: 0.0088 - mae: 2.8652\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.1409 - accuracy: 0.0088 - mae: 1.5787\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.6084 - accuracy: 0.0088 - mae: 3.6137\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.4932 - accuracy: 0.0088 - mae: 3.2171\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.0486 - accuracy: 0.0088 - mae: 2.2063\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.9429 - accuracy: 0.0088 - mae: 3.4883\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.1003 - accuracy: 0.0088 - mae: 3.5708\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6169 - accuracy: 0.0088 - mae: 1.2423\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.3565 - accuracy: 0.0088 - mae: 2.3265\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8286 - accuracy: 0.0088 - mae: 2.1377\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 3.0189 - accuracy: 0.0121 - mae: 1.3476\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.5186 - accuracy: 0.0088 - mae: 2.4382\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.7007 - accuracy: 0.0088 - mae: 3.2245\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.7766 - accuracy: 0.0088 - mae: 2.4867\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.8430 - accuracy: 0.0088 - mae: 3.0735\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.6392 - accuracy: 0.0088 - mae: 2.9415\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.5348 - accuracy: 0.0088 - mae: 1.9303\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.6327 - accuracy: 0.0088 - mae: 3.2433\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.2667 - accuracy: 0.0088 - mae: 3.0461\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8906 - accuracy: 0.0088 - mae: 2.2376\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1135 - accuracy: 0.0088 - mae: 2.6155\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 24.0313 - accuracy: 0.0121 - mae: 4.0734\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.8041 - accuracy: 0.0088 - mae: 3.2469\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8986 - accuracy: 0.0088 - mae: 2.2029\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.2943 - accuracy: 0.0088 - mae: 2.1373\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.4664 - accuracy: 0.0088 - mae: 2.2969\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.2475 - accuracy: 0.0088 - mae: 2.6061\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.9549 - accuracy: 0.0088 - mae: 3.1858\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.3177 - accuracy: 0.0088 - mae: 3.1887\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.1057 - accuracy: 0.0088 - mae: 1.8536\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.5250 - accuracy: 0.0085 - mae: 4.1708\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6649 - accuracy: 0.0088 - mae: 1.5387\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 2.1438 - accuracy: 0.0121 - mae: 1.1531\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6305 - accuracy: 0.0088 - mae: 1.8498\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.2809 - accuracy: 0.0088 - mae: 2.7144\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.9390 - accuracy: 0.0088 - mae: 2.7643\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 18.3487 - accuracy: 0.0088 - mae: 3.6457\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.5997 - accuracy: 0.0088 - mae: 2.6771\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.5467 - accuracy: 0.0088 - mae: 2.7234\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.0718 - accuracy: 0.0088 - mae: 2.9168\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.7648 - accuracy: 0.0088 - mae: 2.7393\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.5606 - accuracy: 0.0088 - mae: 2.0889\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.9909 - accuracy: 0.0088 - mae: 2.7398\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 7.6982 - accuracy: 0.0121 - mae: 2.1810\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.1823 - accuracy: 0.0088 - mae: 2.2645\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.8661 - accuracy: 0.0088 - mae: 3.5382\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 19.9736 - accuracy: 0.0088 - mae: 3.6287\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3539 - accuracy: 0.0088 - mae: 1.2130\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8389 - accuracy: 0.0088 - mae: 2.2436\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.8029 - accuracy: 0.0088 - mae: 3.7646\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.0207 - accuracy: 0.0088 - mae: 1.6081\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 21.8371 - accuracy: 0.0077 - mae: 3.9311\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.1609 - accuracy: 0.0088 - mae: 3.3869\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.0966 - accuracy: 0.0088 - mae: 2.2710\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 5.8387 - accuracy: 0.0121 - mae: 1.7940\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6478 - accuracy: 0.0088 - mae: 1.2926\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.2497 - accuracy: 0.0088 - mae: 2.8280\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3762 - accuracy: 0.0088 - mae: 1.1933\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5019 - accuracy: 0.0088 - mae: 1.4843\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.1917 - accuracy: 0.0088 - mae: 2.4742\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.3802 - accuracy: 0.0088 - mae: 2.7552\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.9124 - accuracy: 0.0088 - mae: 3.6767\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.4070 - accuracy: 0.0088 - mae: 2.4475\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.1060 - accuracy: 0.0088 - mae: 3.3113\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.5160 - accuracy: 0.0088 - mae: 2.9206\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 16.5686 - accuracy: 0.0121 - mae: 3.4399\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.5634 - accuracy: 0.0088 - mae: 2.6837\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.8819 - accuracy: 0.0088 - mae: 2.4318\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.7100 - accuracy: 0.0088 - mae: 2.9774\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.3749 - accuracy: 0.0088 - mae: 2.3294\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.0928 - accuracy: 0.0088 - mae: 2.5926\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.9179 - accuracy: 0.0088 - mae: 2.3731\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.4036 - accuracy: 0.0088 - mae: 2.9781\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.3742 - accuracy: 0.0088 - mae: 1.7125\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 18.4239 - accuracy: 0.0088 - mae: 3.6206\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4487 - accuracy: 0.0088 - mae: 1.9150\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 5.5549 - accuracy: 0.0121 - mae: 1.8485\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.5284 - accuracy: 0.0088 - mae: 2.1763\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.6201 - accuracy: 0.0088 - mae: 3.3851\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.4205 - accuracy: 0.0088 - mae: 1.4909\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.1978 - accuracy: 0.0088 - mae: 2.2414\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.9997 - accuracy: 0.0088 - mae: 3.1051\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.7323 - accuracy: 0.0088 - mae: 2.5431\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.4641 - accuracy: 0.0088 - mae: 1.5291\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.9859 - accuracy: 0.0088 - mae: 3.0974\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.2955 - accuracy: 0.0088 - mae: 1.4203\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.5583 - accuracy: 0.0088 - mae: 3.6696\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13.5588 - accuracy: 0.0121 - mae: 2.9550\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.7125 - accuracy: 0.0088 - mae: 2.8891\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.7986 - accuracy: 0.0088 - mae: 2.7263\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.3218 - accuracy: 0.0088 - mae: 2.2074\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.3133 - accuracy: 0.0088 - mae: 2.6827\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.7942 - accuracy: 0.0088 - mae: 3.3230\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.2549 - accuracy: 0.0088 - mae: 1.4296\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.5718 - accuracy: 0.0088 - mae: 2.8340\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.5862 - accuracy: 0.0088 - mae: 2.5538\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4860 - accuracy: 0.0088 - mae: 2.2047\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8180 - accuracy: 0.0088 - mae: 2.1417\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 7.7613 - accuracy: 0.0121 - mae: 2.1402\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.2315 - accuracy: 0.0088 - mae: 3.3290\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.3791 - accuracy: 0.0088 - mae: 1.9435\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.0970 - accuracy: 0.0088 - mae: 2.9305\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.8829 - accuracy: 0.0088 - mae: 1.5551\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0356 - accuracy: 0.0088 - mae: 1.4059\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.2219 - accuracy: 0.0088 - mae: 2.5084\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.1507 - accuracy: 0.0088 - mae: 3.2921\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.8029 - accuracy: 0.0088 - mae: 2.7263\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4216 - accuracy: 0.0088 - mae: 1.9342\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.8799 - accuracy: 0.0088 - mae: 1.5775\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 16.0586 - accuracy: 0.0121 - mae: 3.3484\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.1303 - accuracy: 0.0088 - mae: 3.7214\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.8490 - accuracy: 0.0088 - mae: 1.6590\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.3658 - accuracy: 0.0088 - mae: 0.9449\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.8417 - accuracy: 0.0088 - mae: 1.5844\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.2692 - accuracy: 0.0088 - mae: 3.4952\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 21.6482 - accuracy: 0.0088 - mae: 3.6998\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.8756 - accuracy: 0.0088 - mae: 1.0943\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6154 - accuracy: 0.0088 - mae: 1.2982\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.2009 - accuracy: 0.0084 - mae: 3.4629\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.8022 - accuracy: 0.0088 - mae: 2.3490\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 5.2461 - accuracy: 0.0121 - mae: 1.8150\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.0067 - accuracy: 0.0088 - mae: 2.7005\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1776 - accuracy: 0.0088 - mae: 2.5307\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3992 - accuracy: 0.0088 - mae: 2.1755\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.0677 - accuracy: 0.0088 - mae: 3.2258\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6970 - accuracy: 0.0088 - mae: 1.8839\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.2656 - accuracy: 0.0088 - mae: 1.2113\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.2014 - accuracy: 0.0088 - mae: 1.4691\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.8596 - accuracy: 0.0088 - mae: 3.0641\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.7761 - accuracy: 0.0088 - mae: 3.5780\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.3113 - accuracy: 0.0088 - mae: 2.2563\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 6.9287 - accuracy: 0.0121 - mae: 1.8531\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.2893 - accuracy: 0.0088 - mae: 3.5722\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0822 - accuracy: 0.0088 - mae: 1.4140\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.0164 - accuracy: 0.0088 - mae: 2.2691\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5912 - accuracy: 0.0088 - mae: 1.5140\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.9714 - accuracy: 0.0088 - mae: 3.3002\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.7754 - accuracy: 0.0088 - mae: 2.2408\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.9901 - accuracy: 0.0088 - mae: 2.4704\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.9319 - accuracy: 0.0088 - mae: 2.6376\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6043 - accuracy: 0.0088 - mae: 1.5087\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.7819 - accuracy: 0.0088 - mae: 2.9449\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 29.2099 - accuracy: 0.0121 - mae: 4.0566\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.3510 - accuracy: 0.0088 - mae: 3.0884\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9338 - accuracy: 0.0088 - mae: 1.0986\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5600 - accuracy: 0.0088 - mae: 1.4522\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.3668 - accuracy: 0.0088 - mae: 3.4957\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.5260 - accuracy: 0.0088 - mae: 1.9571\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.8504 - accuracy: 0.0088 - mae: 1.8633\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.3905 - accuracy: 0.0088 - mae: 2.5168\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.2676 - accuracy: 0.0088 - mae: 3.3572\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.2130 - accuracy: 0.0088 - mae: 1.4803\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4510 - accuracy: 0.0088 - mae: 1.9313\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12.4465 - accuracy: 0.0121 - mae: 3.0263\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.9474 - accuracy: 0.0088 - mae: 3.5064\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 9.7682 - accuracy: 0.0088 - mae: 2.6468\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.8792 - accuracy: 0.0088 - mae: 1.7360\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.3147 - accuracy: 0.0082 - mae: 4.4323\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.4859 - accuracy: 0.0088 - mae: 1.4141\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.8319 - accuracy: 0.0088 - mae: 1.3810\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.0242 - accuracy: 0.0088 - mae: 2.4701\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.5598 - accuracy: 0.0088 - mae: 3.2071\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4389 - accuracy: 0.0088 - mae: 1.2463\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.9353 - accuracy: 0.0088 - mae: 3.1527\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11.5928 - accuracy: 0.0121 - mae: 2.8330\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4764 - accuracy: 0.0088 - mae: 1.2542\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.7081 - accuracy: 0.0088 - mae: 2.5880\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.2926 - accuracy: 0.0088 - mae: 2.3470\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.1482 - accuracy: 0.0088 - mae: 0.8719\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.8924 - accuracy: 0.0088 - mae: 1.1024\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.7884 - accuracy: 0.0088 - mae: 3.4174\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.0590 - accuracy: 0.0088 - mae: 2.1205\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.2516 - accuracy: 0.0088 - mae: 3.0045\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.6010 - accuracy: 0.0088 - mae: 2.7756\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.2608 - accuracy: 0.0082 - mae: 3.0074\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10.3220 - accuracy: 0.0121 - mae: 2.8225\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.2295 - accuracy: 0.0088 - mae: 2.5325\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5574 - accuracy: 0.0088 - mae: 1.8255\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.1977 - accuracy: 0.0088 - mae: 2.4617\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.6976 - accuracy: 0.0088 - mae: 2.6319\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.6112 - accuracy: 0.0088 - mae: 2.7789\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.8341 - accuracy: 0.0088 - mae: 3.1945\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.2603 - accuracy: 0.0088 - mae: 2.5141\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.7006 - accuracy: 0.0088 - mae: 2.4211\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.9247 - accuracy: 0.0088 - mae: 2.4897\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.2693 - accuracy: 0.0088 - mae: 3.0039\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 48.5092 - accuracy: 0.0121 - mae: 4.8504\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.1446 - accuracy: 0.0086 - mae: 2.8959\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6537 - accuracy: 0.0088 - mae: 2.0293\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.3590 - accuracy: 0.0088 - mae: 2.3725\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.9527 - accuracy: 0.0088 - mae: 1.6739\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3588 - accuracy: 0.0088 - mae: 2.1822\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.5379 - accuracy: 0.0088 - mae: 2.9970\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.3549 - accuracy: 0.0088 - mae: 2.5660\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6081 - accuracy: 0.0088 - mae: 2.0134\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5874 - accuracy: 0.0088 - mae: 1.8192\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.3766 - accuracy: 0.0088 - mae: 1.9356\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 15.1479 - accuracy: 0.0121 - mae: 3.0760\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.2244 - accuracy: 0.0088 - mae: 3.0088\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.8836 - accuracy: 0.0088 - mae: 2.4172\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5863 - accuracy: 0.0088 - mae: 1.5663\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.0432 - accuracy: 0.0088 - mae: 2.9566\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.6568 - accuracy: 0.0088 - mae: 2.7433\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5109 - accuracy: 0.0088 - mae: 1.7729\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.3569 - accuracy: 0.0088 - mae: 0.9416\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.5444 - accuracy: 0.0088 - mae: 1.7862\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.7267 - accuracy: 0.0088 - mae: 2.8488\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.1106 - accuracy: 0.0088 - mae: 1.7066\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 9.4402 - accuracy: 0.0121 - mae: 2.5754\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.5333 - accuracy: 0.0088 - mae: 3.2583\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.9621 - accuracy: 0.0088 - mae: 2.1066\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5620 - accuracy: 0.0088 - mae: 1.0018\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.8128 - accuracy: 0.0088 - mae: 1.5869\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.0150 - accuracy: 0.0088 - mae: 3.3978\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5609 - accuracy: 0.0088 - mae: 1.8204\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.8202 - accuracy: 0.0088 - mae: 2.1131\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.2271 - accuracy: 0.0088 - mae: 3.0531\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.5816 - accuracy: 0.0088 - mae: 2.0411\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4100 - accuracy: 0.0088 - mae: 1.7915\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 8.5937 - accuracy: 0.0121 - mae: 2.3572\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.9729 - accuracy: 0.0088 - mae: 1.4100\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.6202 - accuracy: 0.0088 - mae: 1.8208\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.1524 - accuracy: 0.0088 - mae: 1.7253\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.0210 - accuracy: 0.0088 - mae: 2.9542\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.2976 - accuracy: 0.0088 - mae: 2.0116\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.3265 - accuracy: 0.0088 - mae: 3.4053\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.1081 - accuracy: 0.0088 - mae: 0.8550\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.1755 - accuracy: 0.0088 - mae: 2.0783\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.4549 - accuracy: 0.0088 - mae: 2.7467\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.9658 - accuracy: 0.0088 - mae: 2.9245\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 15.3740 - accuracy: 0.0121 - mae: 2.7270\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0555 - accuracy: 0.0088 - mae: 1.3036\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.3024 - accuracy: 0.0088 - mae: 0.9155\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.1529 - accuracy: 0.0088 - mae: 2.2469\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.1332 - accuracy: 0.0088 - mae: 1.9591\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.4835 - accuracy: 0.0088 - mae: 3.4657\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.5321 - accuracy: 0.0088 - mae: 3.3456\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0907 - accuracy: 0.0088 - mae: 1.4517\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.3929 - accuracy: 0.0088 - mae: 1.5596\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4463 - accuracy: 0.0088 - mae: 2.2138\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.1113 - accuracy: 0.0088 - mae: 3.1524\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 6.0569 - accuracy: 0.0121 - mae: 2.0609\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.0206 - accuracy: 0.0088 - mae: 1.7103\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.0930 - accuracy: 0.0088 - mae: 2.3461\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.5556 - accuracy: 0.0088 - mae: 2.2501\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1685 - accuracy: 0.0088 - mae: 2.7273\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.0103 - accuracy: 0.0088 - mae: 2.8250\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.7306 - accuracy: 0.0088 - mae: 1.8154\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.0128 - accuracy: 0.0088 - mae: 2.8505\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.7854 - accuracy: 0.0088 - mae: 2.6024\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.1070 - accuracy: 0.0088 - mae: 3.6373\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.1091 - accuracy: 0.0088 - mae: 2.3631\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13.2444 - accuracy: 0.0121 - mae: 2.7549\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.9740 - accuracy: 0.0088 - mae: 2.4739\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.9447 - accuracy: 0.0088 - mae: 1.8809\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5930 - accuracy: 0.0088 - mae: 1.8606\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.1557 - accuracy: 0.0088 - mae: 1.9421\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.9842 - accuracy: 0.0088 - mae: 2.5059\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.1222 - accuracy: 0.0088 - mae: 2.8285\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.4402 - accuracy: 0.0088 - mae: 1.5696\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4514 - accuracy: 0.0088 - mae: 2.0592\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.9078 - accuracy: 0.0087 - mae: 3.1977\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.1513 - accuracy: 0.0088 - mae: 0.8666\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.2663 - accuracy: 0.0121 - mae: 0.9000\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6182 - accuracy: 0.0088 - mae: 1.5895\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6548 - accuracy: 0.0088 - mae: 2.0425\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0726 - accuracy: 0.0088 - mae: 1.4429\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.2702 - accuracy: 0.0088 - mae: 2.5823\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.1145 - accuracy: 0.0088 - mae: 2.3803\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.5626 - accuracy: 0.0088 - mae: 2.4669\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4783 - accuracy: 0.0088 - mae: 2.0219\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.7137 - accuracy: 0.0088 - mae: 2.8929\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.7256 - accuracy: 0.0085 - mae: 2.8771\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.8288 - accuracy: 0.0088 - mae: 1.8624\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 9.2991 - accuracy: 0.0121 - mae: 2.4127\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.3108 - accuracy: 0.0088 - mae: 2.9692\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.1158 - accuracy: 0.0088 - mae: 0.8551\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9209 - accuracy: 0.0088 - mae: 1.1315\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.5872 - accuracy: 0.0088 - mae: 2.2910\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.8594 - accuracy: 0.0088 - mae: 1.3813\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6127 - accuracy: 0.0088 - mae: 1.6086\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.4894 - accuracy: 0.0088 - mae: 2.6070\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.4811 - accuracy: 0.0088 - mae: 3.5090\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.3673 - accuracy: 0.0088 - mae: 1.8875\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.1616 - accuracy: 0.0088 - mae: 1.2016\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 6.7555 - accuracy: 0.0121 - mae: 1.9495\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.8457 - accuracy: 0.0088 - mae: 3.2301\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.4451 - accuracy: 0.0088 - mae: 2.5423\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.2629 - accuracy: 0.0088 - mae: 2.3903\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.8093 - accuracy: 0.0088 - mae: 1.0859\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.6784 - accuracy: 0.0088 - mae: 1.0387\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.3709 - accuracy: 0.0088 - mae: 3.2474\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.6995 - accuracy: 0.0088 - mae: 2.4274\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9340 - accuracy: 0.0088 - mae: 1.1200\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6790 - accuracy: 0.0088 - mae: 1.3618\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8031 - accuracy: 0.0088 - mae: 2.3206\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13.2327 - accuracy: 0.0121 - mae: 3.0970\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.2963 - accuracy: 0.0088 - mae: 2.0066\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.3095 - accuracy: 0.0088 - mae: 2.8755\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.7518 - accuracy: 0.0088 - mae: 2.5880\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.2243 - accuracy: 0.0088 - mae: 1.9625\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 15.4369 - accuracy: 0.0088 - mae: 3.5212\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.5023 - accuracy: 0.0088 - mae: 2.3624\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5271 - accuracy: 0.0088 - mae: 0.9916\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4699 - accuracy: 0.0088 - mae: 1.7938\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.1918 - accuracy: 0.0088 - mae: 2.2227\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6791 - accuracy: 0.0088 - mae: 1.3390\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4.6380 - accuracy: 0.0121 - mae: 1.7444\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.4155 - accuracy: 0.0088 - mae: 3.2080\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3957 - accuracy: 0.0088 - mae: 2.2356\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.6032 - accuracy: 0.0088 - mae: 3.5361\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.7147 - accuracy: 0.0088 - mae: 1.5989\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.9645 - accuracy: 0.0088 - mae: 0.8010\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.3415 - accuracy: 0.0088 - mae: 1.5323\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.4037 - accuracy: 0.0088 - mae: 2.3969\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.1703 - accuracy: 0.0088 - mae: 2.3345\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.0048 - accuracy: 0.0088 - mae: 0.8105\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.8858 - accuracy: 0.0088 - mae: 0.7749\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.1883 - accuracy: 0.0121 - mae: 0.8775\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.7522 - accuracy: 0.0086 - mae: 1.6552\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 18.6843 - accuracy: 0.0084 - mae: 4.0014\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.7022 - accuracy: 0.0088 - mae: 2.4470\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.8126 - accuracy: 0.0088 - mae: 1.4111\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.8604 - accuracy: 0.0088 - mae: 2.5227\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.9602 - accuracy: 0.0088 - mae: 2.6416\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.2203 - accuracy: 0.0088 - mae: 1.1902\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5794 - accuracy: 0.0088 - mae: 1.0182\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.8921 - accuracy: 0.0088 - mae: 0.7730\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.2604 - accuracy: 0.0088 - mae: 1.5384\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 3.8158 - accuracy: 0.0121 - mae: 1.4265\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5299 - accuracy: 0.0088 - mae: 1.8044\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.6648 - accuracy: 0.0086 - mae: 4.0489\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.2436 - accuracy: 0.0088 - mae: 1.5085\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.7717 - accuracy: 0.0088 - mae: 1.9269\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.0338 - accuracy: 0.0088 - mae: 2.2096\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.9109 - accuracy: 0.0088 - mae: 2.6957\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.7536 - accuracy: 0.0088 - mae: 1.6447\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.7665 - accuracy: 0.0088 - mae: 1.3416\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.5426 - accuracy: 0.0088 - mae: 2.9575\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.1112 - accuracy: 0.0088 - mae: 2.8490\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 8.0834 - accuracy: 0.0121 - mae: 2.0315\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.7887 - accuracy: 0.0088 - mae: 1.9058\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.9413 - accuracy: 0.0088 - mae: 1.9218\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.5105 - accuracy: 0.0088 - mae: 3.8607\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.1207 - accuracy: 0.0088 - mae: 1.1617\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.2599 - accuracy: 0.0088 - mae: 0.9081\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.4253 - accuracy: 0.0088 - mae: 2.2709\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.2176 - accuracy: 0.0088 - mae: 1.2209\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1460 - accuracy: 0.0088 - mae: 2.7145\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3679 - accuracy: 0.0088 - mae: 2.2257\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9969 - accuracy: 0.0088 - mae: 1.1073\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.1381 - accuracy: 0.0121 - mae: 0.8641\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.9281 - accuracy: 0.0088 - mae: 0.7868\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.8831 - accuracy: 0.0088 - mae: 1.8878\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.5481 - accuracy: 0.0088 - mae: 2.2908\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.3794 - accuracy: 0.0081 - mae: 3.4144\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5477 - accuracy: 0.0088 - mae: 1.0036\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.5744 - accuracy: 0.0088 - mae: 1.3437\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.3462 - accuracy: 0.0088 - mae: 1.5803\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.2048 - accuracy: 0.0088 - mae: 2.3661\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.6312 - accuracy: 0.0088 - mae: 2.9465\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.7526 - accuracy: 0.0088 - mae: 2.2595\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 8.6254 - accuracy: 0.0121 - mae: 2.3885\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.9081 - accuracy: 0.0088 - mae: 1.5998\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7707 - accuracy: 0.0088 - mae: 1.0834\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.7750 - accuracy: 0.0088 - mae: 2.0187\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.0806 - accuracy: 0.0088 - mae: 3.1280\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.2149 - accuracy: 0.0088 - mae: 2.9929\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4424 - accuracy: 0.0088 - mae: 2.2378\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.9912 - accuracy: 0.0088 - mae: 1.7336\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6831 - accuracy: 0.0088 - mae: 2.0445\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4347 - accuracy: 0.0088 - mae: 1.8041\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.1670 - accuracy: 0.0088 - mae: 2.4565\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 3.4960 - accuracy: 0.0121 - mae: 1.3644\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.1103 - accuracy: 0.0088 - mae: 1.9526\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.1050 - accuracy: 0.0088 - mae: 1.7000\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.9565 - accuracy: 0.0088 - mae: 1.7231\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3311 - accuracy: 0.0088 - mae: 2.2678\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.6877 - accuracy: 0.0088 - mae: 3.2243\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5624 - accuracy: 0.0088 - mae: 1.5759\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.9679 - accuracy: 0.0088 - mae: 0.7985\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.7437 - accuracy: 0.0088 - mae: 2.9773\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.7041 - accuracy: 0.0088 - mae: 1.3175\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.9246 - accuracy: 0.0088 - mae: 0.7853\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.0439 - accuracy: 0.0121 - mae: 0.8130\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.2960 - accuracy: 0.0088 - mae: 0.9181\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 18.5190 - accuracy: 0.0077 - mae: 3.7207\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.9775 - accuracy: 0.0088 - mae: 3.3968\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.1654 - accuracy: 0.0088 - mae: 1.1456\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.9051 - accuracy: 0.0088 - mae: 1.6838\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.9092 - accuracy: 0.0088 - mae: 3.1060\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1104 - accuracy: 0.0088 - mae: 2.5072\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4582 - accuracy: 0.0088 - mae: 1.8212\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.2026 - accuracy: 0.0088 - mae: 0.8706\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.2729 - accuracy: 0.0088 - mae: 0.9139\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.9198 - accuracy: 0.0121 - mae: 1.1131\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6021 - accuracy: 0.0088 - mae: 2.0443\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.6131 - accuracy: 0.0088 - mae: 2.6678\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.0415 - accuracy: 0.0088 - mae: 1.1648\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.8830 - accuracy: 0.0088 - mae: 1.4389\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.5484 - accuracy: 0.0088 - mae: 2.4943\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.2234 - accuracy: 0.0088 - mae: 1.9700\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.4655 - accuracy: 0.0088 - mae: 2.4590\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1240 - accuracy: 0.0088 - mae: 2.7179\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.0788 - accuracy: 0.0088 - mae: 2.2026\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.7237 - accuracy: 0.0088 - mae: 1.3930\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 7.6952 - accuracy: 0.0121 - mae: 2.0152\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.7317 - accuracy: 0.0088 - mae: 2.7562\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.3222 - accuracy: 0.0088 - mae: 0.9152\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.8833 - accuracy: 0.0088 - mae: 0.7652\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.7797 - accuracy: 0.0088 - mae: 2.5796\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.9118 - accuracy: 0.0088 - mae: 2.9707\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5784 - accuracy: 0.0088 - mae: 1.6073\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.4328 - accuracy: 0.0088 - mae: 2.6447\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.3524 - accuracy: 0.0088 - mae: 2.4541\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.2610 - accuracy: 0.0088 - mae: 1.8091\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.9026 - accuracy: 0.0088 - mae: 1.4200\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.3187 - accuracy: 0.0121 - mae: 0.9171\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.8677 - accuracy: 0.0088 - mae: 0.7598\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.1493 - accuracy: 0.0088 - mae: 1.4673\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8380 - accuracy: 0.0088 - mae: 2.1896\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.0576 - accuracy: 0.0088 - mae: 2.8199\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.8911 - accuracy: 0.0088 - mae: 2.5352\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3890 - accuracy: 0.0088 - mae: 2.2565\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6354 - accuracy: 0.0088 - mae: 1.3663\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.4164 - accuracy: 0.0088 - mae: 1.5672\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.8349 - accuracy: 0.0088 - mae: 1.8143\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.9135 - accuracy: 0.0088 - mae: 3.1638\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 32.6154 - accuracy: 0.0121 - mae: 3.8690\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.9685 - accuracy: 0.0088 - mae: 3.2273\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.5895 - accuracy: 0.0088 - mae: 2.2994\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9608 - accuracy: 0.0088 - mae: 1.1251\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3954 - accuracy: 0.0088 - mae: 1.2986\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3095 - accuracy: 0.0088 - mae: 1.2400\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.2833 - accuracy: 0.0088 - mae: 2.7956\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.8248 - accuracy: 0.0088 - mae: 3.5325\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5607 - accuracy: 0.0088 - mae: 1.8355\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.1591 - accuracy: 0.0088 - mae: 2.0134\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3548 - accuracy: 0.0088 - mae: 2.2715\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 17.2441 - accuracy: 0.0121 - mae: 2.5245\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.6353 - accuracy: 0.0088 - mae: 2.6576\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.2379 - accuracy: 0.0088 - mae: 2.0231\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.8962 - accuracy: 0.0088 - mae: 2.1725\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.2628 - accuracy: 0.0088 - mae: 1.8040\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6096 - accuracy: 0.0088 - mae: 1.6533\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.6377 - accuracy: 0.0088 - mae: 1.8874\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4996 - accuracy: 0.0088 - mae: 2.2076\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 6.7108 - accuracy: 0.0088 - mae: 2.2523\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.2110 - accuracy: 0.0088 - mae: 1.2341\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.3507 - accuracy: 0.0088 - mae: 0.9411\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.1527 - accuracy: 0.0121 - mae: 0.8515\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.0383 - accuracy: 0.0088 - mae: 1.8820\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1197 - accuracy: 0.0088 - mae: 2.7545\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.8027 - accuracy: 0.0088 - mae: 1.2483\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.4526 - accuracy: 0.0088 - mae: 1.5954\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.7232 - accuracy: 0.0088 - mae: 2.5425\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1835 - accuracy: 0.0088 - mae: 2.7318\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1634 - accuracy: 0.0088 - mae: 2.6435\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.3428 - accuracy: 0.0088 - mae: 1.8165\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.1122 - accuracy: 0.0088 - mae: 0.8488\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5705 - accuracy: 0.0088 - mae: 1.5972\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 5.6813 - accuracy: 0.0121 - mae: 1.9773\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.4825 - accuracy: 0.0088 - mae: 2.8138\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.7954 - accuracy: 0.0088 - mae: 2.2771\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.0839 - accuracy: 0.0088 - mae: 0.7999\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.2873 - accuracy: 0.0088 - mae: 1.8340\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.7640 - accuracy: 0.0088 - mae: 1.6947\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.0430 - accuracy: 0.0088 - mae: 2.5421\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.9059 - accuracy: 0.0088 - mae: 2.7106\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5984 - accuracy: 0.0088 - mae: 1.6467\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.0653 - accuracy: 0.0088 - mae: 2.7325\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.9276 - accuracy: 0.0088 - mae: 1.9191\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 2.8974 - accuracy: 0.0121 - mae: 1.3725\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.0744 - accuracy: 0.0088 - mae: 1.1780\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4700 - accuracy: 0.0088 - mae: 1.3181\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4559 - accuracy: 0.0088 - mae: 2.2680\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.6555 - accuracy: 0.0088 - mae: 1.8954\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.0654 - accuracy: 0.0088 - mae: 2.3992\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3811 - accuracy: 0.0088 - mae: 1.2842\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.8585 - accuracy: 0.0088 - mae: 0.7501\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.8331 - accuracy: 0.0088 - mae: 0.7405\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.7563 - accuracy: 0.0088 - mae: 2.6999\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.3177 - accuracy: 0.0088 - mae: 3.0004\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12.7044 - accuracy: 0.0121 - mae: 3.1930\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8985 - accuracy: 0.0088 - mae: 2.3345\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.2370 - accuracy: 0.0088 - mae: 3.0685\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.1595 - accuracy: 0.0088 - mae: 1.4855\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.5105 - accuracy: 0.0088 - mae: 1.3443\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.2633 - accuracy: 0.0088 - mae: 1.8355\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.0094 - accuracy: 0.0088 - mae: 2.2142\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.9260 - accuracy: 0.0088 - mae: 3.0526\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.8427 - accuracy: 0.0088 - mae: 1.9443\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.9222 - accuracy: 0.0088 - mae: 0.7799\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9013 - accuracy: 0.0088 - mae: 1.1447\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 2.5032 - accuracy: 0.0121 - mae: 1.2577\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.0375 - accuracy: 0.0088 - mae: 0.8178\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.0088 - mae: 0.6631\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.9339 - accuracy: 0.0088 - mae: 0.7794\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.5927 - accuracy: 0.0065 - mae: 3.1939\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.8684 - accuracy: 0.0088 - mae: 2.1411\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.1550 - accuracy: 0.0088 - mae: 2.4003\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.3836 - accuracy: 0.0088 - mae: 1.8126\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.3956 - accuracy: 0.0088 - mae: 1.8582\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.5218 - accuracy: 0.0088 - mae: 2.8421\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.2566 - accuracy: 0.0088 - mae: 1.9631\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4.0309 - accuracy: 0.0121 - mae: 1.7025\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.8943 - accuracy: 0.0088 - mae: 1.6960\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.2263 - accuracy: 0.0088 - mae: 0.8961\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4082 - accuracy: 0.0088 - mae: 1.7950\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.1272 - accuracy: 0.0088 - mae: 2.7814\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6169 - accuracy: 0.0088 - mae: 1.5624\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0612 - accuracy: 0.0088 - mae: 1.4890\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.4683 - accuracy: 0.0088 - mae: 2.5044\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6066 - accuracy: 0.0088 - mae: 1.3595\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.2148 - accuracy: 0.0088 - mae: 1.2221\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.2542 - accuracy: 0.0088 - mae: 1.8231\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 7.0287 - accuracy: 0.0121 - mae: 2.1785\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.9815 - accuracy: 0.0088 - mae: 2.7169\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8491 - accuracy: 0.0088 - mae: 2.3712\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5958 - accuracy: 0.0088 - mae: 1.0309\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.9245 - accuracy: 0.0088 - mae: 1.7034\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.0843 - accuracy: 0.0088 - mae: 1.7284\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.6191 - accuracy: 0.0088 - mae: 2.6705\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.1410 - accuracy: 0.0088 - mae: 0.8494\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.6824 - accuracy: 0.0088 - mae: 1.8651\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4310 - accuracy: 0.0088 - mae: 1.8666\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.8073 - accuracy: 0.0088 - mae: 2.3354\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 28.2709 - accuracy: 0.0104 - mae: 4.5518\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.1668 - accuracy: 0.0087 - mae: 3.4904\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4835 - accuracy: 0.0088 - mae: 1.8579\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.7896 - accuracy: 0.0088 - mae: 1.4279\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9660 - accuracy: 0.0088 - mae: 1.1787\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.2763 - accuracy: 0.0088 - mae: 1.7519\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.8084 - accuracy: 0.0088 - mae: 2.5504\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.9824 - accuracy: 0.0088 - mae: 2.3614\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4835 - accuracy: 0.0088 - mae: 1.8223\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9678 - accuracy: 0.0088 - mae: 1.1517\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.0431 - accuracy: 0.0088 - mae: 0.8223\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 2.2368 - accuracy: 0.0121 - mae: 1.0157\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.7392 - accuracy: 0.0088 - mae: 1.9157\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1325 - accuracy: 0.0088 - mae: 2.7678\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.5865 - accuracy: 0.0088 - mae: 2.6784\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.9147 - accuracy: 0.0088 - mae: 1.7372\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.0532 - accuracy: 0.0088 - mae: 1.9872\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3210 - accuracy: 0.0088 - mae: 2.2491\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7156 - accuracy: 0.0088 - mae: 1.0545\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.0690 - accuracy: 0.0088 - mae: 2.7236\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.8235 - accuracy: 0.0088 - mae: 1.5458\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.9248 - accuracy: 0.0088 - mae: 0.7804\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.9382 - accuracy: 0.0121 - mae: 0.7710\n",
      "0.9381737112998962\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "perdidaObj = 1.0\n",
    "x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "while x[0]>perdidaObj:\n",
    "    red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "    \n",
    "#La forma más efectiva que hemos encontrado para mejorar nuestra red ha sido la de hacer este bulce ya que es la unica forma de asegurarnos que la red obtendrá la precisión que busquemos\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c731f011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 0.9382 - accuracy: 0.0121 - mae: 0.7710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9381737112998962, 0.01208285428583622, 0.7709532976150513]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_bikes.evaluate(attr_prueba, obj_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0e05ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 14) for input KerasTensor(type_spec=TensorSpec(shape=(None, 14), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None,).\n",
      "Esperado 203: [[201.52798]]\n",
      "Esperado 247: [[247.29338]]\n",
      "Esperado 315: [[315.31146]]\n",
      "Esperado 214: [[214.59116]]\n",
      "Esperado 164: [[162.66823]]\n",
      "Esperado 122: [[121.300385]]\n",
      "Esperado 119: [[119.077126]]\n",
      "Esperado 89: [[88.58235]]\n",
      "Esperado 90: [[90.05068]]\n",
      "Esperado 61: [[61.305023]]\n",
      "Esperado 49: [[47.611996]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "\n",
    "X=attr[17368]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr[17369]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr[17370]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr[17371]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr[17372]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr[17373]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr[17374]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr[17375]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr[17376]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr[17377]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr[17378]\n",
    "predicciones = red_bikes.predict(X,verbose=0)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c9aa5e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 4.465658745684692\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_bikes = RandomForestRegressor()#Creamos el randomForest\n",
    "forest_bikes.fit(attr_entrenamiento, obj_entrenamiento)#Lo entrenamos\n",
    "evaluaciones = forest_bikes.predict(attr_prueba)#Evaluamos el modelo\n",
    "mse = mean_squared_error(obj_prueba, evaluaciones)#Calculamos la perdida\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d16b5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 203: [203.]\n",
      "Esperado 247: [246.94]\n",
      "Esperado 315: [313.61]\n",
      "Esperado 214: [215.02]\n",
      "Esperado 164: [163.98]\n",
      "Esperado 122: [121.91]\n",
      "Esperado 119: [118.94]\n",
      "Esperado 89: [88.95]\n",
      "Esperado 90: [89.92]\n",
      "Esperado 61: [61.09]\n",
      "Esperado 49: [49.06]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "attr2 = attr[:, np.newaxis]\n",
    "X=attr2[17368]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr2[17369]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr2[17370]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr2[17371]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr2[17372]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr2[17373]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr2[17374]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr2[17375]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr2[17376]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr2[17377]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr2[17378]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fc6c7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo LIME\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Partiremos de este seudocódigo para implementar el metodo\n",
    "N es el n´umero de permutaciones a realizar\n",
    "f es el modelo a explicar\n",
    "X′ ← {} muestras perturbadas\n",
    "R ← {} representaciones\n",
    "W ← {} las distancias entre la muestra x y sus perturbaciones\n",
    "for 1\n",
    "to\n",
    "N do\n",
    "Selecciona k atributos aleatoriamente\n",
    "x′ ← una perturbaci´on de x donde se perturban los k atributos anteriores.\n",
    "w ← la distancia entre x y x′\n",
    "r ← la representaci´on de x′ respecto a x\n",
    "X′ ← X′ ∪ x′\n",
    "R ← R ∪ r\n",
    "W ← R ∪ w\n",
    "end for\n",
    "Y ′ ← f(X′) las predicciones de las perturbaciones\n",
    "G ← modelo ridge entrenado con R para predecir Y ′ y ponderando cada\n",
    "muestra con W\n",
    "return los par´ametros de G\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def explain_model(f, x, N,M):\n",
    "    #f es el modelo a explicar\n",
    "    #X es una lista de ejemplos a los que se aplicará LIME\n",
    "    #N es el número de permutaciones a realizar\n",
    "    #M contiene todos los ejemplos\n",
    "    #Si queremos que el algoritmo cumpla la metrica identidad necesitamos fijar semillas para la aleatoriedad\n",
    "    random.seed(11)\n",
    "    Xi = [] #Aqui guardaremos las muestras perturbadas\n",
    "    R = []  #Aqui guardaremos las representaciones\n",
    "    W = []  #Aqui guradaremos las distancias\n",
    "    for i in range(N):\n",
    "        k = random.randint(1, len(x)) #Escojo un número aletario que representa el número de los atributos a seleccionar\n",
    "        perturbed_x = x.copy() #copio la muestra original\n",
    "        for j in range(k): \n",
    "            perturbed_attr = random.randint(0,len(x)-1)#Voy escojiento los atributos que perturbare de forma aleatoria\n",
    "            mx = abs(max([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor máximo\n",
    "            mn = abs(min([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor mínimo\n",
    "            perturbed_x[perturbed_attr] = random.uniform(mn, mx) # pertubo el atributo con un valor aleatorio ente mn y mx para que el valor esté acotado\n",
    "        w = abs(sum([x[attr] - perturbed_x[attr] for attr in range(0,len(x)-1)])) #Calculo la distancia entre el original y el perturbado\n",
    "        r = [0  if perturbed_x[attr] == x[attr] else 1 for attr in range(0,len(x)-1)] #Calculo la representación del perturbado respecto al original utilizando un operador ternario\n",
    "        Xi.append(perturbed_x) #Acumulo en la lista los perturbados\n",
    "        R.append(r)#Acumulamos en la lista de representaciones\n",
    "        W.append(w)#Añadimos las distancias a la lista\n",
    "    Y_perturbed = []#Aqui guardaremos las predicciones de las perturbaciones\n",
    "    for i in range(len(Xi)):\n",
    "        y = 1\n",
    "            #En los siguiente if y else comprobamos el tipo de modelo que tenemos ya que dependiendo del tipo necesita recibir los atributos de una forma u otra\n",
    "        if isinstance(f, keras.Sequential):#Comprueba si el modelo es una red neuronal\n",
    "            xi = Xi[i]\n",
    "            y = f.predict(xi,verbose=0)#Hacemos la prediccion con verbose=0 para no cargar la salida de lineas generadas por keras\n",
    "        else: #Si no, es un randomForest\n",
    "            xi = Xi[i]\n",
    "            array = np.array(xi)\n",
    "            xi = array.reshape(1, -1)\n",
    "            y = f.predict(xi)#RandomForest no tiene verbose porque no genera nada\n",
    "                \n",
    "            \n",
    "        Y_perturbed.append(y) #Aplico el modelo f a los ejemplos perturbados\n",
    "            \n",
    "    Y_perturbed = np.squeeze(Y_perturbed) #Por alguna razón aparece el error Found array with dim 3. Estimator expected <= 2\" y lo arreglamos con esta linea que quita una dimensión al array\n",
    "    G = Ridge()\n",
    "    G.fit(R, Y_perturbed, sample_weight=W)\n",
    "    return G.coef_#Devolvemos los parametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dd8cf2d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12209265,  0.01907802, -0.01072902, -0.06241706, -0.02617428,\n",
       "        0.02137444, -0.08280167, -0.06579414, -0.04063194, -0.00866057,\n",
       "        0.01660673, -0.02056638, -0.07760425,  0.01122755, -0.02195677,\n",
       "       -0.08298343, -0.04912087, -0.01072922, -0.07058429,  0.07745163,\n",
       "       -0.00535004, -0.06034842, -0.03129559,  0.106972  , -0.08280167,\n",
       "        0.01221738,  0.00380703,  0.00080806, -0.03947047, -0.02006989])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos varias pruebas para comprobar que funciona el metodo LIME\n",
    "atributivos = atributos[5809]\n",
    "\n",
    "explain_model(red_evaluation,atributivos,10,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5173d8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12209265,  0.01907802, -0.01072902, -0.06241706, -0.02617428,\n",
       "        0.02137444, -0.08280167, -0.06579414, -0.04063194, -0.00866057,\n",
       "        0.01660673, -0.02056638, -0.07760425,  0.01122755, -0.02195677,\n",
       "       -0.08298343, -0.04912087, -0.01072922, -0.07058429,  0.07745163,\n",
       "       -0.00535004, -0.06034842, -0.03129559,  0.106972  , -0.08280167,\n",
       "        0.01221738,  0.00380703,  0.00080806, -0.03947047, -0.02006989])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos varias pruebas para comprobar que funciona el metodo LIME\n",
    "atributivos = atributos[5809]\n",
    "\n",
    "explain_model(red_evaluation,atributivos,10,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d8f33d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08181818,  0.01797348,  0.00432282, -0.01447259,  0.02898144,\n",
       "        0.0449544 , -0.06832587, -0.01461441, -0.01552646, -0.06220822,\n",
       "        0.02477694, -0.02245507, -0.02120837,  0.00905765, -0.05728057,\n",
       "       -0.03692766, -0.01940025, -0.04822292, -0.0681671 ,  0.03582224,\n",
       "       -0.03250363, -0.02845789, -0.07067799,  0.04551963, -0.06832587,\n",
       "        0.00015877,  0.012292  ,  0.02249933,  0.0339091 , -0.03986767])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atributivos = atributos[5809]\n",
    "\n",
    "explain_model(forest_evaluation,atributivos,10,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "634110b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -23.35786179, -103.90000024,  201.22922074,   76.74221986,\n",
       "         40.34649733, -169.15943089,  139.32334684, -103.4536384 ,\n",
       "         45.57438371,    5.35837132,  -61.8003497 ,  -48.4623393 ,\n",
       "        151.79888326])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attri = attr[17378]\n",
    "\n",
    "explain_model(red_bikes,attri,10,attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2c2effc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -27.54166575,  -95.45217128,  191.62074367,   63.82419624,\n",
       "         49.62423809, -161.61241803,  146.8868667 , -112.79223177,\n",
       "         20.6582665 ,  -18.95970989,  -52.3572794 ,  -65.40630694,\n",
       "        128.64778787])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attri = attr[17378]\n",
    "\n",
    "explain_model(forest_bikes,attri,10,attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6a56246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#En la definición de cada metrica se importarán las cosas necesarias por si solo se quiere probar una metrica\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def identidad(x1,x2,exp1,exp2):\n",
    "    #Definición: El principio de identidad establece que objetos idénticos deben recibir explicaciones idénticas.\n",
    "\n",
    "    res = True #Si los objetos no son identicos no hay que evaluar\n",
    "    distance = np.linalg.norm(x1 - x2)#Calcula las distancias entre los dos ejemplos\n",
    "    if(distance ==0):   #Solo comprobamos si las explicaciones sean identicas si los objetos son identicos\n",
    "        res = np.linalg.norm(exp1 - exp2) ==0#Comprobamos si ambas explicaciones son iguales\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b089f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Hacemos una pequeña prueba para ver que la identidad funciona cogiendo dos veces el mimso ejemplo y viendo que se generan las \n",
    "#mismas explicaciones\n",
    "ejemplo2=attr[17375]\n",
    "ejemplo1 = attr[17375]\n",
    "print(ejemplo2)\n",
    "print(ejemplo1)\n",
    "exp1 = explain_model(forest_bikes,ejemplo1,2,attr)\n",
    "exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "print(identidad(ejemplo1,ejemplo2,exp1,exp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d4960824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo RandomForest de evaluación cumple la métrica identidad\n",
      "El modelo Red neuronal de evaluación cumple la métrica identidad\n",
      "El modelo Red neuronal de bikes cumple la métrica identidad\n",
      "El modelo RandomForest de bikes cumple la métrica identidad\n"
     ]
    }
   ],
   "source": [
    "#Comprobaremos la métrica identidad\n",
    "#Para comprobarla recorreremos 256 ejemplos en los cuatro modelos y para cada ejemplo en cada modelo generaremos \n",
    "#la explicacion dos veces y comprobaremos que es la misma explicación\n",
    "atributivos = atributos[5553:5809,:] #seleccionamos varias muestras, si cambiamos el número de la izquierda de los dos puntos:, podemos hacer que se utilizen más o menos muestras\n",
    "sonIguales = True #Inicializamos la varibale\n",
    "for x in atributivos: #Recorremos las muestras\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos) #Generamos una explicación para una muestra\n",
    "    exp2 = explain_model(forest_evaluation,x,2,atributos) #Volvemos a generar una explicación para la misma muestra\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2) #Comprobamos si cumplen la identidad\n",
    "    if(not sonIguales): #Cuando no se cumpla rompemos el bucle\n",
    "        break\n",
    "#Mostrarmos el resualdo de evaluar la metrica identidad\n",
    "if(sonIguales):\n",
    "    print(\"El modelo RandomForest de evaluación cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de evaluación no cumple la métrica identidad\")\n",
    "\n",
    "#Repetimos el proceso para los otros tres modelos, para los modelos de bike, además, utilizamos otros datos, como es normal\n",
    "    \n",
    "sonIguales=True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(red_evaluation,x,2,atributos)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "\n",
    "if(sonIguales):\n",
    "    print(\"El modelo Red neuronal de evaluación cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de evaluación no cumple la métrica identidad\")\n",
    "\n",
    "X=attr[17122:17378,:]\n",
    "sonIguales=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    exp2 = explain_model(red_bikes,x,2,attr)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "    \n",
    "if(sonIguales):\n",
    "    print(\"El modelo Red neuronal de bikes cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de bikes no cumple la métrica identidad\")\n",
    "    \n",
    "sonIguales=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    exp2 = explain_model(forest_bikes,x,2,attr)\n",
    "    sonIguales = sonIguales and identidad(x,x,exp1,exp2)\n",
    "    if(not sonIguales):\n",
    "        break\n",
    "    \n",
    "if(sonIguales):\n",
    "    print(\"El modelo RandomForest de bikes cumple la métrica identidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de bikes no cumple la métrica identidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9a59b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def separabilidad(x1,x2,exp1,exp2):\n",
    "#Definición:#Separabilidad: Objetos no idénticos no pueden tener explicaciones idénticas. Para simplificar, cada característica \n",
    "#tiene un nivel mínimo de importancia, positivo o negativo, en las predicciones.\n",
    "\n",
    "    res = True#Iicializamos la variable\n",
    "    distance = np.linalg.norm(x1 - x2)#Calcula las distancias entre los dos ejemplos\n",
    "    if(distance >0):   #Si la distancia es distinta de cero comparamos las explicaciones\n",
    "        res = not(np.linalg.norm(exp1 - exp2) ==0)#Si las explicaciones son distintas se cumple la separabilidad\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "018fbb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         1.         0.91304348 0.         0.16666667\n",
      " 1.         0.         0.24489796 0.2576     0.6        0.19301751\n",
      " 0.01907357 0.09367946]\n",
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Hacemos una pequeña prueba para comprobar que la separabilidad funciona correctamente, comparando dos muestras distintas\n",
    "#y comprobando que sus explicaciones también son distintas. Aunque se parezcan bastante\n",
    "ejemplo2=attr[17376]\n",
    "ejemplo1 = attr[17375]\n",
    "print(ejemplo2)\n",
    "print(ejemplo1)\n",
    "exp1 = explain_model(forest_bikes,ejemplo1,2,attr)\n",
    "exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "print(separabilidad(ejemplo1,ejemplo2,exp1,exp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1eda9871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo RandomForest de evaluación cumple la métrica separabilidad\n",
      "El modelo Red neuronal de evaluación cumple la métrica separabilidad\n",
      "El modelo Red neuronal de bikes cumple la métrica separabilidad\n",
      "El modelo RandomForest de bikes cumple la métrica separabilidad\n"
     ]
    }
   ],
   "source": [
    "#Comprobaremos la métrica separabilidad\n",
    "#Para comprobarla recorreremos 256 ejemplos en los cuatro modelos y los comparamos con otro ejemplo\n",
    "ejemplo1=atributos[5552]#Escogemos una muestra para compararla con todas las muestras de un conjunto\n",
    "atributivos = atributos[5553:5809,:] #Escogemos un conjunto de muestras \n",
    "cumpleSeparabilidad = True #Inicializamos una variable\n",
    "for x in atributivos: #Recorremos las muestras\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)#Generamos una explicación de la muestra que hemos escogido\n",
    "    exp2 = explain_model(forest_evaluation,ejemplo1,2,atributos)#Y una explicación para cada muestra del conjunto\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo1,exp1,exp2) #Comprobamos si se cumple la separabilidad\n",
    "    if(not cumpleSeparabilidad): #Si deja de cumplirse nos saltamos el bucle\n",
    "        break\n",
    "#Evaluamos si se cumple la separabilidad\n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo RandomForest de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "#Repetimos el proceso con los otros tres modelos     \n",
    "    \n",
    "cumpleSeparabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(red_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo1,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "\n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo Red neuronal de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "ejemplo2 = attr[17121]\n",
    "X=attr[17122:17378,:]\n",
    "cumpleSeparabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    exp2 = explain_model(red_bikes,ejemplo2,2,attr)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo2,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo Red neuronal de bikes cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de bikes no cumple la métrica separabilidad\")\n",
    "    \n",
    "cumpleSeparabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "    cumpleSeparabilidad=cumpleSeparabilidad and separabilidad(x,ejemplo2,exp1,exp2)\n",
    "    if(not cumpleSeparabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleSeparabilidad):\n",
    "    print(\"El modelo RandomForest de bikes cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de bikes no cumple la métrica separabilidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1ce5cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def estabilidad(x1,x2,exp1,exp2,umbEj,umbExp):\n",
    "    #Objetos similares deben tener explicaciones similares\n",
    "    #Para esto calcularemos la correlacion de Spearman para los ejemplos, si superan el limite que se pasará a la función\n",
    "    #Calcularemos la correlación de Spearman para las explicaciones y comprobaremos si supera el umbral, en ese caso, cumpliran la estabilidad\n",
    "    res = True #Inicializamos una variable\n",
    "    correlacionEj, _ = spearmanr(x1, x2) #Calculamos la correlación de spearman de dos muestras\n",
    "    if(abs(correlacionEj) >= umbEj): #Si es mayor que el umbral para las muestras, comprobaremos si sus explicaciones son parecidas\n",
    "        correlacionExp, _ = spearmanr(exp1,exp2) #Calculamos la correlación de spearman de las explicaciones\n",
    "        res = abs(correlacionExp)>=umbExp #Si es superior que el umbral de las explicaciones, se cumple la estabilidad\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "650a8d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         1.         0.91304348 0.         0.16666667\n",
      " 1.         0.         0.24489796 0.2576     0.6        0.19301751\n",
      " 0.01907357 0.09367946]\n",
      "[0.         1.         1.         0.86956522 0.         0.16666667\n",
      " 1.         0.33333333 0.24489796 0.2576     0.6        0.19301751\n",
      " 0.02179837 0.09142212]\n",
      "SpearmanrResult(correlation=0.8770812523243259, pvalue=3.801615077865054e-05)\n",
      "SpearmanrResult(correlation=1.0, pvalue=0.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Haremos una pequeña prueba para comprobar la que estabilidad funciona correctamente\n",
    "#Escogemos dos muestras parecidas\n",
    "ejemplo2=attr[17376]\n",
    "ejemplo1 = attr[17375]\n",
    "print(ejemplo2)\n",
    "print(ejemplo1)\n",
    "#Calulamos la correlacion de las muestras \n",
    "print(spearmanr(ejemplo1, ejemplo2))\n",
    "#Generamos sus explicaciones\n",
    "exp1 = explain_model(forest_bikes,ejemplo1,2,attr)\n",
    "exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "#Calculamos la correlación de las explicaciones\n",
    "print(spearmanr(exp1, exp2))\n",
    "#Tras esto, observamos que si se cumple la estabilidad\n",
    "print(estabilidad(ejemplo1,ejemplo2,exp1,exp2,0.75,0.75))#Utilizamos la función para ver que funciona correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "387a07c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo RandomForest de evaluación cumple la métrica separabilidad\n",
      "El modelo Red neuronal de evaluación cumple la métrica separabilidad\n",
      "El modelo Red neuronal de bikes cumple la métrica estabilidad\n",
      "El modelo RandomForest de bikes cumple la métrica estabilidad\n"
     ]
    }
   ],
   "source": [
    "#Comprobaremos la métrica estabilidad\n",
    "#Para comprobarla recorreremos 256 ejemplos en los cuatro modelos y los comparamos con otro ejemplo, del cual sabemos que hay ejemplos muy similares\n",
    "\n",
    "ejemplo1=atributos[5819]\n",
    "atributivos = atributos[5553:5819,:]\n",
    "cumpleEstabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(forest_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo1,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo RandomForest de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "cumpleEstabilidad = True\n",
    "for x in atributivos:\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos)\n",
    "    exp2 = explain_model(red_evaluation,ejemplo1,2,atributos)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo1,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "\n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo Red neuronal de evaluación cumple la métrica separabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de evaluación no cumple la métrica separabilidad\")\n",
    "\n",
    "ejemplo2 = attr[17376]\n",
    "X=attr[17122:17378,:]\n",
    "cumpleEstabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    exp2 = explain_model(red_bikes,ejemplo2,2,attr)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo2,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo Red neuronal de bikes cumple la métrica estabilidad\")\n",
    "else:\n",
    "    print(\"El modelo Red neuronal de bikes no cumple la métrica estabilidad\")\n",
    "    \n",
    "cumpleEstabilidad=True\n",
    "for x in X:\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    exp2 = explain_model(forest_bikes,ejemplo2,2,attr)\n",
    "    cumpleEstabilidad=cumpleEstabilidad and estabilidad(x,ejemplo2,exp1,exp2,0.75,0.75)\n",
    "    if(not cumpleEstabilidad):\n",
    "        break\n",
    "    \n",
    "if(cumpleEstabilidad):\n",
    "    print(\"El modelo RandomForest de bikes cumple la métrica estabilidad\")\n",
    "else:\n",
    "    print(\"El modelo RandomForest de bikes no cumple la métrica estabilidad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4ee299eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import integrate\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "def selectividad(x, model,exp):\n",
    "    #Calcularemos el area bajo la cruva a partir de ir quitando las características más importantes\n",
    "    y = x.copy() #Generamos una copia de la muestra recibida\n",
    "    errores = [] #Aqui acumularemos los errores\n",
    "    prediccionOriginal = 0 \n",
    "    iteraciones= [] #Aqui guardaremos el número de iteraciones, necesario para calcular la integral\n",
    "    if isinstance(model, keras.Sequential): #Dependiendo del modelo que reciba, necesita un tipo de datos u otro \n",
    "            prediccionOriginal = model.predict(x,verbose = 0) #Predecimos si es una red neuronal\n",
    "    else:\n",
    "            array = np.array(x)\n",
    "            x = array.reshape(1, -1)\n",
    "            prediccionOriginal = model.predict(x) #Si es random forest, utilizamos los datos de forma distinta\n",
    "    \n",
    "    for i in range(len(exp)):#Recorremos el número de parametros de las explicaciones\n",
    "        masImportante = max(exp) #Busacmos la mayor importante\n",
    "        atributo = np.where(exp == masImportante)[0] # Averiguamos en que posición se encuentra esta importancia\n",
    "        y[atributo] = 0 #modificamos y la característica más importante en este momento\n",
    "        exp[atributo] = -999999999999999999 #Cambiamos la importancia de esta característica haciendo que tenga un valor muy negativo para que nunca sea la más importante\n",
    "         #Hacemos una predicción con la muestra modificada:\n",
    "        if isinstance(model, keras.Sequential):\n",
    "            z = model.predict(y,verbose=0)\n",
    "            \n",
    "        else:\n",
    "            array = np.array(y)\n",
    "            y2 = array.reshape(1, -1)\n",
    "            z = model.predict(y2)\n",
    "        iteraciones.append(i)\n",
    "        errores.append(abs(prediccionOriginal-z))#Acumulamos el error\n",
    "    \n",
    "    #Cambiamos las dimensiones de ambos np.array, esto ocurre al meter las predicciones en una array, se modifica la dimensión de este\n",
    "    errores = np.squeeze(errores) \n",
    "    res = trapz(iteraciones,errores) #Calculamos el area bajo la cruva\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6f9f9056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estas son las selectividades del modelo Red Evaluación  [0.13354629278182983, 0.1803080439567566, 0.06457960605621338, 0.04284036159515381, -0.00476759672164917, 0.06457960605621338, 3.8172245025634766, 3.932610273361206, 0.05474388599395752]\n",
      "La selectividad media del modelo Red Evaluación es  0.9206294417381287\n",
      "Estas son las selectividades del modelo RandomForest Evaluación  [0.695, 0.6900000000000001, 0.0, 0.6899999999999998, 0.0, 0.0, 4.15, 4.170000000000001, 0.0]\n",
      "La selectividad media del modelo RandomForest Evaluación es  1.155\n",
      "Estas son las selectividades del modelo Red bikes  [-0.5851597785949707, 0.6832714080810547, 0.6243743896484375, 5.3707122802734375, 6.5587005615234375, 16.622493743896484, 20.209182739257812, 24.75194549560547, 18.846359252929688, 32.276954650878906, 35.121437072753906, 16.28521728515625, 6.051361083984375, 3.6080894470214844, 4.909355163574219, 3.0119285583496094, 3.1414031982421875, 7.246679306030273]\n",
      "La selectividad media del modelo Red bikes es  11.374128103256226\n",
      "Estas son las selectividades del modelo RandomForest bikes  [0.0, 0.01999999999999602, 0.22499999999999432, 2.5150000000000006, 4.544999999999973, 16.640000000000015, 19.875000000000007, 23.950000000000017, 17.159999999999997, 29.72500000000001, 31.585000000000036, 14.519999999999996, 6.149999999999977, 4.510000000000005, 4.6100000000000065, 2.6399999999999864, 2.960000000000008, 6.065000000000005]\n",
      "La selectividad media del modelo RandomForest bikes es  10.427500000000002\n"
     ]
    }
   ],
   "source": [
    "#Para probar la selectividad sobre el metodo lime, recorremos varias muestras y veremos cuales son sus selectividades y calcularemos una media\n",
    "atributivos = atributos[5810:5819,:]#seleccionamos varias muestras, si cambiamos el número de la izquierda de los dos puntos:, podemos hacer que se utilizen más o menos muestras\n",
    "\n",
    "selectividades = [] #Aqui acumularemos las selectividades\n",
    "\n",
    "for i in range(len(atributivos)): #Recorremos las muestras\n",
    "    exp = explain_model(red_evaluation,atributivos[i],2,atributos) #Generamos una explicación para cada muestra\n",
    "    sel = selectividad(atributivos[i],red_evaluation,exp) #Calulamos la selectividad de esta muestra\n",
    "    selectividades.append(sel)#Acumulamos la selectividades\n",
    "    \n",
    "print(\"Estas son las selectividades del modelo Red Evaluación \",selectividades) #Mostramos las selectividades\n",
    "print(\"La selectividad media del modelo Red Evaluación es \", np.mean(selectividades)) #Mostramos la media\n",
    "\n",
    "#Repetimos el proceso para los demás modelos\n",
    "\n",
    "selectividades = []\n",
    "\n",
    "for i in range(len(atributivos)):\n",
    "    exp = explain_model(forest_evaluation,atributivos[i],2,atributos)\n",
    "    sel = selectividad(atributivos[i],forest_evaluation,exp)\n",
    "    selectividades.append(sel)\n",
    "    \n",
    "print(\"Estas son las selectividades del modelo RandomForest Evaluación \",selectividades)\n",
    "print(\"La selectividad media del modelo RandomForest Evaluación es \", np.mean(selectividades))\n",
    "\n",
    "X = attr[17360:17378,:]   \n",
    "\n",
    "selectividades = []\n",
    "for i in range(len(X)):\n",
    "    exp = explain_model(red_bikes,X[i],2,attr)\n",
    "    sel = selectividad(X[i],red_bikes,exp)\n",
    "    selectividades.append(sel)\n",
    "    \n",
    "print(\"Estas son las selectividades del modelo Red bikes \",selectividades)\n",
    "print(\"La selectividad media del modelo Red bikes es \", np.mean(selectividades))\n",
    "\n",
    "selectividades = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    exp = explain_model(forest_bikes,X[i],2,attr)\n",
    "    sel = selectividad(X[i],forest_bikes,exp)\n",
    "    selectividades.append(sel)\n",
    "    \n",
    "print(\"Estas son las selectividades del modelo RandomForest bikes \",selectividades)\n",
    "print(\"La selectividad media del modelo RandomForest bikes es \", np.mean(selectividades))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0dc5db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherencia(mae1, mae2):\n",
    "    #Se calcula la diferencia entre el error de predicción (mae1) sobre la señal original y el error de predicción mae2\n",
    "    #de una nueva señal donde se eliminan las características no importantes.\n",
    "    alpha_i = abs(mae1 - mae2)\n",
    "    return alpha_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6eb75871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo Red Neuronal de evaluación tiene unas coherencias de  [4.2473960e-01 3.1312466e-01 1.2915921e-01 4.5259809e-01 2.8135777e-03\n",
      " 1.2915921e-01 3.4266052e+00 3.5245893e+00 1.0948777e-01]\n",
      "El modelo Red Neuronal de evaluación tiene una coherencia media de de  0.94580853\n",
      "El modelo RandomForest de evaluación tiene unas coherencias de  [0.05 0.05 2.   0.05 1.38 2.   1.76 1.8  2.  ]\n",
      "El modelo RandomForest de evaluación tiene una coherencia media de de  1.232222222222222\n",
      "El modelo Red Neuronal de bikes tiene unas coherencias de  [ 30.308372     0.37038803  42.968124   148.86833    102.90701\n",
      "  46.02864     75.51104    131.03801    122.52409    145.69594\n",
      " 210.405      143.98051    108.95059     72.613365    67.9225\n",
      "  41.204407    43.032455     6.1525726 ]\n",
      "El modelo Red Neuronal de bikes tiene una coherencia media de de  85.582306\n",
      "El modelo RandomForest de bikes tiene unas coherencias de  [3.1000e+01 2.0000e-02 4.3780e+01 1.5030e+02 1.0717e+02 4.6840e+01\n",
      " 7.5880e+01 1.3578e+02 1.2880e+02 1.4802e+02 2.0873e+02 1.4540e+02\n",
      " 1.1203e+02 7.2840e+01 6.9360e+01 4.3760e+01 4.4070e+01 9.0500e+00]\n",
      "El modelo RandomForest de bikes tiene una coherencia media de de  87.37944444444445\n"
     ]
    }
   ],
   "source": [
    "#Para probar la coherencia lo que haremos será para varias muestras muestras, generar una predicción, generar su explicación \n",
    "#y a partir de su explicación quitaremos los N atributos menos importantes y generaremos otra explicación, a partir de ambas predicciones \n",
    "#calcularemos dos MAE y con ello calcularemos la coherencia\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#Escogemos un conjunto de musetras junto a sus valores objetivo\n",
    "atributivos = atributos[5810:5819,:]\n",
    "objetivos = objetivo[5810:5819]\n",
    "\n",
    "N=2#Definimos el número de atributos que quitaremos\n",
    "coherencias = []\n",
    "\n",
    "\n",
    "for i in range(len(atributivos)):#Recorremos las muestras\n",
    "    x = atributivos[i] \n",
    "    y = x.copy() #Generamos una copia de la muestra\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos) #Generamos una explicación para la muestra\n",
    "    prediccion1 = red_evaluation.predict(x,verbose=0) #Hacemos una predicción para la muestra\n",
    "    errp = abs(objetivos[i]-prediccion1) #Calculamos el error entre la predicción y el objetivo\n",
    "   \n",
    "    for j in range(N): #Recorremos el número de atributos que queremos quitar\n",
    "        menosImportante = min(exp1) #Cogemos la menor importancia\n",
    "        atributo = np.where(exp1 == menosImportante)[0] #Buscamos a que atributo hace referencia\n",
    "        y[atributo] = 0 #Quitamos el atributo\n",
    "        exp1[atributo] = 99999999999999999 #Cambiamos el valor de esta imporatncia para que nunca más sea  la menor\n",
    "    prediccion2 = red_evaluation.predict(y,verbose=0) #Generemos una predicción con la muestra modificada\n",
    "   \n",
    "    errexp = abs(objetivos[i]-prediccion2) #Calculamos el error de la muestra modificada\n",
    "    res = coherencia(errp,errexp)\n",
    "    coherencias.append(res) #Calculamos la coherencia y la metemos en su lista\n",
    "\n",
    "#Cambiamos las dimensiones del array y los mostramos\n",
    "coherencias = np.squeeze(coherencias)\n",
    "print(\"El modelo Red Neuronal de evaluación tiene unas coherencias de \",coherencias)\n",
    "print(\"El modelo Red Neuronal de evaluación tiene una coherencia media de de \",np.mean(coherencias))\n",
    "\n",
    "\n",
    "#Repetimos el proceso con el resto de modelos\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "for i in range(len(atributivos)):\n",
    "    x = atributivos[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    x = x.reshape(1, -1)\n",
    "    prediccion1 = forest_evaluation.predict(x)\n",
    "    errp = abs(objetivos[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 999999999999999999\n",
    "    y = y.reshape(1, -1)\n",
    "    prediccion2 = forest_evaluation.predict(y)\n",
    "      \n",
    "    errexp = abs(objetivos[i]-prediccion2)\n",
    "    res = coherencia(errp,errexp)\n",
    "    coherencias.append(res) \n",
    "    \n",
    "coherencias = np.squeeze(coherencias)\n",
    "print(\"El modelo RandomForest de evaluación tiene unas coherencias de \",coherencias)\n",
    "print(\"El modelo RandomForest de evaluación tiene una coherencia media de de \",np.mean(coherencias))\n",
    "\n",
    "\n",
    "X=attr[17360:17378,:]\n",
    "objs = obj[17360:17378]\n",
    "\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "    x = X[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    prediccion1 = red_bikes.predict(x,verbose=0)\n",
    "    errp = abs(objs[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 99999999999999999\n",
    "    prediccion2 = red_bikes.predict(y,verbose=0)\n",
    "       \n",
    "    errexp = abs(objs[i]-prediccion2)\n",
    "    res = coherencia(errp,errexp)\n",
    "    coherencias.append(res) \n",
    "\n",
    "\n",
    "coherencias = np.squeeze(coherencias)\n",
    "print(\"El modelo Red Neuronal de bikes tiene unas coherencias de \",coherencias)\n",
    "print(\"El modelo Red Neuronal de bikes tiene una coherencia media de de \",np.mean(coherencias))    \n",
    "\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "for i in range(0,len(X)):\n",
    "    x = X[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    x = x.reshape(1, -1)\n",
    "    prediccion1 = forest_bikes.predict(x)\n",
    "    errp = abs(objs[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 999999999999999999\n",
    "    y = y.reshape(1, -1)\n",
    "    prediccion2 = forest_bikes.predict(y)\n",
    "    errexp = abs(objs[i]-prediccion2)\n",
    "    res = coherencia(errp,errexp)\n",
    "    coherencias.append(res) \n",
    "    \n",
    "\n",
    "    \n",
    "coherencias = np.squeeze(coherencias)\n",
    "print(\"El modelo RandomForest de bikes tiene unas coherencias de \",coherencias)\n",
    "print(\"El modelo RandomForest de bikes tiene una coherencia media de de \",np.mean(coherencias))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "96098651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completitud(ei, pi):\n",
    "    #Evalúa el porcentaje de error de explicación con respecto al error de predicción.\n",
    "    gamma_i = ei / pi\n",
    "    return gamma_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "999af10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo Red Neuronal de evaluación tiene unas completitudes de  22.22707616706536\n",
      "El modelo RandomForest de evaluación tiene una completitud de  102.26523707710479\n",
      "El modelo Red Neuronal de bikes tiene una completitud de  619.6128698731212\n",
      "El modelo RandomForest de bikes tiene una completitud de  871.6249811588647\n"
     ]
    }
   ],
   "source": [
    "#Para evaluar la completitud, recorreremos varias muestras y calcularemos el error de prediccion y el de explicacion \n",
    "#para calcular la completitud\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#Escogemos varias muestras y sus objetivos\n",
    "atributivos = atributos[5810:5819,:]\n",
    "objetivos = objetivo[5810:5819]\n",
    "#Necesitaremos además, los atributos sin normalizar\n",
    "atributos2 = evaluation.loc[:, 'class':'Q27']\n",
    "atributos2 = atributos2.to_numpy()\n",
    "atributos2 = atributos2[5810:5819,:]\n",
    "#Necesitaremos dos arrays para guardar las predicciones\n",
    "predicciones1 = []\n",
    "predicciones2 = []\n",
    "\n",
    "for j in range(len(atributivos)):#Reccoremos las muestras\n",
    "    x = atributivos[j]\n",
    "    pred1 = red_evaluation.predict(x,verbose = 0) #Generamos una prediccion por muestra\n",
    "    predicciones1.append(pred1)\n",
    "    y = 0\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos) #Generamos una prediccion por muestra\n",
    "    atributo2 = atributos2[j]\n",
    "    for i in range(len(exp1)): #Calculamos la prediccion de la esplicación, esto lo hacemos multiplicando para \n",
    "        y += exp1[i]*atributo2[i]#cada atributo, el atributo sin normalizar por la importancia de este atributo\n",
    "    predicciones2.append(y)\n",
    "\n",
    "predicciones1 = np.squeeze(predicciones1)  \n",
    "predicciones2 = np.squeeze(predicciones2) \n",
    "mae1 = mean_absolute_error(objetivos, predicciones1)#Calculamos el error de predicción\n",
    "mae2 = mean_absolute_error(objetivos, predicciones2)#Calculamos el error de explicaciones\n",
    "\n",
    "res =  completitud(mae2,mae1)#Calculamos la completitud\n",
    "#Mostramos la completitud\n",
    "print(\"El modelo Red Neuronal de evaluación tiene unas completitudes de \",res)\n",
    "\n",
    "#Repetimos el proceso para el resto de modelos\n",
    "\n",
    "predicciones1 = []\n",
    "predicciones2 = []\n",
    "for j in range(len(atributivos)):\n",
    "    x = atributivos[j]\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    x = x.reshape(1,-1)\n",
    "    pred1 = forest_evaluation.predict(x)\n",
    "    predicciones1.append(pred1)\n",
    "    y = 0\n",
    "    atributo2 = atributos2[j]\n",
    "    for i in range(len(exp1)):\n",
    "        y += exp1[i]*atributo2[i]\n",
    "    predicciones2.append(y)\n",
    "\n",
    "predicciones1 = np.squeeze(predicciones1)  \n",
    "predicciones2 = np.squeeze(predicciones2) \n",
    "mae1 = mean_absolute_error(objetivos, predicciones1)\n",
    "mae2 = mean_absolute_error(objetivos, predicciones2)\n",
    "\n",
    "res =  completitud(mae2,mae1)\n",
    "print(\"El modelo RandomForest de evaluación tiene una completitud de \",res)\n",
    "\n",
    "\n",
    "X = attr[17360:17378,:]\n",
    "objs = obj[17360:17378]\n",
    "\n",
    "attr2 = bikes.loc[:, 'season':'registered']\n",
    "attr2 = attr2.to_numpy()\n",
    "attr2 = attr2[17360:17378,:]\n",
    "predicciones1 = []\n",
    "predicciones2 = []\n",
    "for j in range(len(X)):\n",
    "    x = X[j]\n",
    "    pred1 = red_bikes.predict(x,verbose = 0)\n",
    "    predicciones1.append(pred1)\n",
    "    y = 0\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    atributo2 = attr2[j]\n",
    "    for i in range(len(exp1)):\n",
    "        y += exp1[i]*atributo2[i]\n",
    "    predicciones2.append(y)\n",
    "\n",
    "predicciones1 = np.squeeze(predicciones1)  \n",
    "predicciones2 = np.squeeze(predicciones2) \n",
    "mae1 = mean_absolute_error(objs, predicciones1)\n",
    "mae2 = mean_absolute_error(objs, predicciones2)\n",
    "\n",
    "res =  completitud(mae2,mae1)\n",
    "print(\"El modelo Red Neuronal de bikes tiene una completitud de \",res)\n",
    "\n",
    "predicciones1 = []\n",
    "predicciones2 = []\n",
    "for j in range(len(X)):\n",
    "    x = X[j]\n",
    "    exp1 = explain_model(forest_bikes,x,2,atributos)\n",
    "    x = x.reshape(1,-1)\n",
    "    pred1 = forest_bikes.predict(x)\n",
    "    predicciones1.append(pred1)\n",
    "    y = 0\n",
    "    atributo2 = attr2[j]\n",
    "    for i in range(len(exp1)):\n",
    "        y += exp1[i]*atributo2[i]\n",
    "    predicciones2.append(y)\n",
    "\n",
    "predicciones1 = np.squeeze(predicciones1)  \n",
    "predicciones2 = np.squeeze(predicciones2) \n",
    "mae1 = mean_absolute_error(objs, predicciones1)\n",
    "mae2 = mean_absolute_error(objs, predicciones2)\n",
    "\n",
    "res =  completitud(mae2,mae1)\n",
    "print(\"El modelo RandomForest de bikes tiene una completitud de \",res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1f997bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def congruencia(coherencias):\n",
    "    #Esta métrica ayuda a capturar la variabilidad de la coherencia.\n",
    "    coherencia_media = np.mean(coherencias) #Calculamos la coherencia media\n",
    "    res = (sum((c - coherencia_media)**2 for c in coherencias)/len(coherencias))**0.5 #A partir de ella, calculamos la variabilidad\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b2d5d020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo Red Neuronal de evaluación tiene una congruencia de  [[1.3598213]]\n",
      "El modelo RandomForest de evaluación tiene una congruencia de  [0.85532031]\n",
      "El modelo Red Neuronal de bikes tiene una congruencia de  [[55.404655]]\n",
      "El modelo RandomForest de bikes tiene una congruencia de  [55.63925418]\n"
     ]
    }
   ],
   "source": [
    "#Para comprobar la congruencia, calcularemos la coherencia de varias muestras y apartir de eso se calculará la congruencia\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "#Cogemos varias meustras y sus valores objetivos\n",
    "atributivos = atributos[5810:5819,:]\n",
    "objetivos = objetivo[5810:5819]\n",
    "\n",
    "#Defnimos el número de características a eliminar\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "for i in range(len(atributivos)): #Recorremos las muestras\n",
    "    x = atributivos[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(red_evaluation,x,2,atributos) #Generamos una explicacion para cada muestra\n",
    "    prediccion1 = red_evaluation.predict(x,verbose=0) #Hacemos una predicción\n",
    "    errp = abs(objetivos[i]-prediccion1) #Calculamos el error de predicción\n",
    "   \n",
    "    for j in range(N): #Eliminaremos N características\n",
    "        menosImportante = min(exp1) #Cogemos la menor importancia\n",
    "        atributo = np.where(exp1 == menosImportante)[0] #Vemos a que atributo pertenece\n",
    "        y[atributo] = 0 #Ponemos ese atributo a cero\n",
    "        exp1[atributo] = 99999999999999999 #Cambiamos la importancia de esta característica para que nunca más sea la mínima\n",
    "    prediccion2 = red_evaluation.predict(y,verbose=0) #Hacemos una predicción con la muestra modificada\n",
    "   \n",
    "    errexp = abs(objetivos[i]-prediccion2) #Calculamos el error de la predicción de la muestra modificada\n",
    "    coherencias.append(coherencia(errp,errexp))\n",
    "    \n",
    "\n",
    "coherencias = list(coherencias)\n",
    "congr = congruencia(coherencias) #Calculamos la congruencia\n",
    "\n",
    "    \n",
    "#Mostramos la congruencia\n",
    "print(\"El modelo Red Neuronal de evaluación tiene una congruencia de \",congr)\n",
    "\n",
    "#Repetimos el proceso para los demás modelos\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "for i in range(len(atributivos)):\n",
    "    x = atributivos[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(forest_evaluation,x,2,atributos)\n",
    "    x = x.reshape(1, -1)\n",
    "    prediccion1 = forest_evaluation.predict(x)\n",
    "    errp = abs(objetivos[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 999999999999999999\n",
    "    y = y.reshape(1, -1)\n",
    "    prediccion2 = forest_evaluation.predict(y)\n",
    "      \n",
    "    errexp = abs(objetivos[i]-prediccion2)\n",
    "    coherencias.append(coherencia(errp,errexp))\n",
    "    \n",
    "coherencias = list(coherencias)\n",
    "congr = congruencia(coherencias)\n",
    "\n",
    "print(\"El modelo RandomForest de evaluación tiene una congruencia de \",congr)\n",
    "\n",
    "X=attr[17360:17378,:]\n",
    "objs = obj[17360:17378]\n",
    "\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "    x = X[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(red_bikes,x,2,attr)\n",
    "    prediccion1 = red_bikes.predict(x,verbose=0)\n",
    "    errp = abs(objs[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 99999999999999999\n",
    "    prediccion2 = red_bikes.predict(y,verbose=0)\n",
    "       \n",
    "    errexp = abs(objs[i]-prediccion2)\n",
    "    coherencias.append(coherencia(errp,errexp))\n",
    "\n",
    "coherencias = list(coherencias)\n",
    "congr = congruencia(coherencias)    \n",
    "\n",
    "print(\"El modelo Red Neuronal de bikes tiene una congruencia de \",congr)\n",
    "\n",
    "\n",
    "N=2\n",
    "coherencias = []\n",
    "\n",
    "for i in range(0,len(X)):\n",
    "    x = X[i]\n",
    "    y = x.copy()\n",
    "    exp1 = explain_model(forest_bikes,x,2,attr)\n",
    "    x = x.reshape(1, -1)\n",
    "    prediccion1 = forest_bikes.predict(x)\n",
    "    errp = abs(objs[i]-prediccion1)\n",
    "    \n",
    "   \n",
    "    for i in range(N):\n",
    "        menosImportante = min(exp1)\n",
    "        atributo = np.where(exp1 == menosImportante)[0]\n",
    "        y[atributo] = 0\n",
    "        exp1[atributo] = 999999999999999999\n",
    "    y = y.reshape(1, -1)\n",
    "    prediccion2 = forest_bikes.predict(y)\n",
    "    errexp = abs(objs[i]-prediccion2)\n",
    "    coherencias.append(coherencia(errp,errexp))\n",
    "    \n",
    "coherencias = list(coherencias)\n",
    "congr = congruencia(coherencias)\n",
    "\n",
    "print(\"El modelo RandomForest de bikes tiene una congruencia de \",congr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
