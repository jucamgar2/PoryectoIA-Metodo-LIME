{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0210de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "#Leemos el csv\n",
    "evaluation = pandas.read_csv('turkiye-student-evaluation_R_Specific.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fd7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  ...  \\\n",
       "1       1      2          1           0           4   3   3   3   3   3  ...   \n",
       "2       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "3       1      2          1           2           4   5   5   5   5   5  ...   \n",
       "4       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "5       1      2          1           0           1   1   1   1   1   1  ...   \n",
       "6       1      2          1           3           3   4   4   4   4   4  ...   \n",
       "7       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "8       1      2          1           1           3   5   5   5   5   5  ...   \n",
       "9       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "10      1      2          1           4           4   4   4   4   4   4  ...   \n",
       "\n",
       "    Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  \n",
       "1     3    3    3    3    3    3    3    3    3    3  \n",
       "2     3    3    3    3    3    3    3    3    3    3  \n",
       "3     5    5    5    5    5    5    5    5    5    5  \n",
       "4     3    3    3    3    3    3    3    3    3    3  \n",
       "5     1    1    1    1    1    1    1    1    1    1  \n",
       "6     4    4    4    4    4    4    4    4    4    4  \n",
       "7     4    4    4    4    4    4    4    4    4    4  \n",
       "8     5    5    5    5    5    5    5    5    5    5  \n",
       "9     4    4    4    4    4    4    4    4    4    4  \n",
       "10    4    4    4    4    4    4    4    4    4    4  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bien\n",
    "evaluation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9259e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08333333 0.         0.         ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.25       ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.5        ... 1.         1.         1.        ]\n",
      " ...\n",
      " [1.         0.         0.         ... 1.         1.         1.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos \n",
    "atributos = evaluation.loc[:, 'class':'Q27']\n",
    "atributos = atributos.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "atributos = scaler.fit_transform(atributos)\n",
    "print(atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22a5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 5. ... 5. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "objetivo = evaluation['Q28']\n",
    "objetivo = evaluation['Q28'].to_numpy(dtype=np.float32)\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#objetivo = scaler.fit_transform(objetivo.reshape(-1, 1))\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141c7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ff2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()\n",
    "normalizador.adapt(atributos_entrenamiento)\n",
    "red_evaluation = keras.Sequential()\n",
    "red_evaluation.add(keras.layers.Input(shape=(31,)))\n",
    "red_evaluation.add(normalizador)\n",
    "red_evaluation.add(keras.layers.Dense(70, activation='relu'))\n",
    "red_evaluation.add(keras.layers.Dense(70, activation='sigmoid'))\n",
    "red_evaluation.add(keras.layers.Dense(1, activation='linear'))\n",
    "#red_evaluation.add(keras.layers.Lambda(lambda x: x * 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b8a17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 31)               63        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 70)                2240      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,344\n",
      "Trainable params: 7,281\n",
      "Non-trainable params: 63\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_evaluation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3114e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s 2ms/step - loss: 1.3394 - accuracy: 0.1409 - mae: 0.8608\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.1409 - mae: 0.4440\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.1409 - mae: 0.3668\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.1409 - mae: 0.3400\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.1409 - mae: 0.3269\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.1409 - mae: 0.3127\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.1409 - mae: 0.3044\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.1409 - mae: 0.2949\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.1409 - mae: 0.2899\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.1409 - mae: 0.2832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25fef708fa0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "red_evaluation.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d4f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.1317 - mae: 0.2944\n",
      "0.2986224293708801\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "perdObj = 1.0\n",
    "x=red_evaluation.evaluate(atributos_prueba, objetivo_prueba)\n",
    "while x[0]>perdObj:\n",
    "    red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_evaluation.evaluate(atributos_prueba, objetivo_prueba)\n",
    "    \n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad4c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.1317 - mae: 0.2944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2986224293708801, 0.13172966241836548, 0.29443252086639404]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_evaluation.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84bc4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "Esperado 4: [[4.1225758]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Esperado 3: [[3.0589964]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Esperado 3: [[3.1229732]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Esperado 1: [[1.0480386]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Esperado 3: [[3.1574287]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Esperado 1: [[1.3307854]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Esperado 1: [[1.0480386]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Esperado 5: [[4.757306]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Esperado 5: [[4.99365]]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Esperado 1: [[1.0824459]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Esperado 1: [[1.0824459]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "\n",
    "X=atributos[5809]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 4:',predicciones)\n",
    "X=atributos[5810]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5811]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5812]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5813]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos[5814]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5815]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5816]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos[5817]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos[5818]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos[5819]\n",
    "predicciones = red_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55821bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 0.26038162094909867\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_evaluation = RandomForestRegressor()\n",
    "forest_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "evaluaciones = forest_evaluation.predict(atributos_prueba)\n",
    "mse = mean_squared_error(objetivo_prueba, evaluaciones)\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a83c67dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 4: [4.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 1: [1.]\n",
      "Esperado 3: [3.]\n",
      "Esperado 1: [1.01]\n",
      "Esperado 1: [1.]\n",
      "Esperado 5: [4.85]\n",
      "Esperado 5: [5.]\n",
      "Esperado 1: [1.]\n",
      "Esperado 1: [1.]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "atributos2 = atributos[:, np.newaxis]\n",
    "X=atributos2[5809]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 4:',predicciones)\n",
    "X=atributos2[5810]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5811]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5812]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5813]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 3:',predicciones)\n",
    "X=atributos2[5814]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5815]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5816]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos2[5817]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 5:',predicciones)\n",
    "X=atributos2[5818]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)\n",
    "X=atributos2[5819]\n",
    "predicciones = forest_evaluation.predict(X)\n",
    "print('Esperado 1:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "250f3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#Leemos el csv\n",
    "#bikes = pandas.read_csv('hour.csv', header=0)\n",
    "bikes = pandas.read_csv('hour2.csv',header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0073ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0       1   0     1   0        0        6           0           1  0.24   \n",
       "1       1   0     1   1        0        6           0           1  0.22   \n",
       "2       1   0     1   2        0        6           0           1  0.22   \n",
       "3       1   0     1   3        0        6           0           1  0.24   \n",
       "4       1   0     1   4        0        6           0           1  0.24   \n",
       "5       1   0     1   5        0        6           0           2  0.24   \n",
       "6       1   0     1   6        0        6           0           1  0.22   \n",
       "7       1   0     1   7        0        6           0           1  0.20   \n",
       "8       1   0     1   8        0        6           0           1  0.24   \n",
       "9       1   0     1   9        0        6           0           1  0.32   \n",
       "\n",
       "    atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.2879  0.81     0.0000       3          13   16  \n",
       "1  0.2727  0.80     0.0000       8          32   40  \n",
       "2  0.2727  0.80     0.0000       5          27   32  \n",
       "3  0.2879  0.75     0.0000       3          10   13  \n",
       "4  0.2879  0.75     0.0000       0           1    1  \n",
       "5  0.2576  0.75     0.0896       0           1    1  \n",
       "6  0.2727  0.80     0.0000       2           0    2  \n",
       "7  0.2576  0.86     0.0000       1           2    3  \n",
       "8  0.2879  0.75     0.0000       1           7    8  \n",
       "9  0.3485  0.76     0.0000       8           6   14  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bién\n",
    "bikes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "890b5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.00817439 0.01467269]\n",
      " [0.         0.         0.         ... 0.         0.02179837 0.03611738]\n",
      " [0.         0.         0.         ... 0.         0.01362398 0.03047404]\n",
      " ...\n",
      " [0.         1.         1.         ... 0.19301751 0.01907357 0.09367946]\n",
      " [0.         1.         1.         ... 0.15786999 0.03542234 0.05417607]\n",
      " [0.         1.         1.         ... 0.15786999 0.03269755 0.04176072]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos y los nomalizamos\n",
    "attr = bikes.loc[:, 'season':'registered']\n",
    "attr = attr.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "attr = scaler.fit_transform(attr)\n",
    "print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e783ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16. 40. 32. ... 90. 61. 49.]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los objetivos\n",
    "obj = bikes['cnt']\n",
    "obj = bikes['cnt'].to_numpy(dtype=np.float32)\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#objetivo = scaler.fit_transform(objetivo.reshape(-1, 1))\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6bec2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cogemos un 85% de los datos para entrenar y un 15% de los datos para evaluar el modelo\n",
    "(attr_entrenamiento, attr_prueba,\n",
    " obj_entrenamiento, obj_prueba) = model_selection.train_test_split(\n",
    "    attr, obj, test_size=.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01172681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la red neuronal \n",
    "normalizador = keras.layers.Normalization()\n",
    "normalizador.adapt(attr_entrenamiento)\n",
    "red_bikes = keras.Sequential()\n",
    "red_bikes.add(keras.layers.Input(shape=(14,))) #añadimos la capa de entrada con 14 neuronas\n",
    "red_bikes.add(normalizador)#Aplicamos un normalizador\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(1, activation='linear'))#Necesitamos una capa de salida linear ya que los valores objetivos son lineares\n",
    "#red_bikes.add(keras.layers.Lambda(lambda x: tf.cast(tf.round(x), dtype=tf.int32)))\n",
    "#red_bikes.add(keras.layers.Lambda(lambda x: round(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b9f0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_5 (Normalizat  (None, 14)               29        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               1500      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,730\n",
      "Trainable params: 11,701\n",
      "Non-trainable params: 29\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Vemos un resumen de la red\n",
    "red_bikes.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e5d4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 2ms/step - loss: 9830.8779 - accuracy: 0.0089 - mae: 66.9587 \n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1980.8746 - accuracy: 0.0090 - mae: 32.8334\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 656.0645 - accuracy: 0.0090 - mae: 17.5062\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 893.7592 - accuracy: 0.0090 - mae: 21.4479\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 424.5097 - accuracy: 0.0090 - mae: 13.9899\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 189.4836 - accuracy: 0.0090 - mae: 9.5391\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 312.6246 - accuracy: 0.0090 - mae: 12.2008\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 226.6298 - accuracy: 0.0090 - mae: 9.9923\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 198.0563 - accuracy: 0.0090 - mae: 10.3778\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 156.1754 - accuracy: 0.0090 - mae: 9.6220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2583a5f81c0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compilamos y entrenamos la red neuronal, buscamos minimizar la función de perdida\n",
    "red_bikes.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6aa4bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 440.6978 - accuracy: 0.0098 - mae: 14.1207\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 114.3765 - accuracy: 0.0090 - mae: 7.2802\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 97.8100 - accuracy: 0.0090 - mae: 7.1500\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 125.4546 - accuracy: 0.0090 - mae: 7.8941\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 109.7826 - accuracy: 0.0090 - mae: 7.4003\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 80.7522 - accuracy: 0.0090 - mae: 6.9012\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 46.7532 - accuracy: 0.0090 - mae: 5.1413\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 68.5729 - accuracy: 0.0090 - mae: 6.1264\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 92.2682 - accuracy: 0.0090 - mae: 7.2408\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 28.9138 - accuracy: 0.0090 - mae: 3.9756\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 61.1902 - accuracy: 0.0090 - mae: 5.9513\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 28.3498 - accuracy: 0.0098 - mae: 4.1956\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 39.3985 - accuracy: 0.0090 - mae: 4.6481\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 69.2359 - accuracy: 0.0090 - mae: 6.1651\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 46.5204 - accuracy: 0.0090 - mae: 4.7767\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 22.2563 - accuracy: 0.0090 - mae: 3.3030\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 72.6950 - accuracy: 0.0090 - mae: 5.1966\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.0381 - accuracy: 0.0090 - mae: 3.2187\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 37.4339 - accuracy: 0.0090 - mae: 4.6309\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 60.4343 - accuracy: 0.0090 - mae: 5.2108\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.7098 - accuracy: 0.0090 - mae: 2.9826\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 21.0924 - accuracy: 0.0090 - mae: 3.4927\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 279.9266 - accuracy: 0.0098 - mae: 9.4513\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 51.3052 - accuracy: 0.0090 - mae: 4.6093\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 34.0115 - accuracy: 0.0090 - mae: 4.4105\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 72.0673 - accuracy: 0.0090 - mae: 6.0482\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 19.4318 - accuracy: 0.0090 - mae: 3.2953\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.7117 - accuracy: 0.0090 - mae: 1.8725\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 51.5372 - accuracy: 0.0090 - mae: 5.2414\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.3490 - accuracy: 0.0090 - mae: 3.0689\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.2986 - accuracy: 0.0090 - mae: 2.3276\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 31.9947 - accuracy: 0.0090 - mae: 4.3181\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 43.7484 - accuracy: 0.0088 - mae: 3.6703\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 11.9427 - accuracy: 0.0098 - mae: 1.8202\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 43.2531 - accuracy: 0.0090 - mae: 3.6401\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 75.8364 - accuracy: 0.0090 - mae: 5.4023\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 45.0528 - accuracy: 0.0090 - mae: 4.8104\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.3802 - accuracy: 0.0090 - mae: 2.2284\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 123.6229 - accuracy: 0.0085 - mae: 6.7237\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.6756 - accuracy: 0.0090 - mae: 2.2409\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.8256 - accuracy: 0.0090 - mae: 2.5648\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 65.1761 - accuracy: 0.0090 - mae: 5.2965\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 23.3977 - accuracy: 0.0090 - mae: 3.2747\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.0979 - accuracy: 0.0090 - mae: 2.6919\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10.4590 - accuracy: 0.0098 - mae: 2.3186\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.4232 - accuracy: 0.0090 - mae: 2.2499\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 35.0650 - accuracy: 0.0090 - mae: 4.4200\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.4848 - accuracy: 0.0090 - mae: 1.2058\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1451 - accuracy: 0.0090 - mae: 2.2162\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 36.2482 - accuracy: 0.0090 - mae: 4.8889\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.8628 - accuracy: 0.0090 - mae: 2.5592\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.9300 - accuracy: 0.0090 - mae: 2.3344\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.0364 - accuracy: 0.0090 - mae: 2.3053\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4510 - accuracy: 0.0090 - mae: 2.0015\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.6448 - accuracy: 0.0090 - mae: 2.3198\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 18.8115 - accuracy: 0.0098 - mae: 3.3070\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 30.1010 - accuracy: 0.0090 - mae: 4.5239\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.5040 - accuracy: 0.0090 - mae: 3.0614\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.4669 - accuracy: 0.0090 - mae: 2.5871\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.6609 - accuracy: 0.0090 - mae: 3.0395\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.4639 - accuracy: 0.0090 - mae: 2.4680\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.8661 - accuracy: 0.0090 - mae: 2.1443\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.2912 - accuracy: 0.0090 - mae: 1.6370\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7781 - accuracy: 0.0090 - mae: 1.0055\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.6604 - accuracy: 0.0090 - mae: 2.1774\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.0624 - accuracy: 0.0090 - mae: 2.6289\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 8.1877 - accuracy: 0.0098 - mae: 2.2533\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.5653 - accuracy: 0.0090 - mae: 1.2038\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3759 - accuracy: 0.0090 - mae: 2.0881\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 26.8885 - accuracy: 0.0090 - mae: 4.1487\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3549 - accuracy: 0.0090 - mae: 1.1227\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 13.4176 - accuracy: 0.0090 - mae: 2.8618\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.1482 - accuracy: 0.0090 - mae: 1.8205\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.5129 - accuracy: 0.0090 - mae: 2.6066\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4505 - accuracy: 0.0090 - mae: 1.8069\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4127 - accuracy: 0.0090 - mae: 1.5575\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7531 - accuracy: 0.0090 - mae: 1.0049\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 5.2519 - accuracy: 0.0098 - mae: 1.7634\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.9702 - accuracy: 0.0090 - mae: 2.8642\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6317 - accuracy: 0.0090 - mae: 1.2570\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.5601 - accuracy: 0.0090 - mae: 2.7891\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.2915 - accuracy: 0.0090 - mae: 2.6130\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.1620 - accuracy: 0.0090 - mae: 1.6017\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7669 - accuracy: 0.0090 - mae: 1.0073\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.3294 - accuracy: 0.0090 - mae: 1.4442\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.6498 - accuracy: 0.0090 - mae: 3.1885\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.1559 - accuracy: 0.0090 - mae: 1.3261\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.5022 - accuracy: 0.0090 - mae: 1.2183\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 8.2536 - accuracy: 0.0098 - mae: 2.3185\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.0496 - accuracy: 0.0090 - mae: 2.3840\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.7673 - accuracy: 0.0090 - mae: 2.3305\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6074 - accuracy: 0.0090 - mae: 1.5023\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6338 - accuracy: 0.0090 - mae: 1.3063\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.4446 - accuracy: 0.0090 - mae: 2.3904\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.8037 - accuracy: 0.0090 - mae: 1.5652\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.4935 - accuracy: 0.0090 - mae: 2.1331\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.8699 - accuracy: 0.0090 - mae: 1.7394\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6901 - accuracy: 0.0090 - mae: 1.9661\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.7799 - accuracy: 0.0090 - mae: 1.7948\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 5.6290 - accuracy: 0.0098 - mae: 1.6131\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5252 - accuracy: 0.0090 - mae: 1.4260\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4330 - accuracy: 0.0090 - mae: 1.9513\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.0175 - accuracy: 0.0090 - mae: 1.1089\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.2301 - accuracy: 0.0090 - mae: 2.0556\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.7111 - accuracy: 0.0090 - mae: 1.7233\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7697 - accuracy: 0.0090 - mae: 1.0530\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.3984 - accuracy: 0.0090 - mae: 2.5559\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.3563 - accuracy: 0.0090 - mae: 1.6183\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.8205 - accuracy: 0.0090 - mae: 1.0259\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.9324 - accuracy: 0.0090 - mae: 1.5842\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 5.9776 - accuracy: 0.0098 - mae: 1.8775\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4086 - accuracy: 0.0090 - mae: 1.9481\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.1666 - accuracy: 0.0090 - mae: 2.1750\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5336 - accuracy: 0.0090 - mae: 1.3603\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9824 - accuracy: 0.0090 - mae: 1.0364\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4456 - accuracy: 0.0090 - mae: 2.1426\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.9405 - accuracy: 0.0090 - mae: 1.3411\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.3813 - accuracy: 0.0090 - mae: 0.9028\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.7341 - accuracy: 0.0090 - mae: 2.6910\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.0797 - accuracy: 0.0090 - mae: 1.8185\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5482 - accuracy: 0.0090 - mae: 1.7300\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10.6003 - accuracy: 0.0098 - mae: 2.7462\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4652 - accuracy: 0.0090 - mae: 1.9666\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7422 - accuracy: 0.0090 - mae: 1.0501\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.1080 - accuracy: 0.0090 - mae: 0.8026\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.7158 - accuracy: 0.0090 - mae: 2.3236\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4705 - accuracy: 0.0090 - mae: 1.9808\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5882 - accuracy: 0.0090 - mae: 1.5186\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0682 - accuracy: 0.0090 - mae: 1.4302\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3992 - accuracy: 0.0090 - mae: 1.2316\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.3268 - accuracy: 0.0090 - mae: 2.3421\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.1808 - accuracy: 0.0090 - mae: 0.8076\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 3.2451 - accuracy: 0.0098 - mae: 1.0402\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.0143 - accuracy: 0.0090 - mae: 1.7254\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.8199 - accuracy: 0.0090 - mae: 1.7589\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.2488 - accuracy: 0.0090 - mae: 1.4216\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.1430 - accuracy: 0.0090 - mae: 1.1674\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.4713 - accuracy: 0.0090 - mae: 1.5456\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.7407 - accuracy: 0.0090 - mae: 1.7581\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0043 - accuracy: 0.0090 - mae: 1.2694\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.0397 - accuracy: 0.0090 - mae: 1.8583\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.4351 - accuracy: 0.0087 - mae: 3.4756\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.8899 - accuracy: 0.0090 - mae: 1.5398\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 19.6210 - accuracy: 0.0098 - mae: 3.0569\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.2977 - accuracy: 0.0090 - mae: 1.6755\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5825 - accuracy: 0.0090 - mae: 1.7254\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 1.2523 - accuracy: 0.0090 - mae: 0.8577\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3604 - accuracy: 0.0090 - mae: 1.1906\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.8442 - accuracy: 0.0090 - mae: 2.0403\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.6022 - accuracy: 0.0090 - mae: 0.9283\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7898 - accuracy: 0.0090 - mae: 0.6670\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.3525 - accuracy: 0.0090 - mae: 2.5901\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.6535 - accuracy: 0.0090 - mae: 1.8218\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.5136 - accuracy: 0.0090 - mae: 1.2975\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.4067 - accuracy: 0.0098 - mae: 0.8274\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.8044 - accuracy: 0.0090 - mae: 0.6826\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.1156 - accuracy: 0.0090 - mae: 1.2006\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.7664 - accuracy: 0.0090 - mae: 1.6504\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.9118 - accuracy: 0.0090 - mae: 1.9266\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.7604 - accuracy: 0.0090 - mae: 2.0835\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5757 - accuracy: 0.0090 - mae: 1.0018\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.9491 - accuracy: 0.0090 - mae: 1.3793\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6852 - accuracy: 0.0090 - mae: 0.6295\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0702 - accuracy: 0.0090 - mae: 1.4305\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.7091 - accuracy: 0.0090 - mae: 1.2821\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 15.5653 - accuracy: 0.0098 - mae: 3.4230\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.8047 - accuracy: 0.0090 - mae: 1.0005\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3388 - accuracy: 0.0090 - mae: 1.2557\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.8769 - accuracy: 0.0090 - mae: 1.3370\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.5996 - accuracy: 0.0090 - mae: 1.3215\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.3320 - accuracy: 0.0090 - mae: 2.4422\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6741 - accuracy: 0.0090 - mae: 1.4253\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.5662 - accuracy: 0.0090 - mae: 1.3197\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4652 - accuracy: 0.0090 - mae: 1.2812\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.7789 - accuracy: 0.0090 - mae: 2.1910\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.8426 - accuracy: 0.0090 - mae: 1.0970\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 2.3499 - accuracy: 0.0098 - mae: 1.1560\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.7531 - accuracy: 0.0090 - mae: 1.3569\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0579 - accuracy: 0.0090 - mae: 1.4711\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.8667 - accuracy: 0.0090 - mae: 2.7742\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.0090 - mae: 0.6101\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7592 - accuracy: 0.0090 - mae: 0.6418\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.2967 - accuracy: 0.0090 - mae: 1.2481\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.2964 - accuracy: 0.0090 - mae: 1.5040\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.0506 - accuracy: 0.0090 - mae: 1.8849\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.3474 - accuracy: 0.0090 - mae: 1.4890\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.4428 - accuracy: 0.0090 - mae: 0.9189\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.1618 - accuracy: 0.0098 - mae: 0.8031\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4154 - accuracy: 0.0090 - mae: 1.1944\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.3039 - accuracy: 0.0090 - mae: 1.7791\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.8592 - accuracy: 0.0090 - mae: 1.2985\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.9147 - accuracy: 0.0090 - mae: 2.2989\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5178 - accuracy: 0.0090 - mae: 0.8987\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.2852 - accuracy: 0.0090 - mae: 1.1450\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3919 - accuracy: 0.0090 - mae: 1.1095\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4072 - accuracy: 0.0090 - mae: 1.2667\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.0090 - mae: 0.5841\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9552 - accuracy: 0.0090 - mae: 1.1327\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4.3647 - accuracy: 0.0098 - mae: 1.5136\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.7620 - accuracy: 0.0090 - mae: 1.3340\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.0944 - accuracy: 0.0090 - mae: 1.8022\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6748 - accuracy: 0.0090 - mae: 1.6039\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.0090 - mae: 0.6235\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.4143 - accuracy: 0.0090 - mae: 0.9654\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.1631 - accuracy: 0.0090 - mae: 0.8680\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4061 - accuracy: 0.0090 - mae: 1.9874\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.6182 - accuracy: 0.0090 - mae: 1.0389\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.6140 - accuracy: 0.0090 - mae: 2.1973\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.1973 - accuracy: 0.0090 - mae: 1.3928\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.9943 - accuracy: 0.0098 - mae: 0.7027\n",
      "0.9942859411239624\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "perdidaObj = 1.0\n",
    "x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "while x[0]>perdidaObj:\n",
    "    red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "    \n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c731f011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 0.9943 - accuracy: 0.0098 - mae: 0.7027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9942859411239624, 0.00978135783225298, 0.7026968002319336]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_bikes.evaluate(attr_prueba, obj_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e05ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 14) for input KerasTensor(type_spec=TensorSpec(shape=(None, 14), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None,).\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Esperado 203: [[203.53151]]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Esperado 247: [[247.07434]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Esperado 315: [[313.20752]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Esperado 214: [[213.88293]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Esperado 164: [[164.46892]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Esperado 122: [[122.25241]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Esperado 119: [[118.61838]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Esperado 89: [[89.396324]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Esperado 90: [[90.23766]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Esperado 61: [[61.298546]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Esperado 49: [[48.715458]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "\n",
    "X=attr[17368]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr[17369]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr[17370]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr[17371]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr[17372]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr[17373]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr[17374]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr[17375]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr[17376]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr[17377]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr[17378]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c9aa5e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 3.354307192174915\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_bikes = RandomForestRegressor()\n",
    "forest_bikes.fit(attr_entrenamiento, obj_entrenamiento)\n",
    "evaluaciones = forest_bikes.predict(attr_prueba)\n",
    "mse = mean_squared_error(obj_prueba, evaluaciones)\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d16b5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 203: [202.84]\n",
      "Esperado 247: [247.09]\n",
      "Esperado 315: [315.21]\n",
      "Esperado 214: [214.37]\n",
      "Esperado 164: [163.95]\n",
      "Esperado 122: [122.01]\n",
      "Esperado 119: [118.91]\n",
      "Esperado 89: [89.1]\n",
      "Esperado 90: [89.98]\n",
      "Esperado 61: [61.01]\n",
      "Esperado 49: [48.88]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "attr2 = attr[:, np.newaxis]\n",
    "X=attr2[17368]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr2[17369]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr2[17370]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr2[17371]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr2[17372]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr2[17373]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr2[17374]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr2[17375]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr2[17376]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr2[17377]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr2[17378]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc6c7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo LIME\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "N es el n´umero de permutaciones a realizar\n",
    "f es el modelo a explicar\n",
    "X′ ← {} muestras perturbadas\n",
    "R ← {} representaciones\n",
    "W ← {} las distancias entre la muestra x y sus perturbaciones\n",
    "for 1\n",
    "to\n",
    "N do\n",
    "Selecciona k atributos aleatoriamente\n",
    "x′ ← una perturbaci´on de x donde se perturban los k atributos anteriores.\n",
    "w ← la distancia entre x y x′\n",
    "r ← la representaci´on de x′ respecto a x\n",
    "X′ ← X′ ∪ x′\n",
    "R ← R ∪ r\n",
    "W ← R ∪ w\n",
    "end for\n",
    "Y ′ ← f(X′) las predicciones de las perturbaciones\n",
    "G ← modelo ridge entrenado con R para predecir Y ′ y ponderando cada\n",
    "muestra con W\n",
    "return los par´ametros de G\n",
    "\"\"\"\n",
    "\n",
    "def explain_model(f, x, N,M):\n",
    "    #f es el modelo a explicar\n",
    "    #N es el número de permutaciones a realizar\n",
    "    Xi = [] #muestras perturbadas\n",
    "    R = [] #representaciones\n",
    "    W = [] #Las distancias entre la muestra x y sus pertubaciones\n",
    "    for i in range(N):\n",
    "        k = random.randint(1, len(x)) #Escojo un número aletario que representa el número de los atributos a seleccionar\n",
    "        perturbed_x = x.copy() #copio la muestra original\n",
    "        for i in range(k): \n",
    "            perturbed_attr = random.randint(0,len(x)-1)#random.choice(list(x.keys())) Voy escojiento los atributos que perturbare de forma aleatoria\n",
    "            mx = abs(max([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor máximo\n",
    "            mn = abs(min([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor mínimo\n",
    "            perturbed_x[perturbed_attr] = random.uniform(mn, mx) # pertubo el atributo con un valor aleatorio ente mn y mx\n",
    "        w = abs(sum([x[attr] - perturbed_x[attr] for attr in range(0,len(x)-1)])) #Calculo la distancia entre el original y el perturbado\n",
    "        r = [0  if perturbed_x[attr] == x[attr] else 1 for attr in range(0,len(x)-1)] #miramos la representacion del pertubado respecto al original utilizando un operador ternario como solemos hacer en java\n",
    "        Xi.append(perturbed_x) #Acumulo en la lista los perturbados\n",
    "        R.append(r)#Acumulamos en la lista de representaciones\n",
    "        W.append(w)#Añadimos las distancias a la lista\n",
    "    Y_perturbed = f(Xi)#aplicamos el modelo f\n",
    "    G = Ridge()\n",
    "    G.fit(R, Y_perturbed, sample_weight=W)\n",
    "    return G.get_params() #Devolvemos los parametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "634110b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': 'deprecated',\n",
       " 'positive': False,\n",
       " 'random_state': None,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain_model(red_evaluation,atributos[5809],1,atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO IDENTIDAD\n",
    "import pandas\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import lambertw\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Creamos dos instancias de datos y sus respectivas explicaciones LIME\n",
    "xa = np.array([0.5, 0.7, 0.1, 0.3])\n",
    "xb = np.array([0.3, 0.9, 0.2, 0.1])\n",
    "ea = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "eb = np.array([0.3, 0.4, 0.5, 0.1])\n",
    "\n",
    "# Calculamos la distancia entre las instancias de datos\n",
    "data_distance = cdist(xa.reshape(1,-1), xb.reshape(1,-1))\n",
    "\n",
    "# Calculamos la distancia entre las explicaciones LIME\n",
    "exp_distance = cdist(ea.reshape(1,-1), eb.reshape(1,-1))\n",
    "\n",
    "# Verificamos si la métrica Identidad se cumple\n",
    "if data_distance == 0 and exp_distance != 0:\n",
    "    print(\"La métrica Identidad no se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Identidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SEPARABILIDAD\n",
    "# Creamos dos instancias de datos y sus respectivas explicaciones LIME\n",
    "xa = np.array([0.5, 0.7, 0.1, 0.3])\n",
    "xb = np.array([0.3, 0.9, 0.2, 0.1])\n",
    "ea = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "eb = np.array([0.3, 0.4, 0.5, 0.1])\n",
    "\n",
    "# Calculamos la distancia entre las instancias de datos\n",
    "data_distance = cdist(xa.reshape(1,-1), xb.reshape(1,-1))\n",
    "\n",
    "# Calculamos la distancia entre las explicaciones LIME\n",
    "exp_distance = cdist(ea.reshape(1,-1), eb.reshape(1,-1))\n",
    "\n",
    "# Verificamos si la métrica Separabilidad se cumple\n",
    "if data_distance != 0 and exp_distance <= 0:\n",
    "    print(\"La métrica Separabilidad no se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Separabilidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO ESTABILIDAD\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Creamos las distancias entre las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_distances = cdist(x, x[0].reshape(1,-1))\n",
    "exp_distances = cdist(ex, ex[0].reshape(1,-1))\n",
    "\n",
    "# Calculamos el coeficiente de correlación de Pearson entre las distancias\n",
    "correlation, _ = pearsonr(data_distances.flatten(), exp_distances.flatten())\n",
    "\n",
    "# Verificamos si la métrica Estabilidad se cumple\n",
    "if correlation > 0:\n",
    "    print(\"La métrica Estabilidad se cumple para este conjunto de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Estabilidad no se cumple para este conjunto de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0722bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO COHERENCIA\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=1))\n",
    "exp_weights = np.exp(-np.linalg.norm(ex - ex.mean(axis=0), axis=1))\n",
    "\n",
    "# Calculamos los logaritmos naturales de los pesos y los sumamos\n",
    "log_sum_data = np.sum(np.log(data_weights))\n",
    "log_sum_exp = np.sum(np.log(exp_weights))\n",
    "\n",
    "# Calculamos la métrica Coherencia\n",
    "alpha = np.exp(log_sum_data - log_sum_exp + lambertw(0.0, -np.exp(log_sum_data - log_sum_exp)).real)\n",
    "alpha /= len(x)\n",
    "\n",
    "# Imprimimos el valor de la métrica Coherencia\n",
    "print(\"El valor de la métrica Coherencia es:\", alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97773e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO COMPLETITUD\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=1))\n",
    "exp_weights = np.exp(-np.linalg.norm(ex - ex.mean(axis=0), axis=1))\n",
    "\n",
    "# Calculamos los valores de ei y pi\n",
    "ei = np.sum(exp_weights)\n",
    "pi = np.sum(data_weights)\n",
    "\n",
    "# Calculamos la métrica Completitud\n",
    "gamma = ei / pi\n",
    "\n",
    "# Imprimimos el valor de la métrica Completitud\n",
    "print(\"El valor de la métrica Completitud es:\", gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO CONGRUENCIA\n",
    "# Creamos una lista de valores de coherencia para un conjunto de N muestras\n",
    "alpha_values = [0.8, 0.6, 0.7, 0.9, 0.5]\n",
    "\n",
    "# Calculamos el valor promedio de la coherencia\n",
    "alpha = np.mean(alpha_values)\n",
    "\n",
    "# Creamos una lista de valores de alpha_i para cada instancia de datos\n",
    "alpha_i_values = [0.9, 0.7, 0.6, 0.8, 0.4]\n",
    "\n",
    "# Calculamos el número de instancias de datos\n",
    "N = len(alpha_i_values)\n",
    "\n",
    "# Calculamos la suma de las diferencias cuadráticas entre alpha_i y alpha\n",
    "diff_squares_sum = np.sum((np.array(alpha_i_values) - alpha) ** 2)\n",
    "\n",
    "# Calculamos la métrica Congruencia\n",
    "delta = np.sqrt((diff_squares_sum / N) / alpha)\n",
    "\n",
    "# Imprimimos el valor de la métrica Congruencia\n",
    "print(\"El valor de la métrica Congruencia es:\", delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5de2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SELECTIVIDAD\n",
    "# Cargamos el dataset de cáncer de mama de scikit-learn\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Definimos las características y la variable objetivo\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "# Creamos un modelo de regresión logística\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(X, y)\n",
    "\n",
    "# Obtenemos las predicciones del modelo en el conjunto de datos completo\n",
    "y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculamos el AUC para el modelo entrenado en el conjunto de datos completo\n",
    "auc_full = roc_auc_score(y, y_pred)\n",
    "\n",
    "# Ordenamos las características de más a menos relevantes según el modelo\n",
    "idx_sorted = np.argsort(np.abs(model.coef_))[0][::-1]\n",
    "\n",
    "# Creamos una lista para almacenar los AUC para cada característica eliminada\n",
    "auc_scores = []\n",
    "\n",
    "# Iteramos sobre las características de más a menos relevantes según el modelo\n",
    "for i in range(X.shape[1]):\n",
    "    # Establecemos la característica i en cero\n",
    "    X_test = X.copy()\n",
    "    X_test[:, idx_sorted[i]] = 0\n",
    "    \n",
    "    # Obtenemos las predicciones del modelo en el conjunto de datos con la característica i eliminada\n",
    "    y_pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculamos el AUC para el modelo entrenado en el conjunto de datos con la característica i eliminada\n",
    "    auc_test = roc_auc_score(y, y_pred_test)\n",
    "    \n",
    "    # Almacenamos el AUC para la característica i eliminada en la lista de AUC\n",
    "    auc_scores.append(auc_test)\n",
    "\n",
    "# Calculamos la métrica Selectividad como el área bajo la curva ROC para el gráfico de AUC vs características eliminadas\n",
    "selectivity = np.trapz(auc_scores, dx=1)\n",
    "\n",
    "# Imprimimos el valor de la métrica Selectividad\n",
    "print(\"El valor de la métrica Selectividad es:\", selectivity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
