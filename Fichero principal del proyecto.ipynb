{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0210de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "#Leemos el csv\n",
    "evaluation = pandas.read_csv('turkiye-student-evaluation_R_Specific.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "40fd7393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>...</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  ...  \\\n",
       "1       1      2          1           0           4   3   3   3   3   3  ...   \n",
       "2       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "3       1      2          1           2           4   5   5   5   5   5  ...   \n",
       "4       1      2          1           1           3   3   3   3   3   3  ...   \n",
       "5       1      2          1           0           1   1   1   1   1   1  ...   \n",
       "6       1      2          1           3           3   4   4   4   4   4  ...   \n",
       "7       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "8       1      2          1           1           3   5   5   5   5   5  ...   \n",
       "9       1      2          1           1           3   4   4   4   4   4  ...   \n",
       "10      1      2          1           4           4   4   4   4   4   4  ...   \n",
       "\n",
       "    Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  \n",
       "1     3    3    3    3    3    3    3    3    3    3  \n",
       "2     3    3    3    3    3    3    3    3    3    3  \n",
       "3     5    5    5    5    5    5    5    5    5    5  \n",
       "4     3    3    3    3    3    3    3    3    3    3  \n",
       "5     1    1    1    1    1    1    1    1    1    1  \n",
       "6     4    4    4    4    4    4    4    4    4    4  \n",
       "7     4    4    4    4    4    4    4    4    4    4  \n",
       "8     5    5    5    5    5    5    5    5    5    5  \n",
       "9     4    4    4    4    4    4    4    4    4    4  \n",
       "10    4    4    4    4    4    4    4    4    4    4  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bién\n",
    "evaluation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9259e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08333333 0.         0.         ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.25       ... 0.5        0.5        0.5       ]\n",
      " [0.08333333 0.         0.5        ... 1.         1.         1.        ]\n",
      " ...\n",
      " [1.         0.         0.         ... 1.         1.         1.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]\n",
      " [1.         0.         0.25       ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos \n",
    "atributos = evaluation.loc[:, 'class':'Q27']\n",
    "atributos = atributos.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "atributos = scaler.fit_transform(atributos)\n",
    "print(atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b22a5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5]\n",
      " [0.5]\n",
      " [1. ]\n",
      " ...\n",
      " [1. ]\n",
      " [0. ]\n",
      " [0. ]]\n"
     ]
    }
   ],
   "source": [
    "objetivo = evaluation['Q28']\n",
    "objetivo = evaluation['Q28'].to_numpy(dtype=np.float32)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "objetivo = scaler.fit_transform(objetivo.reshape(-1, 1))\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "141c7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a6ff2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.Normalization()\n",
    "normalizador.adapt(atributos_entrenamiento)\n",
    "red_evaluation = keras.Sequential()\n",
    "red_evaluation.add(keras.layers.Input(shape=(31,)))\n",
    "red_evaluation.add(normalizador)\n",
    "red_evaluation.add(keras.layers.Dense(75, activation='relu'))\n",
    "red_evaluation.add(keras.layers.Dense(75, activation='sigmoid'))\n",
    "red_evaluation.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "red_evaluation.add(keras.layers.Lambda(lambda x: x * 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6b8a17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_26 (Normaliza  (None, 31)               63        \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 75)                2400      \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 76        \n",
      "                                                                 \n",
      " lambda_2 (Lambda)           (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,239\n",
      "Trainable params: 8,176\n",
      "Non-trainable params: 63\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_evaluation.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3114e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s 4ms/step - loss: 0.2356 - accuracy: 0.2203 - mae: 0.3602\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.3107 - mae: 0.2350\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.3162 - mae: 0.2042\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.3174 - mae: 0.1802\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.3184 - mae: 0.1620\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.3184 - mae: 0.1499\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.3182 - mae: 0.1406\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.3184 - mae: 0.1334\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.3178 - mae: 0.1278\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.3178 - mae: 0.1230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1eabcc910>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "red_evaluation.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_evaluation.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d4f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 703us/step - loss: 0.0315 - accuracy: 0.3322 - mae: 0.1270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.031479619443416595, 0.33218786120414734, 0.127012699842453]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_evaluation.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250f3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para crear la red neuronal\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#Leemos el csv\n",
    "#bikes = pandas.read_csv('hour.csv', header=0)\n",
    "bikes = pandas.read_csv('hour2.csv',header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0073ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0       1   0     1   0        0        6           0           1  0.24   \n",
       "1       1   0     1   1        0        6           0           1  0.22   \n",
       "2       1   0     1   2        0        6           0           1  0.22   \n",
       "3       1   0     1   3        0        6           0           1  0.24   \n",
       "4       1   0     1   4        0        6           0           1  0.24   \n",
       "5       1   0     1   5        0        6           0           2  0.24   \n",
       "6       1   0     1   6        0        6           0           1  0.22   \n",
       "7       1   0     1   7        0        6           0           1  0.20   \n",
       "8       1   0     1   8        0        6           0           1  0.24   \n",
       "9       1   0     1   9        0        6           0           1  0.32   \n",
       "\n",
       "    atemp   hum  windspeed  casual  registered  cnt  \n",
       "0  0.2879  0.81     0.0000       3          13   16  \n",
       "1  0.2727  0.80     0.0000       8          32   40  \n",
       "2  0.2727  0.80     0.0000       5          27   32  \n",
       "3  0.2879  0.75     0.0000       3          10   13  \n",
       "4  0.2879  0.75     0.0000       0           1    1  \n",
       "5  0.2576  0.75     0.0896       0           1    1  \n",
       "6  0.2727  0.80     0.0000       2           0    2  \n",
       "7  0.2576  0.86     0.0000       1           2    3  \n",
       "8  0.2879  0.75     0.0000       1           7    8  \n",
       "9  0.3485  0.76     0.0000       8           6   14  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostramos las 10 primeras lineas para ver que se ha leido bién\n",
    "bikes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "890b5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.00817439 0.01467269]\n",
      " [0.         0.         0.         ... 0.         0.02179837 0.03611738]\n",
      " [0.         0.         0.         ... 0.         0.01362398 0.03047404]\n",
      " ...\n",
      " [0.         1.         1.         ... 0.19301751 0.01907357 0.09367946]\n",
      " [0.         1.         1.         ... 0.15786999 0.03542234 0.05417607]\n",
      " [0.         1.         1.         ... 0.15786999 0.03269755 0.04176072]]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los atributos y los nomalizamos\n",
    "attr = bikes.loc[:, 'season':'registered']\n",
    "attr = attr.to_numpy()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "attr = scaler.fit_transform(attr)\n",
    "print(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e783ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16. 40. 32. ... 90. 61. 49.]\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos los objetivos\n",
    "obj = bikes['cnt']\n",
    "obj = bikes['cnt'].to_numpy(dtype=np.float32)\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#objetivo = scaler.fit_transform(objetivo.reshape(-1, 1))\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bec2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cogemos un 85% de los datos para entrenar y un 15% de los datos para evaluar el modelo\n",
    "(attr_entrenamiento, attr_prueba,\n",
    " obj_entrenamiento, obj_prueba) = model_selection.train_test_split(\n",
    "    attr, obj, test_size=.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01172681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la red neuronal \n",
    "normalizador = keras.layers.Normalization()\n",
    "normalizador.adapt(attr_entrenamiento)\n",
    "red_bikes = keras.Sequential()\n",
    "red_bikes.add(keras.layers.Input(shape=(14,))) #añadimos la capa de entrada con 14 neuronas\n",
    "red_bikes.add(normalizador)#Aplicamos un normalizador\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(100, activation='sigmoid'))#Añadimos una capa intermedia de 100 neuronas con función de activación sigmoide\n",
    "red_bikes.add(keras.layers.Dense(1, activation='linear'))#Necesitamos una capa de salida linear ya que los valores objetivos son lineares\n",
    "#red_bikes.add(keras.layers.Lambda(lambda x: tf.cast(tf.round(x), dtype=tf.int32)))\n",
    "#red_bikes.add(keras.layers.Lambda(lambda x: round(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b9f0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_2 (Normalizat  (None, 14)               29        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               1500      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,730\n",
      "Trainable params: 11,701\n",
      "Non-trainable params: 29\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Vemos un resumen de la red\n",
    "red_bikes.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e5d4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 2ms/step - loss: 139.3950 - accuracy: 0.0093 - mae: 9.3511\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 135.1601 - accuracy: 0.0093 - mae: 9.1462\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 108.3286 - accuracy: 0.0093 - mae: 6.4693\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 87.2385 - accuracy: 0.0093 - mae: 6.1692\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 75.5298 - accuracy: 0.0093 - mae: 6.7426\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 82.9607 - accuracy: 0.0093 - mae: 6.9132\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 76.4263 - accuracy: 0.0093 - mae: 7.0043\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 83.1692 - accuracy: 0.0093 - mae: 7.1503\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 42.1194 - accuracy: 0.0093 - mae: 4.8995\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 16.8568 - accuracy: 0.0093 - mae: 2.6588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e2d38f0eb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compilamos y entrenamos la red neuronal, buscamos minimizar la función de perdida\n",
    "red_bikes.compile(optimizer='SGD', loss='mean_squared_error', metrics=['accuracy', 'mae'])\n",
    "red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aa4bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 15.9997 - accuracy: 0.0069 - mae: 2.9485\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 48.5767 - accuracy: 0.0093 - mae: 5.2197\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 51.3548 - accuracy: 0.0093 - mae: 5.1844\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 77.9876 - accuracy: 0.0093 - mae: 6.1130\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 39.3891 - accuracy: 0.0093 - mae: 4.8097\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 79.6484 - accuracy: 0.0093 - mae: 6.9759\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.2278 - accuracy: 0.0093 - mae: 1.9573\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 67.6278 - accuracy: 0.0090 - mae: 5.1665\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 29.2602 - accuracy: 0.0093 - mae: 3.1265\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 66.9405 - accuracy: 0.0091 - mae: 5.9025\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.3352 - accuracy: 0.0093 - mae: 2.5841\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 146.2983 - accuracy: 0.0069 - mae: 7.8664\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 48.1259 - accuracy: 0.0093 - mae: 5.1204\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.9402 - accuracy: 0.0093 - mae: 2.8503\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 32.0422 - accuracy: 0.0093 - mae: 4.5395\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 36.5284 - accuracy: 0.0093 - mae: 4.7301\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 29.1280 - accuracy: 0.0093 - mae: 4.0434\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 48.5750 - accuracy: 0.0093 - mae: 5.5397\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.3477 - accuracy: 0.0093 - mae: 2.6577\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 24.1118 - accuracy: 0.0093 - mae: 3.8336\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 17.8266 - accuracy: 0.0093 - mae: 3.1388\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 26.8402 - accuracy: 0.0093 - mae: 3.4782\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 83.5601 - accuracy: 0.0069 - mae: 6.2473\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.6137 - accuracy: 0.0093 - mae: 3.1543\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.7534 - accuracy: 0.0093 - mae: 1.8397\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.4907 - accuracy: 0.0093 - mae: 4.1454\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.8486 - accuracy: 0.0093 - mae: 2.5544\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 24.0928 - accuracy: 0.0093 - mae: 4.0140\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.8671 - accuracy: 0.0093 - mae: 2.1509\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 42.5676 - accuracy: 0.0091 - mae: 4.7567\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 17.1240 - accuracy: 0.0093 - mae: 3.1768\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.0243 - accuracy: 0.0093 - mae: 2.7082\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6491 - accuracy: 0.0093 - mae: 1.6080\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 18.0647 - accuracy: 0.0069 - mae: 2.5725\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 27.2034 - accuracy: 0.0093 - mae: 4.2861\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 19.3253 - accuracy: 0.0093 - mae: 3.4982\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 18.2439 - accuracy: 0.0093 - mae: 3.0131\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.9826 - accuracy: 0.0093 - mae: 2.4988\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 26.3916 - accuracy: 0.0093 - mae: 4.1127\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.6427 - accuracy: 0.0093 - mae: 2.6656\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 30.1354 - accuracy: 0.0093 - mae: 4.0309\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.0400 - accuracy: 0.0093 - mae: 1.4121\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.1537 - accuracy: 0.0093 - mae: 1.4421\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.7994 - accuracy: 0.0093 - mae: 3.4852\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 3.5722 - accuracy: 0.0069 - mae: 1.4002\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.4913 - accuracy: 0.0093 - mae: 1.4928\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.9300 - accuracy: 0.0093 - mae: 2.2605\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 26.3717 - accuracy: 0.0093 - mae: 4.1973\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.4418 - accuracy: 0.0093 - mae: 3.7491\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6596 - accuracy: 0.0093 - mae: 1.1253\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.1269 - accuracy: 0.0093 - mae: 0.9839\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.9032 - accuracy: 0.0093 - mae: 1.1817\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 29.6528 - accuracy: 0.0090 - mae: 4.2512\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.0849 - accuracy: 0.0093 - mae: 1.2144\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 24.9473 - accuracy: 0.0090 - mae: 3.8339\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 14.5648 - accuracy: 0.0069 - mae: 2.8658\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6152 - accuracy: 0.0093 - mae: 1.7645\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.6630 - accuracy: 0.0093 - mae: 2.0202\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.3664 - accuracy: 0.0093 - mae: 2.4049\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.0265 - accuracy: 0.0093 - mae: 2.0223\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 25.9624 - accuracy: 0.0086 - mae: 2.9485\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.0156 - accuracy: 0.0093 - mae: 1.5097\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.5620 - accuracy: 0.0093 - mae: 2.2558\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 19.2746 - accuracy: 0.0093 - mae: 3.5266\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.5939 - accuracy: 0.0093 - mae: 2.0272\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.1687 - accuracy: 0.0093 - mae: 1.8630\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 29.6765 - accuracy: 0.0069 - mae: 3.9910\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.8271 - accuracy: 0.0093 - mae: 2.8252\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.7494 - accuracy: 0.0093 - mae: 1.6613\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.1437 - accuracy: 0.0093 - mae: 2.8510\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 21.6075 - accuracy: 0.0093 - mae: 3.3528\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.5367 - accuracy: 0.0093 - mae: 1.1066\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.9496 - accuracy: 0.0093 - mae: 1.4491\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 13.7107 - accuracy: 0.0093 - mae: 3.0958\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.2692 - accuracy: 0.0093 - mae: 2.3891\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9228 - accuracy: 0.0093 - mae: 0.9866\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.5889 - accuracy: 0.0093 - mae: 1.9052\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 13.0901 - accuracy: 0.0069 - mae: 2.8658\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.1803 - accuracy: 0.0093 - mae: 3.2894\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.1880 - accuracy: 0.0093 - mae: 2.8422\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4843 - accuracy: 0.0093 - mae: 2.0497\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6636 - accuracy: 0.0093 - mae: 1.2241\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 24.3431 - accuracy: 0.0090 - mae: 3.8218\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.5400 - accuracy: 0.0093 - mae: 1.1729\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.5821 - accuracy: 0.0093 - mae: 1.8047\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.6416 - accuracy: 0.0093 - mae: 0.9129\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.9655 - accuracy: 0.0093 - mae: 1.3390\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.6355 - accuracy: 0.0093 - mae: 2.0719\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 2.8875 - accuracy: 0.0069 - mae: 1.3382\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4063 - accuracy: 0.0093 - mae: 2.0680\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 19.5483 - accuracy: 0.0091 - mae: 3.0630\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3240 - accuracy: 0.0093 - mae: 1.8519\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.1921 - accuracy: 0.0093 - mae: 1.0703\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.8105 - accuracy: 0.0093 - mae: 1.2713\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.1690 - accuracy: 0.0093 - mae: 1.9810\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.4840 - accuracy: 0.0093 - mae: 3.1133\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.5878 - accuracy: 0.0093 - mae: 1.8684\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.4261 - accuracy: 0.0093 - mae: 0.8565\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5501 - accuracy: 0.0093 - mae: 0.9089\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 4.0786 - accuracy: 0.0069 - mae: 1.4766\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.6348 - accuracy: 0.0093 - mae: 1.5148\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.1028 - accuracy: 0.0093 - mae: 2.1195\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4442 - accuracy: 0.0093 - mae: 1.2130\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.5873 - accuracy: 0.0093 - mae: 2.1464\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4523 - accuracy: 0.0093 - mae: 1.1694\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6960 - accuracy: 0.0093 - mae: 1.2282\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4763 - accuracy: 0.0093 - mae: 1.2410\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.1384 - accuracy: 0.0093 - mae: 1.8688\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 20.5914 - accuracy: 0.0093 - mae: 3.8003\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.2358 - accuracy: 0.0093 - mae: 1.1094\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 2.3358 - accuracy: 0.0069 - mae: 1.2052\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7569 - accuracy: 0.0093 - mae: 0.9852\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.8646 - accuracy: 0.0093 - mae: 1.9035\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 23.6737 - accuracy: 0.0084 - mae: 3.4612\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5593 - accuracy: 0.0093 - mae: 1.3612\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.5328 - accuracy: 0.0093 - mae: 1.2431\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.5069 - accuracy: 0.0093 - mae: 2.0475\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.4535 - accuracy: 0.0093 - mae: 2.0661\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.8768 - accuracy: 0.0093 - mae: 2.0498\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.0407 - accuracy: 0.0093 - mae: 1.8687\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.1987 - accuracy: 0.0093 - mae: 0.8001\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.9359 - accuracy: 0.0069 - mae: 1.0494\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.0660 - accuracy: 0.0093 - mae: 0.7468\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.5987 - accuracy: 0.0093 - mae: 1.4976\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 12.4199 - accuracy: 0.0091 - mae: 2.9950\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4647 - accuracy: 0.0093 - mae: 1.7911\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.3666 - accuracy: 0.0093 - mae: 0.8683\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.1786 - accuracy: 0.0093 - mae: 1.7228\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.0659 - accuracy: 0.0093 - mae: 2.3725\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.0604 - accuracy: 0.0093 - mae: 1.0932\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.8323 - accuracy: 0.0093 - mae: 1.0442\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.7038 - accuracy: 0.0093 - mae: 1.5595\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 10.7129 - accuracy: 0.0069 - mae: 2.3472\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.6122 - accuracy: 0.0093 - mae: 1.8862\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.1526 - accuracy: 0.0093 - mae: 1.7549\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.2528 - accuracy: 0.0093 - mae: 1.5027\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.2567 - accuracy: 0.0093 - mae: 2.4440\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 8.1126 - accuracy: 0.0093 - mae: 2.3056\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7173 - accuracy: 0.0093 - mae: 0.9697\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.4860 - accuracy: 0.0093 - mae: 0.9104\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6283 - accuracy: 0.0093 - mae: 1.1936\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.1660 - accuracy: 0.0093 - mae: 1.4374\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.4400 - accuracy: 0.0093 - mae: 1.9563\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.8572 - accuracy: 0.0069 - mae: 1.0558\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.8074 - accuracy: 0.0093 - mae: 1.0207\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.1983 - accuracy: 0.0093 - mae: 1.1966\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 2ms/step - loss: 1.6653 - accuracy: 0.0093 - mae: 0.9453\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.4421 - accuracy: 0.0091 - mae: 2.6209\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.1389 - accuracy: 0.0093 - mae: 2.5118\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.0197 - accuracy: 0.0093 - mae: 0.7321\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 5.0332 - accuracy: 0.0093 - mae: 1.7855\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 11.3207 - accuracy: 0.0090 - mae: 2.5510\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7467 - accuracy: 0.0093 - mae: 1.0437\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4146 - accuracy: 0.0093 - mae: 1.1170\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 12.6455 - accuracy: 0.0069 - mae: 1.3844\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.0230 - accuracy: 0.0093 - mae: 1.0804\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.6390 - accuracy: 0.0093 - mae: 1.3370\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4106 - accuracy: 0.0093 - mae: 1.2451\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9167 - accuracy: 0.0093 - mae: 1.0499\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 7.7582 - accuracy: 0.0088 - mae: 2.2659\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.8385 - accuracy: 0.0093 - mae: 0.6510\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.0093 - mae: 0.6033\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.3942 - accuracy: 0.0093 - mae: 1.7631\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 15.0023 - accuracy: 0.0086 - mae: 3.2744\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 14.1078 - accuracy: 0.0093 - mae: 3.0025\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 2.3024 - accuracy: 0.0069 - mae: 1.1447\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5412 - accuracy: 0.0093 - mae: 0.9124\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.3145 - accuracy: 0.0093 - mae: 0.8383\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.3932 - accuracy: 0.0093 - mae: 0.7308\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.0188 - accuracy: 0.0093 - mae: 0.7439\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.2515 - accuracy: 0.0088 - mae: 2.3278\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 10.7602 - accuracy: 0.0093 - mae: 2.6725\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.0714 - accuracy: 0.0093 - mae: 2.4134\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.9914 - accuracy: 0.0093 - mae: 1.0592\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7285 - accuracy: 0.0093 - mae: 0.6238\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3051 - accuracy: 0.0093 - mae: 1.1680\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 3.7321 - accuracy: 0.0069 - mae: 1.5443\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.4561 - accuracy: 0.0093 - mae: 1.2107\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7582 - accuracy: 0.0093 - mae: 1.0385\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.0561 - accuracy: 0.0093 - mae: 1.1179\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.8091 - accuracy: 0.0093 - mae: 1.0481\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.9530 - accuracy: 0.0093 - mae: 0.7445\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.2473 - accuracy: 0.0093 - mae: 1.1355\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 6.3861 - accuracy: 0.0093 - mae: 2.2132\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 4.5461 - accuracy: 0.0093 - mae: 1.7805\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3538 - accuracy: 0.0093 - mae: 1.1933\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.3847 - accuracy: 0.0093 - mae: 1.2572\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 3.8466 - accuracy: 0.0069 - mae: 1.6006\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 3.9530 - accuracy: 0.0093 - mae: 1.6889\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.7649 - accuracy: 0.0093 - mae: 1.3714\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 2.0275 - accuracy: 0.0093 - mae: 1.1393\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.0093 - mae: 0.5944\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.9613 - accuracy: 0.0093 - mae: 0.7576\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7890 - accuracy: 0.0093 - mae: 0.6802\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.8810 - accuracy: 0.0093 - mae: 1.0405\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 9.4521 - accuracy: 0.0079 - mae: 2.6036\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.7773 - accuracy: 0.0093 - mae: 1.0708\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5899 - accuracy: 0.0093 - mae: 0.9292\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.9721 - accuracy: 0.0069 - mae: 0.7483\n",
      "0.9720876812934875\n"
     ]
    }
   ],
   "source": [
    "#Definimos cuanta perdida queremos tener y ejecutamos el siguiente bucle para entrenar la red hasta conseguir una perdida menor a la definida\n",
    "perdidaObj = 1.0\n",
    "x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "while x[0]>perdidaObj:\n",
    "    red_bikes.fit(attr_entrenamiento, obj_entrenamiento,\n",
    "                batch_size=256, epochs=10)\n",
    "    x=red_bikes.evaluate(attr_prueba, obj_prueba)\n",
    "    \n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c731f011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 1ms/step - loss: 0.8929 - accuracy: 0.0081 - mae: 0.6922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8928684592247009, 0.00805523619055748, 0.6922006011009216]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora que ya hemos conseguido una perdida menor a la que queriamos, evaluamos para volver a comprobar que la hemos conseguido\n",
    "red_bikes.evaluate(attr_prueba, obj_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e05ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "Esperado 203: [[203.3557]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Esperado 247: [[246.93541]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Esperado 315: [[315.41962]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Esperado 214: [[215.09206]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Esperado 164: [[164.07002]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Esperado 122: [[121.828186]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Esperado 119: [[119.20893]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Esperado 89: [[89.70702]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Esperado 90: [[90.72455]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Esperado 61: [[62.387413]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Esperado 49: [[48.95525]]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones de la red se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "\n",
    "X=attr[17368]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr[17369]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr[17370]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr[17371]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr[17372]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr[17373]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr[17374]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr[17375]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr[17376]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr[17377]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr[17378]\n",
    "predicciones = red_bikes.predict(X)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9aa5e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) del modelo: 3.8617047756041427\n"
     ]
    }
   ],
   "source": [
    "#Ahora trabajaremos con el otro modelo que será un random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "forest_bikes = RandomForestRegressor()\n",
    "forest_bikes.fit(attr_entrenamiento, obj_entrenamiento)\n",
    "evaluaciones = forest_bikes.predict(attr_prueba)\n",
    "mse = mean_squared_error(obj_prueba, evaluaciones)\n",
    "print(\"Error cuadrático medio (MSE) del modelo:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d16b5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperado 203: [202.88]\n",
      "Esperado 247: [246.91]\n",
      "Esperado 315: [314.35]\n",
      "Esperado 214: [214.84]\n",
      "Esperado 164: [163.97]\n",
      "Esperado 122: [122.11]\n",
      "Esperado 119: [118.92]\n",
      "Esperado 89: [89.09]\n",
      "Esperado 90: [90.2]\n",
      "Esperado 61: [61.13]\n",
      "Esperado 49: [49.11]\n"
     ]
    }
   ],
   "source": [
    "#Ahora mismo comprobaremos manualmente si las predicciones del random forest se parecen a lo que esperabamos utilizando los ultimos registros con los cuales no se ha entrenado\n",
    "attr2 = attr[:, np.newaxis]\n",
    "X=attr2[17368]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 203:',predicciones)\n",
    "X=attr2[17369]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 247:',predicciones)\n",
    "X=attr2[17370]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 315:',predicciones)\n",
    "X=attr2[17371]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 214:',predicciones)\n",
    "X=attr2[17372]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 164:',predicciones)\n",
    "X=attr2[17373]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 122:',predicciones)\n",
    "X=attr2[17374]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 119:',predicciones)\n",
    "X=attr2[17375]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 89:',predicciones)\n",
    "X=attr2[17376]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 90:',predicciones)\n",
    "X=attr2[17377]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 61:',predicciones)\n",
    "X=attr2[17378]\n",
    "predicciones = forest_bikes.predict(X)\n",
    "print('Esperado 49:',predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo LIME\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "N es el n´umero de permutaciones a realizar\n",
    "f es el modelo a explicar\n",
    "X′ ← {} muestras perturbadas\n",
    "R ← {} representaciones\n",
    "W ← {} las distancias entre la muestra x y sus perturbaciones\n",
    "for 1\n",
    "to\n",
    "N do\n",
    "Selecciona k atributos aleatoriamente\n",
    "x′ ← una perturbaci´on de x donde se perturban los k atributos anteriores.\n",
    "w ← la distancia entre x y x′\n",
    "r ← la representaci´on de x′ respecto a x\n",
    "X′ ← X′ ∪ x′\n",
    "R ← R ∪ r\n",
    "W ← R ∪ w\n",
    "end for\n",
    "Y ′ ← f(X′) las predicciones de las perturbaciones\n",
    "G ← modelo ridge entrenado con R para predecir Y ′ y ponderando cada\n",
    "muestra con W\n",
    "return los par´ametros de G\n",
    "\"\"\"\n",
    "\n",
    "def explain_model(f, x, N,M):\n",
    "    #f es el modelo a explicar\n",
    "    #N es el número de permutaciones a realizar\n",
    "    Xi = [] #muestras perturbadas\n",
    "    R = [] #representaciones\n",
    "    W = [] #Las distancias entre la muestra x y sus pertubaciones\n",
    "    for i in range(N):\n",
    "        k = random.randint(1, len(x)) #Escojo un número aletario que representa el número de los atributos a seleccionar\n",
    "        perturbed_x = x.copy() #copio la muestra original\n",
    "        for i in range(k): \n",
    "            perturbed_attr = random.choice(list(x.keys())) #Voy escojiento los atributos que perturbare de forma aleatoria\n",
    "            mx = abs(max([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor máximo\n",
    "            mn = abs(min([a[perturbed_attr] for a in M])) #Para el atributo aletorio seleccionado calculo el valor mínimo\n",
    "            perturbed_x[perturbed_attr] = random.uniform(mn, mx) # pertubo el atributo con un valor aleatorio ente mn y mx\n",
    "        w = abs(sum([x[attr] - perturbed_x[attr] for attr in x.keys()])) #Calculo la distancia entre el original y el perturbado\n",
    "        r = {attr: 0  if x_perturbed[attr] = x[attr] else 1 for attr in x.keys()} #miramos la representacion del pertubado respecto al original utilizando un operador ternario como solemos hacer en java\n",
    "        Xi.append(x_perturbed) #Acumulo en la lista los perturbados\n",
    "        R.append(r)#Acumulamos en la lista de representaciones\n",
    "        W.append(w)#Añadimos las distancias a la lista\n",
    "    Y_perturbed = f(Xi)#aplicamos el modelo f\n",
    "    G = Ridge().fit(R, Y_perturbed, sample_weight=W) #Utilizamos Ridge \n",
    "    return G.get_params() #Devolvemos los parametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO IDENTIDAD\n",
    "import pandas\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.special import lambertw\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Creamos dos instancias de datos y sus respectivas explicaciones LIME\n",
    "xa = np.array([0.5, 0.7, 0.1, 0.3])\n",
    "xb = np.array([0.3, 0.9, 0.2, 0.1])\n",
    "ea = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "eb = np.array([0.3, 0.4, 0.5, 0.1])\n",
    "\n",
    "# Calculamos la distancia entre las instancias de datos\n",
    "data_distance = cdist(xa.reshape(1,-1), xb.reshape(1,-1))\n",
    "\n",
    "# Calculamos la distancia entre las explicaciones LIME\n",
    "exp_distance = cdist(ea.reshape(1,-1), eb.reshape(1,-1))\n",
    "\n",
    "# Verificamos si la métrica Identidad se cumple\n",
    "if data_distance == 0 and exp_distance != 0:\n",
    "    print(\"La métrica Identidad no se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Identidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SEPARABILIDAD\n",
    "# Creamos dos instancias de datos y sus respectivas explicaciones LIME\n",
    "xa = np.array([0.5, 0.7, 0.1, 0.3])\n",
    "xb = np.array([0.3, 0.9, 0.2, 0.1])\n",
    "ea = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "eb = np.array([0.3, 0.4, 0.5, 0.1])\n",
    "\n",
    "# Calculamos la distancia entre las instancias de datos\n",
    "data_distance = cdist(xa.reshape(1,-1), xb.reshape(1,-1))\n",
    "\n",
    "# Calculamos la distancia entre las explicaciones LIME\n",
    "exp_distance = cdist(ea.reshape(1,-1), eb.reshape(1,-1))\n",
    "\n",
    "# Verificamos si la métrica Separabilidad se cumple\n",
    "if data_distance != 0 and exp_distance <= 0:\n",
    "    print(\"La métrica Separabilidad no se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Separabilidad se cumple para este par de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO ESTABILIDAD\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Creamos las distancias entre las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_distances = cdist(x, x[0].reshape(1,-1))\n",
    "exp_distances = cdist(ex, ex[0].reshape(1,-1))\n",
    "\n",
    "# Calculamos el coeficiente de correlación de Pearson entre las distancias\n",
    "correlation, _ = pearsonr(data_distances.flatten(), exp_distances.flatten())\n",
    "\n",
    "# Verificamos si la métrica Estabilidad se cumple\n",
    "if correlation > 0:\n",
    "    print(\"La métrica Estabilidad se cumple para este conjunto de instancias de datos y sus explicaciones LIME correspondientes.\")\n",
    "else:\n",
    "    print(\"La métrica Estabilidad no se cumple para este conjunto de instancias de datos y sus explicaciones LIME correspondientes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0722bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO COHERENCIA\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=1))\n",
    "exp_weights = np.exp(-np.linalg.norm(ex - ex.mean(axis=0), axis=1))\n",
    "\n",
    "# Calculamos los logaritmos naturales de los pesos y los sumamos\n",
    "log_sum_data = np.sum(np.log(data_weights))\n",
    "log_sum_exp = np.sum(np.log(exp_weights))\n",
    "\n",
    "# Calculamos la métrica Coherencia\n",
    "alpha = np.exp(log_sum_data - log_sum_exp + lambertw(0.0, -np.exp(log_sum_data - log_sum_exp)).real)\n",
    "alpha /= len(x)\n",
    "\n",
    "# Imprimimos el valor de la métrica Coherencia\n",
    "print(\"El valor de la métrica Coherencia es:\", alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97773e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO COMPLETITUD\n",
    "# Creamos las instancias de datos y sus respectivas explicaciones LIME\n",
    "x = np.array([[0.5, 0.7, 0.1, 0.3], [0.3, 0.9, 0.2, 0.1], [0.1, 0.2, 0.8, 0.6]])\n",
    "ex = np.array([[0.2, 0.3, 0.1, 0.4], [0.3, 0.4, 0.5, 0.1], [0.1, 0.3, 0.6, 0.2]])\n",
    "\n",
    "# Calculamos los pesos de las instancias de datos y sus respectivas explicaciones LIME\n",
    "data_weights = np.exp(-np.linalg.norm(x - x.mean(axis=0), axis=1))\n",
    "exp_weights = np.exp(-np.linalg.norm(ex - ex.mean(axis=0), axis=1))\n",
    "\n",
    "# Calculamos los valores de ei y pi\n",
    "ei = np.sum(exp_weights)\n",
    "pi = np.sum(data_weights)\n",
    "\n",
    "# Calculamos la métrica Completitud\n",
    "gamma = ei / pi\n",
    "\n",
    "# Imprimimos el valor de la métrica Completitud\n",
    "print(\"El valor de la métrica Completitud es:\", gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO CONGRUENCIA\n",
    "# Creamos una lista de valores de coherencia para un conjunto de N muestras\n",
    "alpha_values = [0.8, 0.6, 0.7, 0.9, 0.5]\n",
    "\n",
    "# Calculamos el valor promedio de la coherencia\n",
    "alpha = np.mean(alpha_values)\n",
    "\n",
    "# Creamos una lista de valores de alpha_i para cada instancia de datos\n",
    "alpha_i_values = [0.9, 0.7, 0.6, 0.8, 0.4]\n",
    "\n",
    "# Calculamos el número de instancias de datos\n",
    "N = len(alpha_i_values)\n",
    "\n",
    "# Calculamos la suma de las diferencias cuadráticas entre alpha_i y alpha\n",
    "diff_squares_sum = np.sum((np.array(alpha_i_values) - alpha) ** 2)\n",
    "\n",
    "# Calculamos la métrica Congruencia\n",
    "delta = np.sqrt((diff_squares_sum / N) / alpha)\n",
    "\n",
    "# Imprimimos el valor de la métrica Congruencia\n",
    "print(\"El valor de la métrica Congruencia es:\", delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5de2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO SELECTIVIDAD\n",
    "# Cargamos el dataset de cáncer de mama de scikit-learn\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Definimos las características y la variable objetivo\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "# Creamos un modelo de regresión logística\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(X, y)\n",
    "\n",
    "# Obtenemos las predicciones del modelo en el conjunto de datos completo\n",
    "y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculamos el AUC para el modelo entrenado en el conjunto de datos completo\n",
    "auc_full = roc_auc_score(y, y_pred)\n",
    "\n",
    "# Ordenamos las características de más a menos relevantes según el modelo\n",
    "idx_sorted = np.argsort(np.abs(model.coef_))[0][::-1]\n",
    "\n",
    "# Creamos una lista para almacenar los AUC para cada característica eliminada\n",
    "auc_scores = []\n",
    "\n",
    "# Iteramos sobre las características de más a menos relevantes según el modelo\n",
    "for i in range(X.shape[1]):\n",
    "    # Establecemos la característica i en cero\n",
    "    X_test = X.copy()\n",
    "    X_test[:, idx_sorted[i]] = 0\n",
    "    \n",
    "    # Obtenemos las predicciones del modelo en el conjunto de datos con la característica i eliminada\n",
    "    y_pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculamos el AUC para el modelo entrenado en el conjunto de datos con la característica i eliminada\n",
    "    auc_test = roc_auc_score(y, y_pred_test)\n",
    "    \n",
    "    # Almacenamos el AUC para la característica i eliminada en la lista de AUC\n",
    "    auc_scores.append(auc_test)\n",
    "\n",
    "# Calculamos la métrica Selectividad como el área bajo la curva ROC para el gráfico de AUC vs características eliminadas\n",
    "selectivity = np.trapz(auc_scores, dx=1)\n",
    "\n",
    "# Imprimimos el valor de la métrica Selectividad\n",
    "print(\"El valor de la métrica Selectividad es:\", selectivity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
